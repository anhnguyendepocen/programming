{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Ethen 2017-03-18 20:47:47 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.12.0\n",
      "pandas 0.19.2\n",
      "matplotlib 2.0.0\n",
      "scipy 0.18.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from subprocess import call\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: \n",
      " (100000, 4)\n",
      "\n",
      "memory usage: \n",
      " Index            80\n",
      "user_id      800000\n",
      "item_id      800000\n",
      "rating       800000\n",
      "timestamp    800000\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = 'ml-100k'\n",
    "file_path = os.path.join(file_dir, 'u.data')\n",
    "if not os.path.isdir(file_dir):\n",
    "    call(['curl', '-O', 'http://files.grouplens.org/datasets/movielens/' + file_dir + '.zip'])\n",
    "    call(['unzip', file_dir + '.zip'])\n",
    "\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv(file_path, sep = '\\t', names = names)\n",
    "print('data dimension: \\n', df.shape)\n",
    "\n",
    "# we'll later see why we're printing the memory usage information\n",
    "print('\\nmemory usage: \\n', df.memory_usage(deep = True))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data\n",
      "Number of users: 943\n",
      "Number of items: 1682\n",
      "Sparsity: 6.305%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 100000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recsys.utils import create_matrix\n",
    "\n",
    "# pass the DataFrame and names of the user, item \n",
    "# and ratings columns\n",
    "users_col = 'user_id'\n",
    "items_col = 'item_id'\n",
    "ratings_col = 'rating'\n",
    "X, df = create_matrix(df, users_col, items_col, ratings_col)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 79619 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recsys.model_selection import create_train_test\n",
    "\n",
    "seed = 1234\n",
    "test_size = 0.2\n",
    "X_train, X_test = create_train_test(X, test_size, seed)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BPR:\n",
    "    \n",
    "    def __init__(self, learning_rate, n_iters, n_factors, reg, seed):\n",
    "        self.reg = reg\n",
    "        self.seed = seed\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def fit(self, X):\n",
    "        n_users, n_items = X.shape\n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        self.user_factors = rstate.normal(size = (n_users, self.n_factors))\n",
    "        self.item_factors = rstate.normal(size = (n_items, self.n_factors))\n",
    "\n",
    "        for i in trange(self.n_iters):\n",
    "            for user in range(n_users):\n",
    "                self._update(X, n_users, n_items)\n",
    "\n",
    "        # to avoid re-computation at predict\n",
    "        self._predicted = False\n",
    "        return self\n",
    "                \n",
    "    def _update(self, X, n_users, n_items):\n",
    "        # select the triplet uniformly at random\n",
    "        u = np.random.choice(n_users, 1)\n",
    "        indptr = X[u].indptr\n",
    "        indices = X[u].indices\n",
    "\n",
    "        all_indices = np.arange(n_items)\n",
    "        positive_indices = indices[indptr[0]:indptr[1]]\n",
    "        negative_indices = np.where( ~np.in1d(all_indices, positive_indices) )[0]\n",
    "        i = np.random.choice(positive_indices, 1)\n",
    "        j = np.random.choice(negative_indices, 1)\n",
    "\n",
    "        # decompose the estimator\n",
    "        x_ui = self.user_factors[u].dot(self.item_factors[i].T) \n",
    "        x_uj = self.user_factors[u].dot(self.item_factors[j].T)\n",
    "        x_uij = np.ravel(x_ui - x_uj)\n",
    "\n",
    "        # update\n",
    "        sigmoid = 1.0 / (1.0 + np.exp(-x_uij))\n",
    "        gradient_u = sigmoid * (self.item_factors[i] - self.item_factors[j]) - self.reg * self.user_factors[u]\n",
    "        gradient_i = sigmoid * self.user_factors[u] - self.reg * self.item_factors[i]\n",
    "        gradient_j = sigmoid * -self.user_factors[u] - self.reg * self.item_factors[j]\n",
    "        self.user_factors[u] += self.learning_rate * gradient_u\n",
    "        self.item_factors[i] += self.learning_rate * gradient_i\n",
    "        self.item_factors[j] += self.learning_rate * gradient_j\n",
    "        return self\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Obtain the predicted ratings for every users and items\n",
    "        by doing a dot product of the learnt user and item vectors.\n",
    "        The result will be cached to avoid re-computing \n",
    "        it every time we call predict, thus there will\n",
    "        only be an overhead the first time we call it.\n",
    "        Note, ideally you probably don't need to compute \n",
    "        this as it returns a dense matrix and may take\n",
    "        up huge amounts of memory for large datasets\n",
    "        \"\"\"\n",
    "        if not self._predicted:\n",
    "            self._get_prediction()\n",
    "            self._predicted = True\n",
    "\n",
    "        return self._pred\n",
    "\n",
    "    def _get_prediction(self):\n",
    "        \"\"\"Predicted ratings (dot product of user and item vectors)\"\"\"\n",
    "        self._pred = self.user_factors.dot(self.item_factors.T)\n",
    "        return self\n",
    "\n",
    "    def _predict_user(self, user):\n",
    "        \"\"\"\n",
    "        returns the predicted ratings for the specified user,\n",
    "        this is mainly used in computing evaluation metric,\n",
    "        where we avoid computing the whole predicted rating matrix\n",
    "        TODO : do we even need this in the class?\n",
    "        \"\"\"\n",
    "        user_pred = self.user_factors[user].dot(self.item_factors.T)\n",
    "        return user_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BPR at 0x11a1242b0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = 0.1\n",
    "seed = 1234\n",
    "n_factors = 10\n",
    "n_iterations = 10\n",
    "learning_rate = 0.1\n",
    "bpr = BPR(learning_rate, n_iterations, n_factors, reg, seed)\n",
    "bpr.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 0.05007776599505132\n",
      "testing: 0.007592788971367972\n"
     ]
    }
   ],
   "source": [
    "from recsys.metrics import mapk_score\n",
    "\n",
    "k = 5\n",
    "mapk_train = mapk_score(bpr, X_train, k)\n",
    "mapk_test = mapk_score(bpr, X_test, k)\n",
    "print('training:', mapk_train)\n",
    "print('testing:', mapk_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def compute_mse(ratings):\n",
    "    mask = ratings.nonzero()\n",
    "    y_true = ratings.data\n",
    "    prediction = user_factors.dot(self.item_factors.T)\n",
    "    y_pred = prediction[mask]\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ...,  0.,  0.,  0.],\n",
       "       [ 4.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 5.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09914463, -5.02095942, -4.03751762, ..., -2.19622796,\n",
       "        -1.4127792 ,  0.20080199],\n",
       "       [-2.80288287, -1.62467518, -1.23378673, ..., -9.28956822,\n",
       "        -2.40644468, -4.567055  ],\n",
       "       [-1.80605017, -3.98887743,  1.31625954, ..., -0.30670508,\n",
       "         1.9203558 ,  4.10763957],\n",
       "       ..., \n",
       "       [ 4.21659749, -2.19927371, -2.57470449, ..., -1.66798734,\n",
       "        -9.33224649,  6.97416757],\n",
       "       [ 3.32952222,  2.22922845,  1.25110668, ..., -3.82371835,\n",
       "        -3.41696562,  6.26238452],\n",
       "       [ 0.30419376,  0.42761336,  0.95184887, ..., -6.03760303,\n",
       "         2.9253063 , -4.27824216]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _compute_apk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    average precision at k, y_pred is assumed \n",
    "    to be truncated to length k prior to feeding\n",
    "    it to the function\n",
    "    \"\"\"\n",
    "    # convert to set since membership \n",
    "    # testing in a set is vastly faster\n",
    "    actual = set(y_true)\n",
    "    \n",
    "    # precision at i is a percentage of correct \n",
    "    # items among first i recommendations; the\n",
    "    # correct count will be summed up by n_hit\n",
    "    n_hit = 0\n",
    "    precision = 0\n",
    "    for i, p in enumerate(y_pred, 1):\n",
    "        if p in actual:\n",
    "            n_hit += 1\n",
    "            precision += n_hit / i\n",
    "\n",
    "    # divide by recall at the very end\n",
    "    avg_precision = precision / min(len(actual), k)\n",
    "    return avg_precision\n",
    "\n",
    "\n",
    "def mapk_score(estimator, ratings, k):\n",
    "    \"\"\"\n",
    "    mean average precision at k for the ALS model;\n",
    "    TODO: parallelize the computation\n",
    "    \"\"\"\n",
    "    # compare the top k predictions' index to the actual index,\n",
    "    # the estimator is assumed to have the _predict_user method\n",
    "    mapk = 0\n",
    "    n_users = ratings.shape[0]\n",
    "    for u in range(n_users):\n",
    "        y_true = ratings[u].indices\n",
    "        u_pred = estimator._predict_user(u)\n",
    "        y_pred = np.argsort(u_pred)[::-1][:k]\n",
    "        mapk += _compute_apk(y_true, y_pred, k)\n",
    "\n",
    "    mapk /= n_users\n",
    "    return mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mse 29.2, testing mse 29.1\n"
     ]
    }
   ],
   "source": [
    "train_mse = compute_mse(X_train)\n",
    "test_mse = compute_mse(X_test)\n",
    "print( 'training mse {:.1f}, testing mse {:.1f}'.format(train_mse, test_mse) )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
