{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.marekrei.com/blog/theano-tutorial/\n",
    "\n",
    "https://github.com/bbc/theano-bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8999999999999999\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    " \n",
    "x = T.fvector('x')\n",
    "W = theano.shared(numpy.asarray([0.2, 0.7]), 'W')\n",
    "y = (x * W).sum()\n",
    " \n",
    "f = theano.function([x], y)\n",
    " \n",
    "output = f([1.0, 1.0])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8999999999999999\n",
      "8.540000113844872\n",
      "13.124000136613844\n",
      "15.874400122952459\n",
      "17.524640098361967\n",
      "18.514784073771477\n",
      "19.10887045311546\n",
      "19.46532227718082\n",
      "19.67919336949542\n",
      "19.80751602360941\n"
     ]
    }
   ],
   "source": [
    "x = T.fvector('x')\n",
    "target = T.fscalar('target')\n",
    " \n",
    "W = theano.shared(numpy.asarray([0.2, 0.7]), 'W')\n",
    "y = (x * W).sum()\n",
    " \n",
    "cost = T.sqr(target - y)\n",
    "gradients = T.grad(cost, W)\n",
    "W_updated = W - (0.1 * gradients)\n",
    "updates = [(W, W_updated)]\n",
    " \n",
    "f = theano.function([x, target], y, updates = updates)\n",
    " \n",
    "for i in range(10):\n",
    "    output = f([1.0, 1.0], 20.0)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.],\n",
       "       [ 3.,  4.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = theano.shared(numpy.asarray([[1.0,2.0],[3.0,4.0]]), 'a')\n",
    "a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  4.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.diagonal().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26894142,  0.73105858],\n",
       "       [ 0.26894142,  0.73105858]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = theano.tensor.nnet.softmax(a)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.marekrei.com/blog/theano-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano_bpr.utils import load_data_from_movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data, users_to_index, items_to_index = load_data_from_movielens('http://files.grouplens.org/datasets/movielens/ml-100k/ua.base', 3)\n",
    "testing_data, users_to_index, items_to_index = load_data_from_movielens('http://files.grouplens.org/datasets/movielens/ml-100k/ua.test', 3, users_to_index, items_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano_bpr import BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 2495300 random training samples\n",
      "Processed 2495000 ( 99.99% ) in 0.0066 seconds\n",
      "Total training time 16.76 seconds; 6.714787e-06 per sample\n"
     ]
    }
   ],
   "source": [
    "bpr = BPR(10, len(users_to_index.keys()), len(items_to_index.keys()))\n",
    "bpr.train(training_data, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current AUC mean (900 samples): 0.91299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9129410191673194"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.test(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from time import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank = 10\n",
    "n_users = len(users_to_index)\n",
    "n_items = len(items_to_index)\n",
    "lambda_u = 0.0025\n",
    "lambda_i = 0.0025\n",
    "lambda_j = 0.00025\n",
    "lambda_bias = 0.0\n",
    "learning_rate = 0.05\n",
    "\n",
    "n_iters = 50\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _data_to_dict(data):\n",
    "    data_dict = defaultdict(list)\n",
    "    items = set()\n",
    "    for user, item in data:\n",
    "        data_dict[user].append(item)\n",
    "        items.add(item)\n",
    "    \n",
    "    return data_dict, set(data_dict.keys()), items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# item rated by the user, unique user, item index\n",
    "_train_dict, _train_users, _train_items = _data_to_dict(training_data)\n",
    "\n",
    "# number of interactions * epochs\n",
    "n_sgd_samples = len(training_data) * n_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _uniform_user_sampling(n_samples):\n",
    "    sampled_users = np.random.choice(n_users, size = n_samples)\n",
    "    sgd_users = np.array(list(_train_users))[sampled_users]\n",
    "    \n",
    "    # for each randomly sampled user, generate the corresponding positive and negative item\n",
    "    sgd_pos_items, sgd_neg_items = [], []\n",
    "    for sgd_user in sgd_users:\n",
    "        interacted_items = _train_dict[sgd_user]\n",
    "        pos_item = interacted_items[np.random.choice(len(interacted_items))]\n",
    "        sgd_pos_items.append(pos_item)\n",
    "\n",
    "        neg_item = np.random.choice(n_items)\n",
    "        while neg_item in _train_dict[sgd_user]:\n",
    "            neg_item = np.random.choice(n_items)\n",
    "\n",
    "        sgd_neg_items.append(neg_item)\n",
    "        \n",
    "    return sgd_users, sgd_pos_items, sgd_neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_users, sgd_pos_items, sgd_neg_items = _uniform_user_sampling(n_samples = n_sgd_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u = T.lvector('u')\n",
    "i = T.lvector('i')\n",
    "j = T.lvector('j')\n",
    "\n",
    "W = theano.shared(np.random.random((n_users, rank)).astype('float32'), name='W')\n",
    "H = theano.shared(np.random.random((n_items, rank)).astype('float32'), name='H')\n",
    "B = theano.shared(np.zeros(n_items).astype('float32'), name='B')\n",
    "\n",
    "x_ui = T.dot(W[u], H[i].T).diagonal()\n",
    "x_uj = T.dot(W[u], H[j].T).diagonal()\n",
    "x_uij = B[i] - B[j] + x_ui - x_uj\n",
    "\n",
    "# minimize the cost\n",
    "reg_u = lambda_u * (W[u] ** 2).sum()\n",
    "reg_i = lambda_i * (H[i] ** 2).sum()\n",
    "reg_j = lambda_j * (H[j] ** 2).sum()\n",
    "cost = reg_u + reg_i + reg_j - T.log(T.nnet.sigmoid(x_uij)).sum()\n",
    "\n",
    "g_cost_W = T.grad(cost=cost, wrt=W)\n",
    "g_cost_H = T.grad(cost=cost, wrt=H)\n",
    "g_cost_B = T.grad(cost=cost, wrt=B)\n",
    "\n",
    "updates = [ (W, W - learning_rate * g_cost_W), (H, H - learning_rate * g_cost_H), (B, B - learning_rate * g_cost_B) ]\n",
    "train_model = theano.function(inputs=[u, i, j], outputs=cost, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed 2495000 ( 99.99% ) in 0.0064 seconds"
     ]
    }
   ],
   "source": [
    "# batch training\n",
    "z = 0\n",
    "t2 = t1 = time()\n",
    "while (z+1)*batch_size < n_sgd_samples:\n",
    "    train_model(\n",
    "        sgd_users[z*batch_size: (z+1)*batch_size],\n",
    "        sgd_pos_items[z*batch_size: (z+1)*batch_size],\n",
    "        sgd_neg_items[z*batch_size: (z+1)*batch_size]\n",
    "    )\n",
    "    z += 1\n",
    "    t2 = time()\n",
    "    sys.stderr.write(\"\\rProcessed %s ( %.2f%% ) in %.4f seconds\" %(str(z*batch_size), 100.0 * z*batch_size/n_sgd_samples, t2 - t1))\n",
    "    sys.stderr.flush()\n",
    "    t1 = t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_user(user):\n",
    "    w = W.get_value()\n",
    "    h = H.get_value()\n",
    "    b = B.get_value()\n",
    "    user_pred = w[user].dot(h.T) + b \n",
    "    return user_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dict, test_users, test_items = _data_to_dict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9160137687835515"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = 0.0\n",
    "for user in test_dict:\n",
    "    n = 0\n",
    "    user_auc = 0.0\n",
    "    predictions = predict_user(user)\n",
    "\n",
    "    # training dataset's interaction is the negative item for test set\n",
    "    pos_items = test_dict[user]\n",
    "    #neg_items = _train_dict[user]\n",
    "    for pos_item in pos_items:\n",
    "        if pos_item in _train_items:\n",
    "            #for neg_item in neg_items:\n",
    "            for neg_item in _train_items:\n",
    "                if neg_item not in test_dict[user] and neg_item not in _train_dict[user]:\n",
    "                    n += 1\n",
    "                    if predictions[pos_item] > predictions[neg_item]:\n",
    "                        user_auc += 1\n",
    "\n",
    "    user_auc /= n\n",
    "    auc += user_auc\n",
    "    \n",
    "auc / len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91475319760458429"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_values = []\n",
    "\n",
    "for user in test_dict:\n",
    "    if user in _train_users:\n",
    "        auc_for_user = 0.0\n",
    "        n = 0\n",
    "        predictions = predict_user(user)\n",
    "        for pos_item in test_dict[user]:\n",
    "            if pos_item in _train_items:\n",
    "                # training dataset's interaction is the negative item for test set\n",
    "                for neg_item in _train_items:\n",
    "                    if neg_item not in test_dict[user] and neg_item not in _train_dict[user]:\n",
    "                        n += 1\n",
    "                        if predictions[pos_item] > predictions[neg_item]:\n",
    "                            auc_for_user += 1\n",
    "        if n > 0:\n",
    "            auc_for_user /= n\n",
    "            auc_values.append(auc_for_user)\n",
    "            \n",
    "np.mean(auc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "url = 'http://files.grouplens.org/datasets/movielens/ml-100k/ua.base'\n",
    "threshold = 3 # rating for positive\n",
    "\n",
    "raw_data = []\n",
    "for line in urlopen(url).readlines():\n",
    "    user, item, rating, timestamp = str(line, 'utf-8').split('\\t')\n",
    "    if int(rating) > threshold:\n",
    "        raw_data.append((user, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will return a data array consisting\n",
    "# of (user, item) tuples, a mapping from user ids to integers\n",
    "# and a mapping from item ids to integers.\n",
    "users_to_i = {}\n",
    "items_to_i = {}\n",
    "\n",
    "# coordinates that have positive interactions\n",
    "data = []\n",
    "\n",
    "u = 0\n",
    "i = 0\n",
    "for user, item in raw_data:\n",
    "    if user not in users_to_i:\n",
    "        users_to_i[user] = u\n",
    "        u += 1\n",
    "    \n",
    "    if item not in items_to_i:\n",
    "        items_to_i[item] = i\n",
    "        i += 1\n",
    "    \n",
    "    data.append((users_to_i[user], items_to_i[item]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
