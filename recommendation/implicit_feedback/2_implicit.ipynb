{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    html {\n",
       "        font-size: 18px !important;\n",
       "    }\n",
       "\n",
       "    body {\n",
       "        background-color: #FFF !important;\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    body .notebook-app {\n",
       "        background-color: #FFF !important;\n",
       "    }\n",
       "\n",
       "    #header {\n",
       "        box-shadow: none !important;\n",
       "    }\n",
       "\n",
       "    #notebook {\n",
       "        padding-top: 0px;\n",
       "    }\n",
       "\n",
       "    #notebook-container {\n",
       "        box-shadow: none;\n",
       "        -webkit-box-shadow: none;\n",
       "        padding: 10px;\n",
       "    }\n",
       "\n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border: 1px dashed #CCCCCC;\n",
       "    }\n",
       "\n",
       "    .edit_mode div.cell.selected {\n",
       "        border: 1px dashed #828282;\n",
       "    }\n",
       "\n",
       "    div.output_wrapper {\n",
       "        margin-top: 8px;\n",
       "    }\n",
       "\n",
       "    a {\n",
       "        color: #383838;\n",
       "    }\n",
       "\n",
       "    code,\n",
       "    kbd,\n",
       "    pre,\n",
       "    samp {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem !important;\n",
       "    }\n",
       "\n",
       "    h1 {\n",
       "        font-size: 2rem !important;\n",
       "        font-weight: 500 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: uppercase !important;\n",
       "    }\n",
       "\n",
       "    h2 {\n",
       "        font-size: 1.8rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: none !important;\n",
       "    }\n",
       "\n",
       "    h3 {\n",
       "        font-size: 1.5rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        font-style: italic !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    h4,\n",
       "    h5,\n",
       "    h6 {\n",
       "        font-size: 1rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    .prompt {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem;\n",
       "        text-align: right;\n",
       "        line-height: 1.21429rem;\n",
       "    }\n",
       "\n",
       "    /* INTRO PAGE */\n",
       "\n",
       "    .toolbar_info,\n",
       "    .list-container {\n",
       "        ;\n",
       "    }\n",
       "    /* NOTEBOOK */\n",
       "\n",
       "    div#header-container {\n",
       "        display: none !important;\n",
       "    }\n",
       "\n",
       "    div#notebook {\n",
       "        border-top: none;\n",
       "        font-size: 1rem;\n",
       "    }\n",
       "\n",
       "    div.input_prompt {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .code_cell div.input_prompt:after,\n",
       "    div.output_prompt:after {\n",
       "        content: '\\25b6';\n",
       "    }\n",
       "\n",
       "    div.output_prompt {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    div.input_area {\n",
       "        border-radius: 0px;\n",
       "        border: 1px solid #d8d8d8;\n",
       "    }\n",
       "\n",
       "    div.output_area pre {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    div.output_subarea {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .rendered_html pre,\n",
       "    .rendered_html table,\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        border: 1px #828282 solid;\n",
       "        font-size: 0.75rem;\n",
       "        font-family: 'Menlo', monospace;\n",
       "    }\n",
       "\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        padding: 5px 10px;\n",
       "    }\n",
       "\n",
       "    .rendered_html th {\n",
       "        font-weight: normal;\n",
       "        background: #f8f8f8;\n",
       "    }\n",
       "\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "\n",
       "    div.output_html {\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    table.dataframe tr {\n",
       "        border: 1px #CCCCCC;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border-radius: 0px;\n",
       "    }\n",
       "\n",
       "    div.cell.edit_mode {\n",
       "        border-radius: 0px;\n",
       "        border: thin solid #CF5804;\n",
       "    }\n",
       "\n",
       "    span.ansiblue {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    span.ansigray {\n",
       "        color: #d8d8d8;\n",
       "    }\n",
       "\n",
       "    span.ansigreen {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    span.ansipurple {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    span.ansired {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    span.ansiyellow {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    div.output_stderr {\n",
       "        background-color: #D43132;\n",
       "    }\n",
       "\n",
       "    div.output_stderr pre {\n",
       "        color: #e8e8e8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython.CodeMirror {\n",
       "        background: #F8F8F8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython div.CodeMirror-selected {\n",
       "        background: #e8e8e8 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-gutters {\n",
       "        background: #F8F8F8;\n",
       "        border-right: 0px;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-linenumber {\n",
       "        color: #b8b8b8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-cursor {\n",
       "        border-left: 1px solid #585858 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-atom {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-number {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-property,\n",
       "    .cm-s-ipython span.cm-attribute {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-keyword {\n",
       "        font-weight: normal;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-string {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-operator {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-builtin {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable-2 {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-def {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-error {\n",
       "        background: #FFBDBD;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-tag {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-link {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-matchingbracket {\n",
       "        text-decoration: underline;\n",
       "         !important;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir( os.path.join('..','..', 'notebook_format') )\n",
    "from formats import load_style\n",
    "load_style(css_style = 'custom2.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2017-01-25 22:22:54 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.11.3\n",
      "pandas 0.18.1\n",
      "matplotlib 1.5.1\n",
      "sklearn 0.18\n",
      "tqdm 4.11.0-5982db6\n",
      "scipy 0.18.1\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,matplotlib,sklearn,tqdm,scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering for Implicit Feedback Datasets\n",
    "\n",
    "One common scenario in real-world recommendation system is we only have **implicit** instead of **explicit** user-item interaction data. To elaborate on this a little bit more, a user may be searching for an item on the web, or listening to songs. Unlike a rating data, where we have direct access to the user's preference towards an item, these type of actions do not **explicitly** state or quantify any preference of the user for the item, but instead gives us **implicit confidence** about the user’s opinion.\n",
    "\n",
    "Even when we do have explicit data, it might still be a good idea to incorporate implicit data into the model. Consider, for example, listening to songs. When users listen to music on a streaming service, they might rarely ever rate a song that he/she like or dislike. But more often they skip a song, or listen only halfway through it if they dislike it. If the user really liked a song, they will often come back and listen to it. So, to infer a user's musical taste profile, their listens, repeat listens, skips and fraction of tracks listened to, etc. might be far more valuable signals than explicit ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulation\n",
    "\n",
    "Recall from the previous notebook that the loss function for training the recommendation model on explicit feedback data was:\n",
    "\n",
    "\\begin{align}\n",
    "L_{explicit} &= \\sum\\limits_{u,i \\in S}( r_{ui} - x_{u} y_{i}^{T} )^{2} + \\lambda \\big( \\sum\\limits_{u} \\left\\Vert x_{u} \\right\\Vert^{2} + \\sum\\limits_{i} \\left\\Vert y_{i} \\right\\Vert^{2} \\big)\n",
    "\\end{align}\n",
    "\n",
    "Where:\n",
    "\n",
    "- $r_{ui}$ is the true rating given by user $u$ to the item $i$\n",
    "- $x_u$ and $y_i$ are user u's and item i's latent factors, both are $1×d$ dimensional, where $d$ the number of latent factors that the user can specify\n",
    "- $S$ was the set of all user-item ratings\n",
    "- $\\lambda$ controls the regularization strength that prevents overfitting the user and item vectors\n",
    "\n",
    "To keep it concrete, let's assume we're working music data and the value of our $r_{ui}$ will consists of implicit ratings that counts the number of times a user has listened to a song (song listen count). Then new formulation becomes:\n",
    "\n",
    "\\begin{align}\n",
    "L_{implicit} &= \\sum\\limits_{u,i} c_{ui}( p_{ui} - x_{u} y_{i}^{T} )^2 + \\lambda \\big( \\sum\\limits_{u} \\left\\Vert x_{u} \\right\\Vert^{2} + \\sum\\limits_{i} \\left\\Vert y_{i} \\right\\Vert^{2} \\big)\n",
    "\\end{align}\n",
    "\n",
    "Recall that with implicit feedback, we do not have ratings anymore; rather, we have users' preferences for items. Therefore, in the new loss function, the ratings $r_{ui}$ has been replaced with a preference $p_{ui}$ indicating the preference of user $u$ to item $i$. $p_{ui}$ is a set of binary variables and is computed by binarizing $r_{ui}$.\n",
    "\n",
    "\\begin{align}\n",
    "p_{ui} &= \\begin{cases} 1 &\\mbox{if } r_{ui} > 0 \\\\ 0 & \\mbox{otherwise} \\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "We make the assumption that if a user has interacted at all with an item ($r_{ui} > 0$), then we set $p_{ui} = 1$ to indicate that user $u$ has a liking/preference for item $i$. Otherwise, we set $p_{ui} = 0$. However, these assumptions comes with varying degrees of confidence. First of all, when $p_{ui} = 0$, we assume that it should be associated with a lower confidence, as there are many reasons beyond disliking the item as to why the user has not interacted with it. e.g. Unaware of it's existence. On the other hand, as the number of implicit feedback, $r_{ui}$,   grows, we have a stronger indication that the user does indeed like the item (regardless of whether he/she if buying a gift for someone else). So to measure the level of confidence mentioned above, we introduce another set of variables $c_{ui}$ that measures our confidence in observing $p_{ui}$:\n",
    "\n",
    "\\begin{align}\n",
    "c_{ui} = 1 + \\alpha r_{ui}\n",
    "\\end{align}\n",
    "\n",
    "Where the 1 ensures we have some minimal confidence for every user-item pair, and as we observe more and more implicit feedback (as $r_{ui}$ gets larger and larger), our confidence in $p_{ui} = 1$ increases accordingly. And the term $\\alpha$ is a parameter that we have to specify to control the rate of the increase. This formulation takes intuitive sense when we look back at the $c_{ui}( p_{ui} - x_{u} y_{i}^{T} )^2$ term in the loss function. A larger $c_{ui}$ means that the prediction $x_{u} y_{i}^{T}$ has to be that much closer to $p_{ui}$ so that term will not to contribute too much to the total loss.\n",
    "\n",
    "The implementation in the later section will be based on the formula above, but note that there are many ways in which we can tune the formulation above. For example, we can derive $p_{ui}$ from $r_{ui}$ differently. So instead of setting the binary cutoff at 0, we can set it at a threshold that we chose. Similarly, there are many ways to transform $r_{ui}$ into the confidence level $c_{ui}$. e.g. we can use:\n",
    "\n",
    "\\begin{align}\n",
    "c_{ui} = 1 + \\alpha log \\left( 1 + r_{ui} / \\epsilon \\right)\n",
    "\\end{align}\n",
    "\n",
    "Regardless of the scheme, it's important to realize that we are transforming the raw observation $r_{ui}$ into two distinct representation, the preference $p_{ui}$ and the confidence levels of the preference $c_{ui}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares\n",
    "\n",
    "Let's assume that we have $m$ useres and $n$ items. Now, to solve for the loss function above, we start by treating $y_i$ as constant and solve the loss function with respect to $x_u$.\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial L_{implicit}}{\\partial x_u} \n",
    "&\\implies -2 \\sum_i c_{ui}(p_{ui} - x_{u} y_{i}^{T})y_i + 2 \\lambda x_u = 0 \\\\\n",
    "&\\implies -2 Y^T C^u p_u + 2 Y^T C^u Y x_u + 2 \\lambda x_u = 0 \\\\\n",
    "&\\implies (Y^T C^u Y + \\lambda I)x_u = Y^T C^u p_{u} \\\\\n",
    "&\\implies x_u = (Y^T C^u Y + \\lambda I)^{-1} Y^T C^u p_u\n",
    "\\end{align}\n",
    "\n",
    "Where: \n",
    "\n",
    "- $Y \\in \\mathbb{R}^{n \\times d}$ represents all item row vectors vertically stacked on each other\n",
    "- $p_u \\in \\mathbb{R^{n \\times 1}}$ contains element all of the preferences of the user\n",
    "- The diagonal matrix $C^u \\in \\mathbb{R^{n \\times n}}$ consists of $c_{ui}$ in row/column $i$, which is the of confidence in items for this user. e.g. if $u = 0$ then the matrix for user $u_0$ will look like:\n",
    "\n",
    "\\begin{align}\n",
    "{C}^{u_0} = \\begin{bmatrix} c_{u_{01}} & 0 & 0 & 0 & ... & 0 \\\\ 0 & c_{u_{02}} & 0 & 0 & ... &0\\\\ ... \\\\ ... \\\\ 0 & 0 & 0 & 0 & ... & c_{u_{0n}}\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "The main computational bottleneck in the expression above is the need to compute $Y^T C^u Y$ for every user. Speedup can be obtained by re-writing the expression as:\n",
    "\n",
    "\\begin{align}\n",
    "{Y}^T {C}^{u} {Y} &= Y^T Y + {Y}^T \\left( C^u - I \\right) Y\n",
    "\\end{align}\n",
    "\n",
    "Notice now the term $Y^T Y$ becomes independent of each user and can be computed independently, next notice $\\left( C^u - I \\right)$ now has only $n_u$ non-zero elements, where $n_u$ is the number of items for which $r_{ui} > 0$. Similarly, $C^u p_u$ contains only $n_u$ non-zero elements since $p_u$ is a binary transformation of $r_{ui}$. Thus the final formulation becomes:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial L_{implicit}}{\\partial x_u} \n",
    "&\\implies x_u = (Y^T Y + Y^T \\left( C^u - I \\right) Y + \\lambda I)^{-1} Y^T C^u p_u\n",
    "\\end{align}\n",
    "\n",
    "After solving for $x_u$ the same procedure can be carried out for to solve for $y_i$ giving a similar expression:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial L_{implicit}}{\\partial y_i} \n",
    "&\\implies y_i = (X^T X + X^T \\left( C^i - I \\right) X + \\lambda I)^{-1} X^T C^i p_i\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We'll use the same movielens dataset like the previous notebook. The movielens data is not an implicit feedback dataset as the user did provide explicit ratings, but we will use it for now to test out our implementation. The preprocessing procedure of loading the data and doing the train/test split is the same as the previous notebook, thus a helper function is created and saved under the same folder as the notebook. All we need to do is tell it the file directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 90570 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from movielens import create_train_test\n",
    "file_dir = 'ml-100k'\n",
    "train, test = create_train_test(file_dir)\n",
    "\n",
    "# convert to sparse matrix\n",
    "Rui_train = csr_matrix(train)\n",
    "Rui_test = csr_matrix(test)\n",
    "Rui_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following implementation uses some tricks to speed up the procedure. First of all, when we need to solve $Ax = b$ where $A$ is an $n \\times n$ matrix, a lot of books might write the solution as $x = A^{-1} b$, however, in practice there is hardly ever a good reason to calculate that it that way as solving the equation $Ax = b$ is faster than finding $A^{-1}$.\n",
    "\n",
    "The next one is the idea of computing matrix product $X^T X$ using a [outer product](https://docs.scipy.org/doc/numpy/reference/generated/numpy.outer.html) of each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 4],\n",
       "       [3, 1],\n",
       "       [5, 2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example matrix\n",
    "X = np.array([[9, 3, 5], [4, 1, 2]]).T\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[115,  49],\n",
       "       [ 49,  21]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normal matrix product\n",
    "X.T.dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:\n",
      " [9 4]\n",
      "outer product of row:\n",
      " [[81 36]\n",
      " [36 16]]\n",
      "row:\n",
      " [3 1]\n",
      "outer product of row:\n",
      " [[9 3]\n",
      " [3 1]]\n",
      "row:\n",
      " [5 2]\n",
      "outer product of row:\n",
      " [[25 10]\n",
      " [10  4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 115.,   49.],\n",
       "       [  49.,   21.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intialize an empty array\n",
    "end_result = np.zeros((2, 2))\n",
    "\n",
    "# loop through each row add up the outer product\n",
    "for i in range(X.shape[0]):\n",
    "    out = np.outer(X[i], X[i])\n",
    "    end_result += out\n",
    "    print('row:\\n', X[i])\n",
    "    print('outer product of row:\\n', out)\n",
    "\n",
    "end_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way that this speed things is that the matrix product is now the sum of the outer products of the rows, where each row's computation is independent of another can be computed in the parallelized fashion then added back together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImplicitMF:\n",
    "    \"\"\"\n",
    "    Alternating Least Squares for implicit feedback\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_iters : int\n",
    "        number of iterations to train the algorithm\n",
    "\n",
    "    n_factors : int\n",
    "        number/dimension of user and item latent factors\n",
    "\n",
    "    alpha : int\n",
    "        scaling factor that indicates the level of confidence in preference\n",
    "\n",
    "    reg : int\n",
    "        regularization term for the user and item latent factors\n",
    "\n",
    "    seed : int\n",
    "        seed for the randomly initialized user, item latent factors\n",
    "\n",
    "    Reference\n",
    "    ---------\n",
    "    Collaborative Filtering for Implicit Feedback Datasets\n",
    "    http://yifanhu.net/PUB/cf.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, n_iters, n_factors, alpha, reg, seed):\n",
    "        self.reg = reg\n",
    "        self.seed = seed\n",
    "        self.alpha = alpha\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "    \n",
    "    def fit(self, train):\n",
    "        \"\"\"train: csr_matrix that holds the training data\"\"\"\n",
    "        \n",
    "        # the original confidence vectors should include a + 1,\n",
    "        # but this direct addition is not allowed when using sparse matrix,\n",
    "        # thus we'll have to deal with this later in the computation\n",
    "        Cui = self.alpha * train\n",
    "        Ciu = Cui.T.tocsr()\n",
    "        self.n_users, self.n_items = Cui.shape\n",
    "        \n",
    "        # initialize user latent vectors X and item latent vectors Y\n",
    "        # randomly with a specified set seed\n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        self.X = rstate.normal( size = (self.n_users, self.n_factors) )\n",
    "        self.Y = rstate.normal( size = (self.n_items, self.n_factors) )      \n",
    "        for _ in tqdm(range(self.n_iters), desc = 'training progress'):\n",
    "            self._als_step(Cui, self.X, self.Y)\n",
    "            self._als_step(Ciu, self.Y, self.X)\n",
    "            \n",
    "            print(X.shape)\n",
    "            print(Y.shape)\n",
    "            print()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _als_step(self, Cui, X, Y):\n",
    "        \"\"\"\n",
    "        when solving the user latent vectors,\n",
    "        the item vectors will be fixed and vice versa\n",
    "        \"\"\"\n",
    "        # the variable name follows the notation when holding\n",
    "        # the item vector Y constant and solving for user vector X\n",
    "        \n",
    "        # YtY is a d * d matrix that is computed\n",
    "        # independently of each user\n",
    "        YtY = Y.T.dot(Y)\n",
    "        data = Cui.data\n",
    "        indptr, indices = Cui.indptr, Cui.indices\n",
    "\n",
    "        # for every user build up A and b then solve for Ax = b,\n",
    "        # this for loop is the bottleneck and can be easily parallized\n",
    "        # as each users' computation is independent of one another\n",
    "        for u in range(self.n_users):\n",
    "            # initialize a new A and b for every user\n",
    "            b = np.zeros(self.n_factors)\n",
    "            A = YtY + self.reg * np.eye(self.n_factors)\n",
    "            \n",
    "            for index in range( indptr[u], indptr[u + 1] ):         \n",
    "                # indices[index] stores non-zero positions for a given row\n",
    "                # data[index] stores corresponding confidence,\n",
    "                # we also add 1 to the confidence, since we did not \n",
    "                # do it in the beginning, when we were to give every \n",
    "                # user-item pair and minimal confidence\n",
    "                i = indices[index]\n",
    "                confidence = data[index] + 1\n",
    "\n",
    "                # for b, Y^T C^u p_u\n",
    "                # there should be a times 1 for the preference \n",
    "                # Pui = 1\n",
    "                # b += confidence * Y[i] * Pui\n",
    "                # but the times 1 can be dropped\n",
    "                b += confidence * Y[i]\n",
    "                \n",
    "                # for A, Y^T (C^u - I) Y\n",
    "                A += (confidence - 1) * np.outer(Y[i], Y[i])\n",
    "\n",
    "            X[u] = np.linalg.solve(A, b)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"predict ratings for every user and item\"\"\"\n",
    "        pred = self.X.dot(self.Y.T)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training progress: 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ImplicitMF at 0x11c7b7e10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als = ImplicitMF(n_iters = 1, n_factors = 20, alpha = 15, reg = 0.01, seed = 1234)\n",
    "als.fit(Rui_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse(model, ratings):\n",
    "    \"\"\"ignore zero terms prior to comparing the mse\"\"\"\n",
    "    mask = ratings.nonzero()\n",
    "    y_true = ratings.data\n",
    "    y_pred = model.predict()[mask]\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mse 8.2, testing mse 9.2\n"
     ]
    }
   ],
   "source": [
    "train_mse = compute_mse(als, Rui_train)\n",
    "test_mse = compute_mse(als, Rui_test)\n",
    "print( 'training mse {:.1f}, testing mse {:.1f}'.format(train_mse, test_mse) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [Blog: Don’t invert that matrix](https://www.johndcook.com/blog/2010/01/19/dont-invert-that-matrix/)\n",
    "- [Blog: Implicit Feedback and Collaborative Filtering](http://datamusing.info/blog/2015/01/07/implicit-feedback-and-collaborative-filtering/)\n",
    "- [Paper: Collaborative Filtering for Implicit Feedback Datasets](http://yifanhu.net/PUB/cf.pdf)\n",
    "- [StackExchange: Analytic solution for matrix factorization using alternating least squares](http://math.stackexchange.com/questions/1072451/analytic-solution-for-matrix-factorization-using-alternating-least-squares)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
