{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2017-07-22 16:09:24 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 6.1.0\n",
      "\n",
      "numpy 1.13.1\n",
      "pandas 0.19.2\n",
      "matplotlib 2.0.0\n",
      "torch 0.1.12_2\n",
      "epsilon 0.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "from subprocess import call\n",
    "from epsilon.utils import jit_toy_data\n",
    "\n",
    "# no need to worry about this part, it makes\n",
    "# subsequent model evaluation runs faster\n",
    "jit_toy_data()\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,matplotlib,torch,epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize side information, flexible loss function and sequence-based representation. Translate a classic matrix factorization model into a neural network form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make up some trainig data and specify the type to be float, i.e. np.float32\n",
    "# We DO not recommend double, i.e. np.float64, especially on the GPU. GPUs have bad\n",
    "# double precision performance since they are optimized for float32\n",
    "X_train = np.asarray([3.3, 4.4, 5.5, 6.71, 6.93, 4.168, 9.779, 6.182, 7.59, \n",
    "                      2.167, 7.042, 10.791, 5.313, 7.997, 5.654, 9.27, 3.1], dtype = np.float32)\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "y_train = np.asarray([1.7, 2.76, 2.09, 3.19, 1.694, 1.573, 3.366, 2.596, 2.53, \n",
    "                      1.221, 2.827, 3.465, 1.65, 2.904, 2.42, 2.94, 1.3], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PyTorch Tensor is conceptually identical to a numpy array: a Tensor is an n-dimensional array, and PyTorch provides many functions for operating on these Tensors. Like numpy arrays, PyTorch Tensors do not know anything about deep learning or computational graphs or gradients; they are a generic tool for scientific computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert numpy array to Pytorch Tensors to hold input and outputs\n",
    "# and wrap them in Variables. Setting requires_grad = False indicates\n",
    "# that we do not need to compute gradients with respect to these Variables\n",
    "# during the backward pass\n",
    "X = Variable(torch.from_numpy(X_train), requires_grad = False)\n",
    "y = Variable(torch.from_numpy(y_train), requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we start defining the linear regression model\n",
    "\n",
    "# linear regression is simply applying a linear transformation\n",
    "# to the incoming data, i.e. y = Ax + b, here we only have a 1\n",
    "# dimensional data, thus the feature size will be 1\n",
    "model = nn.Linear(in_features = 1, out_features = 1)\n",
    "\n",
    "# although we can write our own loss function, the nn module\n",
    "# also contains definitions of popular loss functions; here\n",
    "# we use the MSELoss, a.k.a the L2 loss, and size_average parameter\n",
    "# simply divides it with the number of examples\n",
    "loss_function = nn.MSELoss(size_average = True)\n",
    "\n",
    "# Then we use the optim module to define an Optimizer that will update the weights of\n",
    "# the model for us. Here we will use SGD; but it contains many other\n",
    "# optimization algorithms. The first argument to the Adam constructor tells the\n",
    "# optimizer the parameters that it should update\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "for i in range(n_epochs):\n",
    "    # torch accumulates the gradients, thus before running new things\n",
    "    # use the optimizer object to zero all of the gradients for the\n",
    "    # variables it will update (which are the learnable weights of the model),\n",
    "    # think in terms of refreshing the gradients before doing the another round of update\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward pass: compute predicted y by passing x to the model\n",
    "    output = model(X)\n",
    "    \n",
    "    # compute and loss function\n",
    "    loss = loss_function(output, y)\n",
    "    \n",
    "    # backward pass: compute gradient of the loss with respect to model parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # call the step function on an Optimizer makes an update to its parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', \n",
       "               0.3180\n",
       "              [torch.FloatTensor of size 1x1]), ('bias', \n",
       "               0.3285\n",
       "              [torch.FloatTensor of size 1])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the weight and bias from the model, we can\n",
    "# access the state_dict() attribute from the model that\n",
    "# we've defined\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.3180\n",
      "[torch.FloatTensor of size 1x1]\n",
      " \n",
      " 0.3285\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or we could get it from the model's parameter\n",
    "# which by itself is a generator\n",
    "param_list = list(model.parameters())\n",
    "print(param_list[0].data, param_list[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAFsCAYAAAADhPr/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116df19b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remember to convert the type from\n",
    "# torch.FloatTensor to numpy\n",
    "params = model.state_dict()\n",
    "weight = params['weight'].numpy()\n",
    "bias = params['bias'].numpy()\n",
    "\n",
    "# change default figure and font size\n",
    "plt.rcParams['figure.figsize'] = 8, 6 \n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# visualize the fitted line against the original data point\n",
    "plt.plot(X_train, y_train, 'ro', label = 'Original data')\n",
    "plt.plot(X_train, weight * X_train + bias, label = 'Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download the data if it's not in the same local directory\n",
    "file_dir = 'ml-100k'\n",
    "file_path = os.path.join(file_dir, 'u.data')\n",
    "if not os.path.isdir(file_dir):\n",
    "    call(['curl', '-O', 'http://files.grouplens.org/datasets/movielens/' + file_dir + '.zip'])\n",
    "    call(['unzip', file_dir + '.zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: \n",
      " (100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id item_id  rating  timestamp\n",
       "0     196     242       3  881250949\n",
       "1     186     302       3  891717742\n",
       "2      22     377       1  878887116\n",
       "3     244      51       2  880606923\n",
       "4     166     346       1  886397596"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epsilon.utils import check_value_and_coltype\n",
    "\n",
    "# pass the DataFrame and names of \n",
    "# the user, item and ratings columns\n",
    "user_col = 'user_id'\n",
    "item_col = 'item_id'\n",
    "rating_col = 'rating'\n",
    "timestamp_col = 'timestamp'\n",
    "\n",
    "names = [user_col, item_col, rating_col, timestamp_col]\n",
    "df = pd.read_csv(file_path, sep = '\\t', names = names)\n",
    "\n",
    "# this is simply a quick utility function to ensure\n",
    "# the columns does not include nan values and convert\n",
    "# type to string if they are not already\n",
    "df = check_value_and_coltype(df, user_col, item_col)\n",
    "print('data dimension: \\n', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set dimension:  (90641, 5)\n",
      "testing set dimension:  (9359, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1997</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id item_id  rating  year  month\n",
       "0     196     242       3  1997     12\n",
       "2      22     377       1  1997     11\n",
       "3     244      51       2  1997     11\n",
       "4     166     346       1  1998      2\n",
       "5     298     474       4  1998      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_time(row):\n",
    "    timestamp = datetime.utcfromtimestamp(row)\n",
    "    time = str(timestamp.year) + ',' + str(timestamp.month)\n",
    "    return time\n",
    "    \n",
    "\n",
    "df[timestamp_col] = df[timestamp_col].apply(extract_time)\n",
    "df_time = (df[timestamp_col]\n",
    "           .str.split(',', expand = True)\n",
    "           .rename(columns = {0: 'year', 1: 'month'}))\n",
    "\n",
    "for col in df_time.columns:\n",
    "    df_time[col] = df_time[col].apply(int)\n",
    "\n",
    "df = df.drop(timestamp_col, axis = 1)\n",
    "df = pd.concat([df, df_time], axis = 1)\n",
    "\n",
    "# mask is the watershed for the train/test data\n",
    "mask = (df['year'] == 1998) & (df['month'] >= 4)\n",
    "df_train = df[~mask]\n",
    "df_test = df[mask]\n",
    "\n",
    "print('training set dimension: ', df_train.shape)\n",
    "print('testing set dimension: ', df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<867x1406 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 50138 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from epsilon.utils import RecommenderMatrix\n",
    "\n",
    "dtype = 'float32'\n",
    "rating_threshold = 3\n",
    "rec_matrix = RecommenderMatrix(\n",
    "    user_col, item_col, rating_col, dtype, rating_threshold = rating_threshold)\n",
    "\n",
    "X_train = rec_matrix.fit_transform(df_train)\n",
    "X_test = rec_matrix.transform(df_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<867x1406 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 1171 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pytorch_rec import Interactions, BaseModule\n",
    "import torch.utils.data as data\n",
    "\n",
    "n_users = X_train.shape[0]\n",
    "n_items = X_train.shape[1]\n",
    "n_factors = 15\n",
    "learning_rate = 0.1\n",
    "#weight_decay = weight_decay\n",
    "#loss_function = loss_function\n",
    "n_epochs = 5\n",
    "\n",
    "batch_size = 10\n",
    "num_workers = 0\n",
    "shuffle = True\n",
    "sparse = False\n",
    "random_state = 1234\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "loss_function = nn.MSELoss(size_average = True)\n",
    "\n",
    "# check if it's possible to use gpu\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = np.random.randint(n_users)\n",
    "neg_item = np.random.randint(n_items)\n",
    "start = X_train.indptr[row]\n",
    "end = X_train.indptr[row + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 104,  184,  204,  216,  223,  237,  392,  484,  497,  524,  527,\n",
       "        529,  532,  537,  538,  552,  557,  563,  570,  580,  591,  595,\n",
       "        596,  599,  604,  613,  618,  620,  621,  638,  654,  665,  700,\n",
       "        755,  761,  777,  830,  831,  834,  853,  884,  889,  934,  942,\n",
       "        943,  948,  952,  956,  958,  967,  989, 1013, 1056, 1081, 1097,\n",
       "       1145, 1226, 1287, 1298, 1364, 1386], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = X_train.indices[start:end]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searched = np.searchsorted(X_train.indices[start:end], neg_item, 'right')\n",
    "searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = Interactions(train)\n",
    "train_loader = data.DataLoader(\n",
    "    data_train, batch_size = batch_size, shuffle = shuffle, num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = BaseModule(n_users, n_items, n_factors, sparse)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "solver = optimizer(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([868, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1639, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([868, 15])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?np.searchsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:18<00:00, 15.81s/it, loss=246]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from torch.autograd import Variable\n",
    "\n",
    "history = []\n",
    "loop = trange(n_epochs)\n",
    "for n_epoch in loop:\n",
    "    total_loss = torch.FloatTensor([0.0])\n",
    "    for batch_idx, (row, col, value) in enumerate(train_loader):\n",
    "        if cuda:\n",
    "            row, col, value = row.cuda(), col.cuda(), value.cuda()\n",
    "        \n",
    "        row = Variable(row, requires_grad = False)\n",
    "        col = Variable(col, requires_grad = False)\n",
    "        value = Variable(value, requires_grad = False)\n",
    "        \n",
    "        # boilerplate code:\n",
    "        # 1. refresh gradients\n",
    "        # 2. conduct forward pass\n",
    "        # 3. compute loss function\n",
    "        # 4. perform backward pass\n",
    "        # 5. do a step and update the weights\n",
    "        solver.zero_grad()\n",
    "        output = model(row, col)\n",
    "        loss = loss_function(output, value)\n",
    "        loss.backward()\n",
    "        solver.step()\n",
    "        total_loss += loss.data[0]\n",
    "    \n",
    "    loss = total_loss[0] / len(train_loader)\n",
    "    # specify loss to display at the end of the progress bar\n",
    "    loop.set_postfix(loss = loss)\n",
    "    history.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[214.5266990291262,\n",
       " 228.3621193733451,\n",
       " 239.10773389232128,\n",
       " 238.5614794792586,\n",
       " 245.89502427184465]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-32a6c6ca30b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m self.model = model(self.n_users,\n\u001b[0m\u001b[1;32m      2\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_items\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                            \u001b[0mn_factors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_factors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            sparse=sparse)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "self.model = model(self.n_users,\n",
    "                           self.n_items,\n",
    "                           n_factors=self.n_factors,\n",
    "                           dropout_p=self.dropout_p,\n",
    "                           sparse=sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = BasePipeline(train, test=test, model=BaseModule,\n",
    "                        n_factors=10, batch_size=1024, dropout_p=0.02,\n",
    "                        lr=0.02, weight_decay=0.1,\n",
    "                        optimizer=torch.optim.Adam, n_epochs=40,\n",
    "                        verbose=True, random_seed=2017)\n",
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "- [Blog: Matrix Factorization in PyTorch](http://blog.ethanrosenthal.com/2017/06/20/matrix-factorization-in-pytorch/)\n",
    "- [Notebook: PyTorch Tensor Basic Usage](http://nbviewer.jupyter.org/github/GunhoChoi/Kind_PyTorch_Tutorial/blob/master/01_Tensor_Basics/pytorch_tensor_basic.ipynb)\n",
    "- [Notebook: PyTorch Linear Regression](http://nbviewer.jupyter.org/github/GunhoChoi/Kind_PyTorch_Tutorial/blob/master/03_Linear_Regression/Linear_Regression.ipynb)\n",
    "- [PyTorch Documentation: Learning PyTorch with Examples](http://pytorch.org/tutorials/beginner/pytorch_with_examples.html)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
