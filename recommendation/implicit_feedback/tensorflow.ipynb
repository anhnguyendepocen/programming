{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension: \n",
      " (100000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_dir = 'ml-100k'\n",
    "file_path = os.path.join(file_dir, 'u.data')\n",
    "if not os.path.isdir(file_dir):\n",
    "    call(['curl', '-O', 'http://files.grouplens.org/datasets/movielens/' + file_dir + '.zip'])\n",
    "    call(['unzip', file_dir + '.zip'])\n",
    "\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "data = pd.read_csv(file_path, sep = '\\t', names = names)\n",
    "print('data dimension: \\n', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1574 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 82520 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def create_matrix(data, users_col, items_col, ratings_col, threshold = None):\n",
    "    \"\"\"\n",
    "    creates the sparse user-item interaction matrix,\n",
    "    if the data is not in the format where the interaction only\n",
    "    contains the positive items (indicated by 1), then use the \n",
    "    threshold parameter to determine which items are considered positive\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        implicit rating data\n",
    "\n",
    "    users_col : str\n",
    "        user column name\n",
    "\n",
    "    items_col : str\n",
    "        item column name\n",
    "    \n",
    "    ratings_col : str\n",
    "        implicit rating column name\n",
    "\n",
    "    threshold : int, default None\n",
    "        threshold to determine whether the user-item pair is \n",
    "        a positive feedback\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ratings : scipy sparse csr_matrix [n_users, n_items]\n",
    "        user/item ratings matrix\n",
    "\n",
    "    data : DataFrame\n",
    "        the implict rating data that retains only the positive feedback\n",
    "        (if specified to do so)\n",
    "    \"\"\"\n",
    "    if threshold is not None:\n",
    "        data = data[data[ratings_col] >= threshold]\n",
    "        data[ratings_col] = 1\n",
    "    \n",
    "    for col in (items_col, users_col, ratings_col):\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "    ratings = csr_matrix(( data[ratings_col],\n",
    "                           (data[users_col].cat.codes, data[items_col].cat.codes) ))\n",
    "    ratings.eliminate_zeros()\n",
    "    return ratings, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items_col = 'item_id'\n",
    "users_col = 'user_id'\n",
    "ratings_col = 'rating'\n",
    "threshold = 3\n",
    "X, df = create_matrix(df, users_col, items_col, ratings_col, threshold)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "def create_train_test(ratings, test_size = 0.2, seed = 1234):\n",
    "    \"\"\"\n",
    "    split the user-item interactions matrix into train and test set\n",
    "    by removing some of the interactions from every user and pretend\n",
    "    that we never seen them\n",
    "    TODO: parallelize the computation\n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings : scipy sparse csr_matrix\n",
    "        The user-item interactions matrix\n",
    "    test_size : float between 0.0 and 1.0, default 0.2\n",
    "        Proportion of the user-item interactions for each user\n",
    "        in the dataset to move to the test set; e.g. if set to 0.2\n",
    "        and a user has 10 interactions, then 2 will be moved to the\n",
    "        test set\n",
    "    seed : int, default 1234\n",
    "        Seed for reproducible random splitting the \n",
    "        data into train/test set\n",
    "    Returns\n",
    "    -------\n",
    "    train : scipy sparse csr_matrix\n",
    "        Training set\n",
    "    test : scipy sparse csr_matrix\n",
    "        Test set\n",
    "    \"\"\"\n",
    "    assert test_size < 1.0 and test_size > 0.0\n",
    "\n",
    "    # Dictionary Of Keys based sparse matrix is more efficient\n",
    "    # for constructing sparse matrices incrementally compared with csr_matrix\n",
    "    train = ratings.copy().todok()\n",
    "    test = dok_matrix(train.shape, dtype = np.int32)\n",
    "    \n",
    "    # for all the users assign randomly chosen interactions\n",
    "    # to the test and assign those interactions to zero in the training;\n",
    "    # when computing the interactions to go into the test set, \n",
    "    # remember to round up the numbers (e.g. a user has 4 ratings, if the\n",
    "    # test_size is 0.2, then 0.8 ratings will go to test, thus we need to\n",
    "    # round up to ensure the test set gets at least 1 rating)\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    for u in range(ratings.shape[0]):\n",
    "        split_index = ratings[u].indices\n",
    "        n_splits = ceil(test_size * split_index.shape[0])\n",
    "        test_index = rstate.choice(split_index, size = n_splits, replace = False)\n",
    "        test[u, test_index] = ratings[u, test_index]\n",
    "        train[u, test_index] = 0\n",
    "    \n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1574 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 65641 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = create_train_test(ratings, test_size = 0.2, seed = 1234)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import trange\n",
    "from itertools import islice\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class TensorflowBPR:\n",
    "    \"\"\"\n",
    "    Bayesian Personalized Ranking (BPR) for implicit feedback data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_rate : float, default 0.01\n",
    "        learning rate for the Adam optimizer\n",
    "\n",
    "    n_factors : int, default 20\n",
    "        Number/dimension of user and item latent factors\n",
    "\n",
    "    n_iters : int, default 15\n",
    "        Number of iterations to train the algorithm\n",
    "        \n",
    "    n_batch_size : int, default 2000\n",
    "        batch size for batch gradient descent, the original paper\n",
    "        uses stochastic gradient descent (i.e., batch size of 1),\n",
    "        but this can make the training unstable (very sensitive to\n",
    "        learning rate)\n",
    "\n",
    "    reg : int, default 0.01\n",
    "        Regularization term for the user and item latent factors\n",
    "\n",
    "    seed : int, default 1234\n",
    "        Seed for the randomly initialized user, item latent factors\n",
    "\n",
    "    verbose : boolean, default True\n",
    "        Whether to print progress bar while training\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    user_factors : 2d numpy array [n_users, n_factors]\n",
    "        User latent factors learnt\n",
    "\n",
    "    item_factors : 2d numpy array [n_items, n_factors]\n",
    "        Item latent factors learnt\n",
    "        \n",
    "    item_bias : 1d numpy array [n_items]\n",
    "        bias term for the items\n",
    "\n",
    "    history : list\n",
    "        Loss function's history, can be used to evaluate\n",
    "        whether the algorithm converged or not\n",
    "\n",
    "    Reference\n",
    "    ---------\n",
    "    S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme \n",
    "    Bayesian Personalized Ranking from Implicit Feedback\n",
    "    - https://arxiv.org/pdf/1205.2618.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate = 0.01, n_factors = 15, n_iters = 10, \n",
    "                 n_batch_size = 2000, reg = 0.01, seed = 1234, verbose = True):\n",
    "        self.reg = reg\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "        self.n_batch_size = n_batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def fit(self, ratings):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix [n_users, n_items]\n",
    "            sparse matrix of user-item interactions\n",
    "        \"\"\"\n",
    "        # history stores the cost, allows assessing convergence\n",
    "        self.history = []\n",
    "        indptr = ratings.indptr\n",
    "        indices = ratings.indices\n",
    "        n_users, n_items = ratings.shape\n",
    "        \n",
    "        # ensure batch size makes sense\n",
    "        batch_size = self.n_batch_size\n",
    "        if ratings.nnz < batch_size:\n",
    "            batch_size = ratings.nnz\n",
    "            sys.stderr.write('WARNING: Batch size is greater than number of training interactions,'\n",
    "                             'switching to a batch size of {}\\n'.format(X.nnz))\n",
    "\n",
    "        batch_iters = ratings.nnz // batch_size\n",
    "        \n",
    "        # progress bar for training iteration if verbose is turned on\n",
    "        loop = range(self.n_iters)\n",
    "        if self.verbose:\n",
    "            loop = trange(self.n_iters, desc = self.__class__.__name__)\n",
    "        \n",
    "        self._build_graph(n_users, n_items)\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "\n",
    "            for _ in loop:\n",
    "                iteration_cost = 0.0\n",
    "                for _ in range(batch_iters):\n",
    "                    sampled = self._sample(n_users, n_items, indices, indptr)\n",
    "                    sampled_users, sampled_pos_items, sampled_neg_items = sampled\n",
    "                    feed_dict = {self._slice_u: sampled_users, \n",
    "                                 self._slice_i: sampled_pos_items, \n",
    "                                 self._slice_j: sampled_neg_items}\n",
    "                    _, cost = sess.run([self._train_step, self._total_cost], feed_dict)\n",
    "                    iteration_cost += cost / self.n_batch_size\n",
    "\n",
    "                iteration_cost /= batch_iters\n",
    "                self.history.append(iteration_cost)\n",
    "\n",
    "            self.user_factors = sess.run(self.user_factors)\n",
    "            self.item_factors = sess.run(self.item_factors)\n",
    "            self.item_bias = sess.run(self.item_bias)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def _sample(self, n_users, n_items, indices, indptr):\n",
    "        \"\"\"sample batches of random triplets u, i, j\"\"\"\n",
    "        sampled_pos_items = np.zeros(self.n_batch_size, dtype = np.int32)\n",
    "        sampled_neg_items = np.zeros(self.n_batch_size, dtype = np.int32)\n",
    "        sampled_users = np.random.choice(n_users, size = self.n_batch_size).astype(np.int32)\n",
    "\n",
    "        for idx, user in enumerate(sampled_users):\n",
    "            pos_items = indices[ indptr[user]:indptr[user + 1] ]\n",
    "            pos_item = np.random.choice(pos_items)\n",
    "            neg_item = np.random.choice(n_items)\n",
    "            while neg_item in pos_items:\n",
    "                neg_item = np.random.choice(n_items)\n",
    "\n",
    "            sampled_pos_items[idx] = pos_item\n",
    "            sampled_neg_items[idx] = neg_item\n",
    "\n",
    "        return sampled_users, sampled_pos_items, sampled_neg_items       \n",
    "    \n",
    "    def _build_graph(self, n_users, n_items):\n",
    "        \"\"\"build the tensorflow computational graph\"\"\"\n",
    "        # initialize random weights\n",
    "        self.user_factors = tf.Variable(tf.truncated_normal((n_users, self.n_factors), seed = self.seed), \n",
    "                                        name = 'user_factors')\n",
    "        self.item_factors = tf.Variable(tf.truncated_normal((n_items, self.n_factors), seed = self.seed), \n",
    "                                        name = 'item_factors')\n",
    "        self.item_bias = tf.Variable(tf.zeros(n_items), name = 'item_bias')\n",
    "\n",
    "        # use tf.gather() to select a non-contiguous slice from the tensor\n",
    "        # http://stackoverflow.com/questions/35146444/tensorflow-python-accessing-individual-elements-in-a-tensor\n",
    "        self._slice_u = tf.placeholder(tf.int32, self.n_batch_size)\n",
    "        self._slice_i = tf.placeholder(tf.int32, self.n_batch_size)\n",
    "        self._slice_j = tf.placeholder(tf.int32, self.n_batch_size)\n",
    "        user_u = tf.gather(self.user_factors, self._slice_u)\n",
    "        item_i = tf.gather(self.item_factors, self._slice_i)\n",
    "        item_j = tf.gather(self.item_factors, self._slice_j)\n",
    "        bias_i = tf.gather(self.item_bias, self._slice_i)\n",
    "        bias_j = tf.gather(self.item_bias, self._slice_j)\n",
    "        \n",
    "        # decompose the estimator, compute the difference between\n",
    "        # the score of the positive items i and negative items j\n",
    "        x_ui = tf.diag_part( tf.matmul(user_u, tf.transpose(item_i)) )\n",
    "        x_uj = tf.diag_part( tf.matmul(user_u, tf.transpose(item_j)) )\n",
    "        x_uij = bias_i - bias_j + x_ui - x_uj\n",
    "\n",
    "        # minimize the cost\n",
    "        cost_u = self.reg * tf.reduce_sum(user_u ** 2)\n",
    "        cost_i = self.reg * tf.reduce_sum(item_i ** 2) + tf.reduce_sum(bias_i ** 2)\n",
    "        cost_j = self.reg * tf.reduce_sum(item_j ** 2) + tf.reduce_sum(bias_j ** 2)\n",
    "        cost_uij = tf.reduce_sum( tf.log(tf.nn.sigmoid(x_uij)) )\n",
    "        self._total_cost = cost_u + cost_i + cost_j - cost_uij\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        self._train_step = optimizer.minimize(self._total_cost)\n",
    "        return self\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Obtain the predicted ratings for every users and items\n",
    "        by doing a dot product of the learnt user and item vectors.\n",
    "        The result will be cached to avoid re-computing \n",
    "        it every time we call predict, thus there will\n",
    "        only be an overhead the first time we call it.\n",
    "        Note, ideally you probably don't need to compute \n",
    "        this as it returns a dense matrix and may take\n",
    "        up huge amounts of memory for large datasets\n",
    "        \"\"\"\n",
    "        if not self._predicted:\n",
    "            self._get_prediction()\n",
    "            self._predicted = True\n",
    "\n",
    "        return self._pred\n",
    "\n",
    "    def _get_prediction(self):\n",
    "        \"\"\"Predicted ratings (dot product of user and item vectors)\"\"\"\n",
    "        self._pred = self.user_factors.dot(self.item_factors.T) + self.item_bias\n",
    "        return self\n",
    "\n",
    "    def _predict_user(self, user):\n",
    "        \"\"\"\n",
    "        returns the predicted ratings for the specified user,\n",
    "        this is mainly used in computing evaluation metric,\n",
    "        where we avoid computing the whole predicted rating matrix\n",
    "        \n",
    "        TODO : do we even need this in the class?\n",
    "        \"\"\"\n",
    "        user_pred = self.user_factors[user].dot(self.item_factors.T) + self.item_bias\n",
    "        return user_pred\n",
    "    \n",
    "    def recommend(self, ratings, N = 5, user_ids = None):\n",
    "        \"\"\"\n",
    "        Returns the top N ranked items for given user id,\n",
    "        excluding the ones that the user already liked\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix [n_users, n_items]\n",
    "            sparse matrix of user-item interactions \n",
    "        \n",
    "        N : int\n",
    "            top-N similar items' N\n",
    "            \n",
    "        user_ids : 1d iterator, e.g. list or numpy array\n",
    "            users' id that we wish to find top-N recommended for\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        recommendation : 2d numpy array [number of query users_ids, N]\n",
    "            each row is the top-N ranked item for each query user\n",
    "        \"\"\"\n",
    "        if user_ids is not None:\n",
    "            recommendation = np.zeros((len(user_ids), N))\n",
    "            for idx, user in enumerate(user_ids):\n",
    "                top_n = self._recommend_user(ratings, user, N)\n",
    "                recommendation[idx] = top_n\n",
    "        else:\n",
    "            n_users = ratings.shape[0]\n",
    "            recommendation = np.zeros((n_users, N))\n",
    "            for user in range(n_users):\n",
    "                top_n = self._recommend_user(ratings, user, N)\n",
    "                recommendation[user] = top_n\n",
    "\n",
    "        return recommendation\n",
    "\n",
    "    def _recommend_user(self, ratings, user, N):\n",
    "        \"\"\"the top-N ranked items for a given user\"\"\"\n",
    "        scores = self._predict_user(user)\n",
    "\n",
    "        # compute the top N items, removing the items that the user already liked\n",
    "        # from the result and ensure that we don't get out of bounds error when \n",
    "        # we ask for more recommendations than that are available\n",
    "        liked = set(ratings[user].indices)\n",
    "        count = N + len(liked)\n",
    "        if count < scores.shape[0]:\n",
    "\n",
    "            # when trying to obtain the top-N indices from the score,\n",
    "            # using argpartition to retrieve the top-N indices in \n",
    "            # unsorted order and then sort them will be faster than doing\n",
    "            # straight up argort on the entire score\n",
    "            # http://stackoverflow.com/questions/42184499/cannot-understand-numpy-argpartition-output\n",
    "            ids = np.argpartition(scores, -count)[-count:]\n",
    "            best_ids = np.argsort(scores[ids])[::-1]\n",
    "            best = ids[best_ids]\n",
    "        else:\n",
    "            best = np.argsort(scores)[::-1]\n",
    "\n",
    "        top_n = list( islice((rec for rec in best if rec not in liked), N) )\n",
    "        return top_n\n",
    "    \n",
    "    def get_similar_items(self, N = 5, item_ids = None):\n",
    "        \"\"\"\n",
    "        return the top N similar items for itemid, where\n",
    "        cosine distance is used as the distance metric\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        N : int\n",
    "            top-N similar items' N\n",
    "            \n",
    "        item_ids : 1d iterator, e.g. list or numpy array\n",
    "            the item ids that we wish to find the similar items\n",
    "            of, the default None will compute the similar items\n",
    "            for all the items\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        similar_items : 2d numpy array [number of query item_ids, N]\n",
    "            each row is the top-N most similar item id for each\n",
    "            query item id\n",
    "        \"\"\"\n",
    "        # cosine distance is proportional to normalized euclidean distance,\n",
    "        # thus we normalize the item vectors and use euclidean metric so\n",
    "        # we can use the more efficient kd-tree for nearest neighbor search;\n",
    "        # also the item will always to nearest to itself, so we add 1 to \n",
    "        # get an additional nearest item and remove itself at the end\n",
    "        normed_item_factors = normalize(self.item_factors)\n",
    "        knn = NearestNeighbors(n_neighbors = N + 1, metric = 'euclidean')\n",
    "        knn.fit(normed_item_factors)\n",
    "\n",
    "        # returns a distance, index tuple,\n",
    "        # we don't actually need the distance\n",
    "        if item_ids is not None:\n",
    "            normed_item_factors = normed_item_factors[item_ids]\n",
    "\n",
    "        _, items = knn.kneighbors(normed_item_factors)\n",
    "        similar_items = items[:, 1:]\n",
    "        return similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorflowBPR: 100%|██████████| 10/10 [00:30<00:00,  2.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TensorflowBPR at 0x106e01080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_params = {\n",
    "    'n_factors': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_iters': 10,\n",
    "    'reg': 0.01,\n",
    "    'n_batch_size': 2000 \n",
    "}\n",
    "\n",
    "tf_bpr = TensorflowBPR(**bpr_params)\n",
    "tf_bpr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auc_score(model, ratings):\n",
    "    auc = 0.0\n",
    "    n_users, n_items = ratings.shape\n",
    "    for user, row in enumerate(ratings):\n",
    "        y_pred = model._predict_user(user)\n",
    "        y_true = np.zeros(n_items, dtype = np.int32)\n",
    "        y_true[row.indices] = 1\n",
    "        auc += roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    auc /= n_users\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946753849062\n",
      "0.898517343117\n"
     ]
    }
   ],
   "source": [
    "print(auc_score(tf_bpr, train))\n",
    "print(auc_score(tf_bpr, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAGDCAYAAACC+tIOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbIiIiEhGKWyIiIhIRv1/Nx5BrShyu9IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f788240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 6, 4\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "plt.plot(tf_bpr.history)\n",
    "plt.title('Convergence Plot')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-764efa883dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hi' is not defined"
     ]
    }
   ],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_factors = 10\n",
    "n_users, n_items = train.shape\n",
    "reg = 0.25\n",
    "\n",
    "n_iters = 10\n",
    "n_batch_size = 2000 # should be smaller than train.nnz\n",
    "seed = 1234\n",
    "learning_rate = 0.05\n",
    "n_iters = 10\n",
    "batch_iters = train.nnz // n_batch_size"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
