{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Advice\n",
    "\n",
    "- How can we update/store the model for updating when new users/new items/ new interactions come in?\n",
    "    - The most robust answer is that you periodically recompute the model from scratch to handle all three. For just new interactions, you can run additional fitting iterations on the same model with the new data. (You can persist the model by pickling it.) Adding new users/items (this is called fold-in) is somewhat tricky, and not explicitly supported. For models that naturally take in new information (and new users), you should have a look at [sequence-based models](https://maciejkula.github.io/spotlight/index.html#sequential-models)\n",
    "- Getting similar items\n",
    "    - https://github.com/lyst/lightfm/issues/244\n",
    "- bdicts library to convert UUIDs to 32 bit ints for recommender libraries\n",
    "    - https://stackoverflow.com/questions/48068147/recommender-systems-convert-uuids-to-32-bit-ints-for-recommender-libraries\n",
    "- Evaluation:\n",
    "    - The scores themselves have no meaning in isolation; they are only meaningful because they define a ranking over items for a given user. The scale they take depends on the loss you specify, the learning rate, the regularization parameters, and the data itself. I recommend keeping an eye on the MRR/AUC scores of your model, and comparing them with what a random or a popularity model would achieve.\n",
    "- Mini-Batch Training for large dataset:\n",
    "    - https://github.com/lyst/lightfm/issues/234\n",
    "- Item-Item Recommendation ???\n",
    "    - https://github.com/lyst/lightfm/issues/239#issuecomment-352774493\n",
    "- Sample weight for different interactions\n",
    "    - https://github.com/lyst/lightfm/issues/260\n",
    "- Handling non-categorical features\n",
    "    - https://github.com/lyst/lightfm/issues/261\n",
    "- Explaining Recommendation\n",
    "    - try using item similarity to do that present support for your recommendations. For example, you could use cosine similarity between the embedding of the item you are recommending and items that the user has interacted with in the past to find items from the user's history that are most similar to the recommendation you are making.\n",
    "    - https://github.com/lyst/lightfm/issues/251#issuecomment-363314396\n",
    "- One interesting characteristic of WARP is that it is effectively playing against itself: it is preferentially using examples that it scores highly as negative examples. Up to a certain point, this allows it to express user preferences better; beyond that point, it is self-defeating, as it is selecting the examples that it should recommend and treating them as negatives. The extent to which that happens is governed by the max_sampled hyperparameter. I suspect that this is what happening in your case. Instead of switching to BPR, can you try decreasing that hyperparameter? Otherwise, I don't see any obvious problems with switching losses. It's interesting that you find different results with adagrad and adadelta, I haven't observed that.\n",
    "    - https://github.com/lyst/lightfm/issues/258#issuecomment-363313831\n",
    "- Use sample weight to incorporate multiple feedbacks\n",
    "    - https://github.com/lyst/lightfm/issues/258#issuecomment-363313831\n",
    "- Contextual-Awareness: If you want to have contextual features (time-varying, or specific to a given interaction instance), you could integrate them in either user or item features. This way you would have more than one features row for a given user or item. For example, instead of having one row for item 10: {'id': 10, 'category': 'foo'} you could have two rows: {'id': 10, 'category': 'foo', 'time-of-week': 'friday'} and {'id': 10, 'category': 'foo', 'time-of-week': 'tuesday'}. With a little ingenuity in feature engineering you can make the model very flexible.\n",
    "    - https://github.com/lyst/lightfm/issues/238#issuecomment-352774054\n",
    "- To incorporate numerical side features, we may find that discretization works better.\n",
    "    - https://github.com/lyst/lightfm/issues/261\n",
    "- Using predict with feature matrix\n",
    "    - https://github.com/lyst/lightfm/issues/240\n",
    "- Get item recommendation for a particular user on a particular item page\n",
    "    - https://github.com/lyst/lightfm/issues/266#issuecomment-378243505"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
