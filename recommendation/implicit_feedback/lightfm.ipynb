{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Advice\n",
    "\n",
    "- How can we update/store the model for updating when new users/new items/ new interactions come in?\n",
    "    - The most robust answer is that you periodically recompute the model from scratch to handle all three. For just new interactions, you can run additional fitting iterations on the same model with the new data. (You can persist the model by pickling it.) Adding new users/items (this is called fold-in) is somewhat tricky, and not explicitly supported. For models that naturally take in new information (and new users), you should have a look at [sequence-based models](https://maciejkula.github.io/spotlight/index.html#sequential-models)\n",
    "- Getting similar items\n",
    "    - https://github.com/lyst/lightfm/issues/244\n",
    "- bdicts library to convert UUIDs to 32 bit ints for recommender libraries\n",
    "    - https://stackoverflow.com/questions/48068147/recommender-systems-convert-uuids-to-32-bit-ints-for-recommender-libraries\n",
    "- Evaluation:\n",
    "    - The scores themselves have no meaning in isolation; they are only meaningful because they define a ranking over items for a given user. The scale they take depends on the loss you specify, the learning rate, the regularization parameters, and the data itself. I recommend keeping an eye on the MRR/AUC scores of your model, and comparing them with what a random or a popularity model would achieve.\n",
    "- Mini-Batch Training for large dataset:\n",
    "    - https://github.com/lyst/lightfm/issues/234\n",
    "- Item-Item Recommendation ???\n",
    "    - https://github.com/lyst/lightfm/issues/239#issuecomment-352774493\n",
    "- Sample weight for different interactions\n",
    "    - https://github.com/lyst/lightfm/issues/260\n",
    "- Handling non-categorical features\n",
    "    - https://github.com/lyst/lightfm/issues/261\n",
    "- Explaining Recommendation\n",
    "    - try using item similarity to do that present support for your recommendations. For example, you could use cosine similarity between the embedding of the item you are recommending and items that the user has interacted with in the past to find items from the user's history that are most similar to the recommendation you are making.\n",
    "    - https://github.com/lyst/lightfm/issues/251#issuecomment-363314396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethen/lightfm/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lightfm.datasets import fetch_movielens\n",
    "\n",
    "movielens = fetch_movielens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = movielens['train']\n",
    "test = movielens['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 9430 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4169018268585205\n",
      "Precision: train 0.62, test 0.09.\n",
      "AUC: train 0.92, test 0.87.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "model = LightFM(learning_rate=0.05, loss='bpr')\n",
    "\n",
    "start = time()\n",
    "model.fit(train, epochs=50)\n",
    "print(time() - start)\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?model.predict_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = model.predict_rank(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 438.,  324.,  337.,   82.,  177.,  288.,  191.,  166.,   22.,   46.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.286494016647339\n",
      "Precision: train 0.65, test 0.11.\n",
      "AUC: train 0.95, test 0.91.\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "\n",
    "start = time()\n",
    "model.fit_partial(train, epochs=50)\n",
    "print(time() - start)\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
