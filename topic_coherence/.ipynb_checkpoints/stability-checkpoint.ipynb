{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('http://fonts.googleapis.com/css?family=Source+Code+Pro');\n",
       "@import url('http://fonts.googleapis.com/css?family=Vollkorn');\n",
       "@import url('http://fonts.googleapis.com/css?family=Arimo');\n",
       "@import url('http://fonts.googleapis.com/css?family=Fira_sans');\n",
       "    \n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "    div.text_cell code {\n",
       "        background: transparent;\n",
       "        color: #000000;\n",
       "        font-weight: 600;\n",
       "        font-size: 12pt;\n",
       "        font-style: bold;\n",
       "        font-family:  'Source Code Pro', Consolas, monocco, monospace;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "\t}\n",
       "\t\n",
       "    div.input_area {\n",
       "        background: #F6F6F9;\n",
       "        border: 1px solid #586e75;\n",
       "    }\n",
       "\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 30pt;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h2 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "        text-align: left;\n",
       "    }\n",
       "    .text_cell_render h2 {\n",
       "        font-weight: 200;\n",
       "        font-size: 16pt;\n",
       "        font-style: italic;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1.5em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h3 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h3 {\n",
       "        font-weight: 200;\n",
       "        font-size: 14pt;\n",
       "        line-height: 100%;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 2em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    }\n",
       "    h4 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h4 {\n",
       "        font-weight: 100;\n",
       "        font-size: 14pt;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    h5 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 200;\n",
       "        font-style: normal;\n",
       "        color: #1d3b84;\n",
       "        font-size: 16pt;\n",
       "        margin-bottom: 0em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: 'Fira sans', verdana,arial,sans-serif;\n",
       "        line-height: 125%;\n",
       "        font-size: 115%;\n",
       "        text-align:justify;\n",
       "        text-justify:inter-word;\n",
       "    }\n",
       "    div.output_wrapper{\n",
       "        margin-top:0.2em;\n",
       "        margin-bottom:0.2em;\n",
       "    }\n",
       "\n",
       "    code{\n",
       "      font-size: 70%;\n",
       "    }\n",
       "    .rendered_html code{\n",
       "    background-color: transparent;\n",
       "    }\n",
       "    ul{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li li{\n",
       "        padding-left: 0.2em; \n",
       "        margin-bottom: 0.2em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    ol{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ol li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "    .rendered_html :hover {\n",
       "       text-decoration: none; \n",
       "    }\n",
       "    .rendered_html :visited {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :focus {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :active {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "    } \n",
       "    hr {\n",
       "      color: #f3f3f3;\n",
       "      background-color: #f3f3f3;\n",
       "      height: 1px;\n",
       "    }\n",
       "    blockquote{\n",
       "      display:block;\n",
       "      background: #fcfcfc;\n",
       "      border-left: 5px solid #c76c0c;\n",
       "      font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "      width:680px;\n",
       "      padding: 10px 10px 10px 10px;\n",
       "      text-align:justify;\n",
       "      text-justify:inter-word;\n",
       "      }\n",
       "      blockquote p {\n",
       "        margin-bottom: 0;\n",
       "        line-height: 125%;\n",
       "        font-size: 100%;\n",
       "      }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir( os.path.join('..', 'notebook_format') )\n",
    "from formats import load_style\n",
    "load_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2016-11-11 13:40:42 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.11.2\n",
      "pandas 0.18.1\n",
      "matplotlib 1.5.1\n",
      "gensim 0.13.1\n",
      "scikit-learn 0.18\n",
      "scipy 0.18.1\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 8, 6 # change default figure size\n",
    "plt.rcParams['font.size'] = 12 # and font size\n",
    "\n",
    "# 1. magic to print version\n",
    "# 2. magic so that the notebook will reload external python modules\n",
    "%load_ext watermark\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,matplotlib,gensim,scikit-learn,scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability Analysis for Topic Models\n",
    "\n",
    "This documentation aims to reproduce the methodology from the paper [How Many Topics? Stability Analysis for Topic Models (2014) Derek Greene, Derek O'Callaghan, Pádraig Cunningham](https://arxiv.org/abs/1404.4606). In the paper, they proposed a topic stability method that tries to address the issue of choosing an appropriate topic number for a given corpus.\n",
    "\n",
    "## Quick Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recent scikit-learn are raising deprecation warnings that\n",
    "# default value for 'learning_method' will be changed \n",
    "# from 'online' to 'batch'; we won't worry about it\n",
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning) \n",
    "\n",
    "texts = ['human interface computer',\n",
    "         'survey user computer system response time',\n",
    "         'eps user interface system',\n",
    "         'system human system eps',\n",
    "         'user response time',\n",
    "         'trees',\n",
    "         'graph trees',\n",
    "         'graph minors trees',\n",
    "         'graph minors survey']\n",
    "\n",
    "\n",
    "# convert to document-term matrix and train the lda model\n",
    "vec = CountVectorizer(ngram_range = (1, 2), stop_words = 'english', \n",
    "                      min_df = 2, max_df = 0.85, max_features = 10000)\n",
    "X_dtm = vec.fit_transform(texts)\n",
    "\n",
    "# train LDA\n",
    "lda = LatentDirichletAllocation(n_topics = 2, max_iter = 25, \n",
    "                                n_jobs = -1, evaluate_every = 5)\n",
    "doc_topic_distr = lda.fit_transform(X_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "graph, graph minors, minors, trees, survey, human, eps, time, computer, interface, response time, response, user\n",
      "\n",
      "Topic #1:\n",
      "response, time, computer, response time, interface, human, eps, user, survey, minors, graph minors, trees, graph\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(lda_model, vec, n_top_words):\n",
    "    \"\"\"top words associated with each topic for the sklearn LDA model\"\"\"\n",
    "    features = vec.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        print( 'Topic #{}:'.format(topic_idx) )\n",
    "        print( ', '.join([ features[i] for i in np.argsort(topic)[-n_top_words:] ]) )\n",
    "        print()\n",
    "    \n",
    "    print()\n",
    "\n",
    "N_TOPWORDS = 15\n",
    "print_top_words(lda_model = lda, vec = vec, n_top_words = N_TOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Ranking Similarity\n",
    "\n",
    "Before getting into topic stability, we will need to have two basic ideas in mind:\n",
    "\n",
    "- The stability of clustering model refers to its ability to consistently generate similar results when applying the same algorithm to the same data source.\n",
    "- One common output that a topic model reports is the top terms (in the paper, they refer to it as a **ranked list**, hence we'll use top terms and ranked list interchangeably) associated with each topics.\n",
    "\n",
    "Given these two piece of information, the idea behind topic stability is that we compare the similarity of the topic terms between different runs of the topic model to determine whether it is stable or not.\n",
    "\n",
    "To formalize it a bit, the output of a topic modeling algorithm is in the form of a ranking set containing $k$ ranked lists, denoted $S = \\{R_1,...,R_k\\}$. The $i_{th}$ topic produced by the algorithm is represented by the list $R_i$ ($k$ is simply the topic number that we specified, in the sklearn API, this is `n_topics`), containing the top $t$ terms which are most representative of that topic. Usually $t$ is within the range of 10 to 20.\n",
    "\n",
    "Now that we've obtained the ranked list, a naive approach to assess the similarity between a pair of ranked lists $R_i, R_j$ would be to employ a simple similarity such as the **Jaccard similarity**. \n",
    "\n",
    "However, such measures do not take into account positional information, that is terms occurring at the top of a ranked list generated by a topic model algorithm such as LDA will naturally be more relevant to a topic than those occurring at the tail of the list. Also, in practice, rather than considering all $m$ terms in a corpus, it may be preferable to use only the top $t << m$ terms to represent the ranked list.\n",
    "\n",
    "Therefore, we instead use of a weighted version of the Jaccard index, suitable for calculating the similarity between pairs of indefinite rankings. Specifically, we define the **Average Jaccard (AJ)** measure as follows. We calculate the average of the Jaccard scores between every pair of subsets of d top-ranked terms in two lists, for depth $d \\in [1, t]$. That is:\n",
    "\n",
    "\\begin{equation} \n",
    "AJ(R_i, R_j) = \\frac{1}{t} \\sum_{d = 1}^t \\gamma_d (R_i, R_j)\n",
    "\\end{equation}\n",
    "\n",
    "Where:\n",
    "\n",
    "\\begin{equation}\n",
    "\\gamma_d (R_i, R_j) = \\frac{ \\rvert R_{i, d} \\cap R_{j, d} \\rvert }{ \\rvert R_{i, d} \\cup R_{j, d} \\rvert }\n",
    "\\end{equation}\n",
    "\n",
    "such that $R_{i,d}$ is the head of list $R_i$ up to depth $d$. This is a symmetric measure producing values in the range [0,1], where the terms in the ranked list are weighted according to a decreasing linear scale. To demonstrate this, a simple illustrative example is shown below.\n",
    "\n",
    "<img src=\"img/jaccard.png\" height=\"70%\" width=\"70%\">\n",
    "\n",
    "Note that, although the Jaccard score at depth $d = 5$ is comparatively high (0.429), the Average Jaccard score is much lower (0.154), as the similarity between terms occurs towards the tails of the lists – these terms carry less weight than those at the head of the lists, such as \"album\" and \"sport\".\n",
    "\n",
    "The following code chunk reproduces the results from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R1 = [\n",
    "    ['album'],\n",
    "    ['album', 'music'],\n",
    "    ['album', 'music', 'best'],\n",
    "    ['album', 'music', 'best', 'award'],\n",
    "    ['album', 'music', 'best', 'award', 'win']\n",
    "]\n",
    "\n",
    "R2 = [\n",
    "    ['sport'],\n",
    "    ['sport', 'best'],\n",
    "    ['sport', 'best', 'win'],\n",
    "    ['sport', 'best', 'win', 'medal'],\n",
    "    ['sport', 'best', 'win', 'medal', 'award']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_jaccard(ranking1, ranking2):\n",
    "    \"\"\"\n",
    "    compute jaccard similarity that does not take into account \n",
    "    rank positions and indefinite list\n",
    "    \"\"\"\n",
    "    set1 = set(ranking1)\n",
    "    set2 = set(ranking2)\n",
    "    \n",
    "    # if the numerator turned out to be 0, \n",
    "    # return 0 as the jaccard similarity\n",
    "    numerator = len( set1.intersection(set2) )\n",
    "    if not numerator:\n",
    "        return 0\n",
    "\n",
    "    denominator = len( set1.union(set2) )\n",
    "    jaccard_sim = numerator / denominator\n",
    "    return jaccard_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_avg_jaccard(ranking1, ranking2):\n",
    "    \"\"\"\n",
    "    weighted version of jaccard similarity, \n",
    "    which takes into account rank positions\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    k = len(ranking1)\n",
    "    for i in range(1, k + 1):\n",
    "        total += compute_jaccard( ranking1[:i], ranking2[:i] )\n",
    "        \n",
    "    avg_jaccard_sim = total / k\n",
    "    return avg_jaccard_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard: 0.42857142857142855\n",
      "average jaccard: 0.15428571428571428\n"
     ]
    }
   ],
   "source": [
    "# test it for the final depth\n",
    "ranking1 = R1[4]\n",
    "ranking2 = R2[4]\n",
    "jaccard = compute_jaccard(ranking1, ranking2)\n",
    "avg_jaccard = compute_avg_jaccard(ranking1, ranking2)\n",
    "print('jaccard:', jaccard)\n",
    "print('average jaccard:', avg_jaccard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model Agreement\n",
    "\n",
    "Now that we have a similarity metric for the top-terms, we move on to the problem of measuring the agreement between two different $k$-way topic models, represented as two ranking sets $S_x = \\{ R_{x1}, ..., R_{xk} \\}$ and $S_y = \\{ R_{y1}, ..., R_{yk} \\}$, both containing $k$ ranked lists. We construct a $k × k$ similarity matrix $M$, such that the entry $M_{ij}$ indicates the agreement between $R_{xi}$ and $R_{yj}$ (i.e. the i-th topic in the first model and the j-th topic in the second model), as calculated using the Average Jaccard score. We then find the best match between the rows and columns of $M$ (pairs that have the highest similarity between the two ranked set), or so called the optimal permutation, denoted as $\\pi$. From this we can product an agreement score:\n",
    "\n",
    "\\begin{equation}\n",
    "agree(S_x, S_y) = \\frac{1}{k} \\sum_{i = 1}^k AJ \\big( R_{xi}, \\pi(R_{xi}) \\big)\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\pi(R_{xi})$ denotes the ranked list in $S_y$ matched to $R_{xi}$ by the permutation $\\pi$. Hungarian method is to find the optimal permutation, details of this method is included in the appendix.\n",
    "\n",
    "A simple example illustrating the agreement process is shown below Fig. 1.\n",
    "\n",
    "<img src=\"img/agreement.png\" height=\"70%\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare between two ranking the set\n",
    "# where the length of the set is simply\n",
    "# the number of topics in each topic model\n",
    "S1 = [\n",
    "    ['sport', 'win', 'award'],\n",
    "    ['bank', 'finance', 'money'],\n",
    "    ['music', 'album', 'band']\n",
    "]\n",
    "\n",
    "S2 = [\n",
    "    ['finance', 'bank', 'economy'],\n",
    "    ['music', 'band', 'award'],\n",
    "    ['win', 'sport', 'money']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.06666667,  0.5       ],\n",
       "       [ 0.5       ,  0.        ,  0.06666667],\n",
       "       [ 0.        ,  0.61111111,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproduce the similarity matrix\n",
    "n_topic = len(S1)\n",
    "sim_mat = np.zeros(( n_topic, n_topic ))\n",
    "for row in range(n_topic):  \n",
    "    for col in range(n_topic):\n",
    "        sim_mat[row, col] = compute_avg_jaccard(S1[row], S2[col])\n",
    "\n",
    "sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53703703703703709"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solve for the optimal permutation using hungarian algorithm,\n",
    "# for the scipy implementation, each element is presented as cost\n",
    "# hence we take the negative sign of the similarity matrix\n",
    "row_ind, col_ind = linear_sum_assignment(-sim_mat)\n",
    "agreement = np.mean( sim_mat[row_ind, col_ind] )\n",
    "agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simply wrapping all of it in one function\n",
    "def compute_agreement(S1, S2):\n",
    "    \"\"\"\n",
    "    measuring the agreement between two different \n",
    "    k-way topic models, represented as two rank sets;\n",
    "    the rank set is simply the top words for each topic\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the similarity matrix\n",
    "    n_topic = len(S1)\n",
    "    sim_mat = np.zeros(( n_topic, n_topic ))\n",
    "    for row in range(n_topic):\n",
    "        for col in range(n_topic):\n",
    "            sim_mat[row, col] = compute_avg_jaccard(S1[row], S2[col])    \n",
    "    \n",
    "    # solve for the optimal permutation using hungarian algorithm,\n",
    "    # for the scipy implementation, each element is presented as cost\n",
    "    # hence we use the negative sign of the similarity matrix as input\n",
    "    row_ind, col_ind = linear_sum_assignment(-sim_mat)\n",
    "    agreement = np.mean( sim_mat[row_ind, col_ind] )\n",
    "    return agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53703703703703709"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement = compute_agreement(S1, S2)\n",
    "agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the Number of Topics\n",
    "\n",
    "Building on top of the agreement score, the topic number selction process is defined as follows:\n",
    "\n",
    "- Randomly generate $\\gamma$ samples of the full corpus, each containing $\\beta \\times n$ documents. $n$ denotes the total number of documents, and $\\beta$ is $0 < \\beta < 1$ denotes the sampling ratio controlling the number of documents in each sample.\n",
    "- For each value of $k \\in [kmin, kmax]$ (a defined range of topic numbers to search for):\n",
    "    - Apply the topic modeling algorithm to the complete data set of $n$ documents to generate $k$ topics, and represent the output as the reference ranking set $S_0$.\n",
    "    - For each sample $\\gamma$:\n",
    "        - Apply the topic modeling algorithm to it to generate $k$ topics, and represent the output as the ranking set $S_i$. \n",
    "        - Calculate the agreement score agree ($S_0$, $S_i$).\n",
    "    - Compute the mean agreement score for $k$ over all $\\gamma$ samples. This measure is the overall topic stability at $k$ topics.\n",
    "    \n",
    "After going through the whole process, we can examine the plot of the stability scores ranging from $[kmin, kmax]$ and the optimal value for $k$ may be identified based on peaks in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_all = fetch_20newsgroups(subset = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(newsgroups_all.data)\n",
    "n_top_words = 20\n",
    "n_topics_range = [2, 10, 20, 30]\n",
    "n_sample_frac = 0.8\n",
    "n_sample_time = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethen/anaconda/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/ethen/anaconda/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/ethen/anaconda/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/ethen/anaconda/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from topic_stability import TopicStability\n",
    "\n",
    "ts = TopicStability(\n",
    "    vec = vec, \n",
    "    lda_model = lda, \n",
    "    n_top_words = n_top_words, \n",
    "    n_topics_range = n_topics_range, \n",
    "    n_sample_frac = n_sample_frac, \n",
    "    n_sample_time = n_sample_time\n",
    ")\n",
    "ts.fit(X)\n",
    "print('best number of topic:', ts.best_n_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(n_topics_range, avg_agreements)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure( figsize = (10, 6) )\n",
    "\n",
    "# for acessing the color cycle\n",
    "# http://stackoverflow.com/questions/34247297/matplotlib-1-5-usage-of-axes-prop-cycle\n",
    "colors = list(plt.rcParams['axes.prop_cycle'])\n",
    "\n",
    "for k in range( len(n_topics_range) ):    \n",
    "    plt.subplot(2, 2, k + 1)\n",
    "    prob = max_probs[k]\n",
    "    mean_prob = np.round( np.mean(prob), 2 )\n",
    "    plt.hist( prob, histtype = 'stepfilled', alpha = 0.85, \n",
    "              color = colors[k]['color'], bins = 30 )\n",
    "    plt.title( '{} topics, mean prob of {}'.format( n_topics_range[k], mean_prob ) )\n",
    "    plt.axvline(x = 0.5, color = \"black\", linestyle = '--')\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [How Many Topics? Stability Analysis for Topic Models (2014) Derek Greene, Derek O'Callaghan, Pádraig Cunningham](https://arxiv.org/abs/1404.4606)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
