{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2017-12-26 10:42:36 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.13.3\n",
      "pandas 0.21.1\n",
      "sklearn 0.19.1\n",
      "matplotlib 2.1.0\n"
     ]
    }
   ],
   "source": [
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# change default style figure and font size\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['font.size'] = 12\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,sklearn,matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have these constraints, do not use Bayesian optimization.\n",
    "\n",
    "- f is a black box function, with no closed form nor gradients.\n",
    "- f is expensive to evaluate.\n",
    "- You only have noisy observations of f.\n",
    "\n",
    "Bayesian optimization in layman terms: We evaluate a few points and fit a regression model to it. After fitting this regression model, we can use it to predict where the minimum. Finally, we go to that point and evaluate our function. We can repeat the steps we just mentioned until we run out of budget.\n",
    "\n",
    "tree-based models for high dimension??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key problems with black box optimization is that we can never know with 100% certainty what our function’s best input is; to do so would mean testing an often-infinite number of input values. This means we have to draw the line somewhere, since we can’t test an infinite number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val score: 0.929472902747\n",
      "test score: 0.944444444444\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html\n",
    "X, y = load_digits(n_class = 10, return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "def report(results):\n",
    "    \"\"\"report best scores and corresponding parameters\"\"\"\n",
    "    print('Best score obtained: {0}'.format(results.best_score_))\n",
    "    print('Parameters:')\n",
    "    for param, value in results.best_params_.items():\n",
    "        print('\\t{}: {}'.format(param, value))\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "rf = RandomForestClassifier()\n",
    "search_spaces = {'max_depth': Integer(3, 15)}\n",
    "# Real(1e-6, 1e+6, prior = 'log-uniform')\n",
    "# Categorical(['linear', 'poly', 'rbf'])\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator = rf,\n",
    "    search_spaces = search_spaces,\n",
    "    cv = 5,\n",
    "    n_iter = 3,\n",
    "    return_train_score = False)\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"val score: %s\" % bayes_search.best_score_)\n",
    "print(\"test score: %s\" % bayes_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 13}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dark-element.com/2016/10/10/bayesian-optimization-of-black-box-functions/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
