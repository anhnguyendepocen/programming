{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "data_dir = os.path.join(gensim.__path__[0], 'test', 'test_data')\n",
    "train_file_path = os.path.join(data_dir, 'lee_background.cor')\n",
    "test_file_path = os.path.join(data_dir, 'lee.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  4.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedLineDocument\n",
    "\n",
    "# each line is a single document\n",
    "train_corpus = TaggedLineDocument(train_file_path)\n",
    "\n",
    "model = Doc2Vec(min_count = 2, size = 100, workers = 7)\n",
    "model.build_vocab(train_corpus)\n",
    "for _ in trange(8):\n",
    "    model.train(train_corpus)\n",
    "    model.alpha -= 0.002  # decrease the learning rate\n",
    "    model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "    \n",
    "# If you’re finished training a model (=no more updates, only querying), you can do\n",
    "# to trim unneeded model memory\n",
    "# model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 292, 1: 8})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "ranks = []\n",
    "for idx, doc in enumerate(train_corpus):\n",
    "    # each line is a TaggedDocument namedtuple, where we can\n",
    "    # access the words attribute and infer their word vectors\n",
    "    inferred_vector = model.infer_vector(doc.words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn = model.corpus_count)\n",
    "    rank = [doc_id for doc_id, _ in sims].index(idx)\n",
    "    ranks.append(rank)\n",
    "\n",
    "Counter(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.58224672, -0.43096396, -0.33039987, -0.06532005,  0.47400451,\n",
       "       -0.48527843,  0.01416627, -0.2556819 ,  0.56022859,  0.05959554,\n",
       "       -0.75745648,  0.81947565, -0.0115818 , -0.21682028,  0.94731522,\n",
       "       -0.40724245,  0.40448874, -0.54299033,  0.05646265, -0.55159432,\n",
       "        0.34756666, -0.891092  ,  0.41050884,  0.19965491,  0.51197499,\n",
       "        0.76365852, -0.42333227, -0.02293444,  0.06794542,  1.10781157,\n",
       "        0.07878274,  0.09709717,  1.52739763,  1.52857971,  0.63935286,\n",
       "        0.67650592, -0.30052426,  0.44312361, -1.32764304, -0.34013611,\n",
       "       -0.75963336, -0.09873898, -0.78795689,  0.2531268 ,  0.15569344,\n",
       "        0.29239166,  0.16786104, -0.95119458,  1.06164527, -0.52167094,\n",
       "        0.22298038,  0.4879244 , -0.73503453, -0.3620781 , -0.82793939,\n",
       "       -0.43032843,  0.34696817,  0.46614733, -0.31515405,  0.1487086 ,\n",
       "       -0.72470874,  0.60460603,  0.20055507,  1.0842762 , -0.05671849,\n",
       "        0.67490703,  0.47700262,  0.22134401, -0.21704741,  0.12069666,\n",
       "        0.7789551 ,  0.84724051, -0.47805002, -0.57244855, -0.0701121 ,\n",
       "        0.39550227, -0.28872105,  0.2459404 , -0.36851695,  0.27095425,\n",
       "        0.10138271,  1.01849067, -1.12886369, -1.30282986,  0.54146743,\n",
       "       -0.37611789, -0.10779613,  0.60773498, -0.01325577, -0.62523186,\n",
       "       -0.00694705, -0.23154826,  0.00494381, -0.71651679,  0.679856  ,\n",
       "       -0.04138361, -0.21533759, -0.8604064 ,  0.26367924,  0.96913493], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(file_path, tag = True):\n",
    "    \"\"\"For training data, add tags\"\"\"\n",
    "    with open(file_path, encoding = 'iso-8859-1') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # simple_preprocess\n",
    "            # tokenize text into individual words, \n",
    "            # remove punctuation, set to lowercase\n",
    "            preprocessed = simple_preprocess(line)\n",
    "            if tag:\n",
    "                yield TaggedDocument(preprocessed, [i])\n",
    "            else:\n",
    "                yield preprocessed\n",
    "                \n",
    "train_corpus = list(read_corpus(train_file_path))\n",
    "test_corpus = list(read_corpus(test_file_path, tag = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['hundreds', 'of', 'people', 'have', 'been', 'forced', 'to', 'vacate', 'their', 'homes', 'in', 'the', 'southern', 'highlands', 'of', 'new', 'south', 'wales', 'as', 'strong', 'winds', 'today', 'pushed', 'huge', 'bushfire', 'towards', 'the', 'town', 'of', 'hill', 'top', 'new', 'blaze', 'near', 'goulburn', 'south', 'west', 'of', 'sydney', 'has', 'forced', 'the', 'closure', 'of', 'the', 'hume', 'highway', 'at', 'about', 'pm', 'aedt', 'marked', 'deterioration', 'in', 'the', 'weather', 'as', 'storm', 'cell', 'moved', 'east', 'across', 'the', 'blue', 'mountains', 'forced', 'authorities', 'to', 'make', 'decision', 'to', 'evacuate', 'people', 'from', 'homes', 'in', 'outlying', 'streets', 'at', 'hill', 'top', 'in', 'the', 'new', 'south', 'wales', 'southern', 'highlands', 'an', 'estimated', 'residents', 'have', 'left', 'their', 'homes', 'for', 'nearby', 'mittagong', 'the', 'new', 'south', 'wales', 'rural', 'fire', 'service', 'says', 'the', 'weather', 'conditions', 'which', 'caused', 'the', 'fire', 'to', 'burn', 'in', 'finger', 'formation', 'have', 'now', 'eased', 'and', 'about', 'fire', 'units', 'in', 'and', 'around', 'hill', 'top', 'are', 'optimistic', 'of', 'defending', 'all', 'properties', 'as', 'more', 'than', 'blazes', 'burn', 'on', 'new', 'year', 'eve', 'in', 'new', 'south', 'wales', 'fire', 'crews', 'have', 'been', 'called', 'to', 'new', 'fire', 'at', 'gunning', 'south', 'of', 'goulburn', 'while', 'few', 'details', 'are', 'available', 'at', 'this', 'stage', 'fire', 'authorities', 'says', 'it', 'has', 'closed', 'the', 'hume', 'highway', 'in', 'both', 'directions', 'meanwhile', 'new', 'fire', 'in', 'sydney', 'west', 'is', 'no', 'longer', 'threatening', 'properties', 'in', 'the', 'cranebrook', 'area', 'rain', 'has', 'fallen', 'in', 'some', 'parts', 'of', 'the', 'illawarra', 'sydney', 'the', 'hunter', 'valley', 'and', 'the', 'north', 'coast', 'but', 'the', 'bureau', 'of', 'meteorology', 'claire', 'richards', 'says', 'the', 'rain', 'has', 'done', 'little', 'to', 'ease', 'any', 'of', 'the', 'hundred', 'fires', 'still', 'burning', 'across', 'the', 'state', 'the', 'falls', 'have', 'been', 'quite', 'isolated', 'in', 'those', 'areas', 'and', 'generally', 'the', 'falls', 'have', 'been', 'less', 'than', 'about', 'five', 'millimetres', 'she', 'said', 'in', 'some', 'places', 'really', 'not', 'significant', 'at', 'all', 'less', 'than', 'millimetre', 'so', 'there', 'hasn', 'been', 'much', 'relief', 'as', 'far', 'as', 'rain', 'is', 'concerned', 'in', 'fact', 'they', 've', 'probably', 'hampered', 'the', 'efforts', 'of', 'the', 'firefighters', 'more', 'because', 'of', 'the', 'wind', 'gusts', 'that', 'are', 'associated', 'with', 'those', 'thunderstorms'], tags=[0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
