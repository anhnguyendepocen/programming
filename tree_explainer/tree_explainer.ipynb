{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "import numpy as np\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2017-06-29 20:57:04 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 6.1.0\n",
      "\n",
      "numpy 1.12.1\n",
      "pandas 0.19.2\n",
      "matplotlib 2.0.0\n",
      "sklearn 0.18.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from graphviz import Source\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eli5 experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size = 0.2, random_state = 14)\n",
    "\n",
    "model_xgb = XGBClassifier(n_estimators = 100)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "accuracy_score(y_test, model_xgb.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_feature_imp(model_xgb, feature_names = None, importance_type = 'gain'):\n",
    "    # XGBClassifier is a scikit-learn like\n",
    "    # wrapper around the actual underlying model\n",
    "    booster = model_xgb.get_booster()\n",
    "    \n",
    "    # get the normalized feature importance (sum up to 1)\n",
    "    score = booster.get_score(importance_type = importance_type)\n",
    "    all_features_score = np.array(\n",
    "        [score.get(f, 0.) for f in booster.feature_names], dtype = np.float32)\n",
    "    \n",
    "    normed_score = all_features_score / np.sum(all_features_score)\n",
    "    \n",
    "    # construct a dataframe with the feature name mapping with the score\n",
    "    if feature_names is None:\n",
    "        feature_names = booster.feature_names\n",
    "\n",
    "    feature_imp = {'weight': normed_score, 'feature': feature_names}\n",
    "    df_feature_imp = pd.DataFrame(feature_imp)[['feature', 'weight']]\n",
    "    df_feature_imp = (df_feature_imp\n",
    "                      .sort_values('feature')\n",
    "                      .reset_index(drop = True))\n",
    "    return df_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>0.688613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>0.267231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>0.026507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>0.017650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature    weight\n",
       "0  petal length (cm)  0.688613\n",
       "1   petal width (cm)  0.267231\n",
       "2  sepal length (cm)  0.026507\n",
       "3   sepal width (cm)  0.017650"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature_imp = xgb_feature_imp(model_xgb, feature_names = iris.feature_names)\n",
    "df_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import Booster, XGBRegressor, XGBClassifier\n",
    "\n",
    "def _check_booster_args(xgb):\n",
    "    if isinstance(xgb, Booster):\n",
    "        booster = xgb\n",
    "    else:\n",
    "        booster = xgb.get_booster()\n",
    "        is_regression = isinstance(xgb, XGBRegressor)\n",
    "\n",
    "    return booster, is_regression\n",
    "\n",
    "booster, is_regression = _check_booster_args(model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if isinstance(xgb, XGBClassifier):\n",
    "        return 1 if xgb.n_classes_ == 2 else xgb.n_classes_\n",
    "    elif isinstance(xgb, XGBRegressor):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_targets = model_xgb.n_classes_\n",
    "n_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_margin=False\n",
    "ntree_limit=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 3, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 3,\n",
       "       1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3,\n",
       "       3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 3, 1,\n",
       "       3, 3, 1, 3, 3, 1, 3, 3, 1, 3, 4, 1, 3, 3, 1, 3, 4, 1, 3, 4, 1, 3, 1,\n",
       "       1, 3, 4, 1, 3, 3, 1, 3, 1, 1, 3, 3, 1, 3, 4, 1, 3, 1, 1, 3, 3, 1, 3,\n",
       "       1, 1, 3, 3, 1, 3, 3, 1, 5, 7, 1, 3, 1, 0, 5, 3, 0, 5, 3, 0, 5, 3, 0,\n",
       "       5, 3, 0, 5, 3, 0, 3, 3, 0, 5, 3, 0, 5, 2, 0, 3, 3, 0, 5, 2, 0, 3, 3,\n",
       "       0, 3, 1, 0, 5, 1, 0, 3, 1, 0, 5, 2, 0, 3, 1, 0, 5, 2, 0, 3, 1, 0, 3,\n",
       "       1, 0, 5, 1, 0, 3, 1, 0, 1, 1, 0, 5, 3, 0, 1, 1, 0, 1, 1, 0, 3, 3, 0,\n",
       "       1, 1, 0, 1, 1, 0, 3, 3, 0, 1, 1, 0, 1, 1, 0, 5, 3, 0, 1, 1, 0, 1, 1,\n",
       "       0, 5, 3, 0, 1, 1, 0, 5, 1, 0, 1, 3, 0, 1, 1, 0, 5, 3, 0, 1, 1, 0, 5,\n",
       "       1], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import DMatrix\n",
    "dmatrix = DMatrix(np.atleast_2d(X_train[0]), missing = model_xgb.missing)\n",
    "\n",
    "# each record indicating the predicted leaf index of each sample in each tree\n",
    "leaf_preds = booster.predict(dmatrix,\n",
    "    output_margin=output_margin,\n",
    "    ntree_limit=ntree_limit,\n",
    "    pred_leaf=True)[0]\n",
    "\n",
    "leaf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  3.2012167 ,  0.02203865,  0.00565705,\n",
       "       -0.31680772,  0.        , -1.92371082, -0.03058295,  0.63473058,\n",
       "       -0.77690864, -0.21795982, -2.3625524 , -0.24004447,  0.73383176], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrib_preds = booster.predict(dmatrix,\n",
    "    output_margin=output_margin,\n",
    "    ntree_limit=ntree_limit,\n",
    "    pred_contribs=True)[0]\n",
    "\n",
    "contrib_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:[f2<2.3] yes=1,no=2,missing=1,gain=54.04,cover=53.3333\\n\\t1:leaf=0.141176,cover=16\\n\\t2:leaf=-0.0730435,cover=37.3333\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_dumps = booster.get_dump(with_stats=True)\n",
    "tree_dumps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 3, ..., 0, 5, 1],\n",
       "       [2, 7, 3, ..., 0, 5, 1],\n",
       "       [2, 7, 3, ..., 0, 6, 4],\n",
       "       ..., \n",
       "       [1, 3, 3, ..., 0, 5, 1],\n",
       "       [2, 7, 3, ..., 0, 5, 1],\n",
       "       [2, 6, 6, ..., 0, 2, 4]], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.02203865,  0.        ,  0.63473058, -2.3625524 ], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = contrib_preds[0]\n",
    "temp[0::n_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7057831"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0::n_targets].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9350071"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[1::n_targets].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.369698"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[2::n_targets].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?booster.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 300)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 3, ..., 0, 5, 1],\n",
       "       [2, 7, 3, ..., 0, 5, 1],\n",
       "       [2, 7, 3, ..., 0, 6, 4],\n",
       "       ..., \n",
       "       [1, 3, 3, ..., 0, 5, 1],\n",
       "       [2, 7, 3, ..., 0, 5, 1],\n",
       "       [2, 6, 6, ..., 0, 2, 4]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_dumps = booster.get_dump(with_stats=True)\n",
    "len(tree_dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.01017746,  0.98426396,  0.0055586 ],\n",
       "       [ 0.00323318,  0.98674703,  0.01001976],\n",
       "       [ 0.9871586 ,  0.01061085,  0.00223063],\n",
       "       [ 0.0064597 ,  0.98924237,  0.00429798],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00535245,  0.02136614,  0.97328138],\n",
       "       [ 0.00672622,  0.98879844,  0.00447531],\n",
       "       [ 0.01331715,  0.24523123,  0.74145162],\n",
       "       [ 0.00286762,  0.99050093,  0.00663148],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.98938084,  0.00838355,  0.00223565],\n",
       "       [ 0.00399441,  0.99322915,  0.00277646],\n",
       "       [ 0.00177171,  0.00231007,  0.99591821],\n",
       "       [ 0.00689198,  0.02128228,  0.97182572],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.98951334,  0.00762879,  0.00285789],\n",
       "       [ 0.98951334,  0.00762879,  0.00285789],\n",
       "       [ 0.00298985,  0.98946321,  0.00754686],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.0016053 ,  0.0019783 ,  0.99641645],\n",
       "       [ 0.0016053 ,  0.0019783 ,  0.99641645],\n",
       "       [ 0.00303994,  0.99063748,  0.00632263],\n",
       "       [ 0.00203299,  0.00247168,  0.99549532],\n",
       "       [ 0.00533606,  0.0201945 ,  0.97446942],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00517333,  0.99123085,  0.0035959 ],\n",
       "       [ 0.00144433,  0.00175599,  0.99679971],\n",
       "       [ 0.00619607,  0.98980927,  0.00399463],\n",
       "       [ 0.00288936,  0.98854059,  0.00857004],\n",
       "       [ 0.00289029,  0.01829333,  0.97881639],\n",
       "       [ 0.00190771,  0.99376869,  0.00432361],\n",
       "       [ 0.01017746,  0.98426396,  0.0055586 ],\n",
       "       [ 0.0249716 ,  0.18757053,  0.78745788],\n",
       "       [ 0.04305145,  0.68599641,  0.27095214],\n",
       "       [ 0.00352285,  0.9699499 ,  0.02652724],\n",
       "       [ 0.00505782,  0.99142659,  0.00351561],\n",
       "       [ 0.00555424,  0.99058503,  0.00386067],\n",
       "       [ 0.00382937,  0.94035786,  0.05581279],\n",
       "       [ 0.00347778,  0.9882713 ,  0.00825086],\n",
       "       [ 0.01927167,  0.70495808,  0.27577022],\n",
       "       [ 0.00331948,  0.00741879,  0.98926175],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.01009092,  0.12271063,  0.86719853],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00144433,  0.00175599,  0.99679971],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00203299,  0.00247168,  0.99549532],\n",
       "       [ 0.0036648 ,  0.96092838,  0.03540676],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00303994,  0.99063748,  0.00632263],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.0078495 ,  0.03294392,  0.95920658],\n",
       "       [ 0.00856524,  0.98625028,  0.00518448],\n",
       "       [ 0.00286234,  0.98867726,  0.00846043],\n",
       "       [ 0.0016053 ,  0.0019783 ,  0.99641645],\n",
       "       [ 0.00279851,  0.9889009 ,  0.00830059],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.0016053 ,  0.0019783 ,  0.99641645],\n",
       "       [ 0.00203299,  0.00247168,  0.99549532],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.00780276,  0.98747432,  0.00472295],\n",
       "       [ 0.00190771,  0.99376869,  0.00432361],\n",
       "       [ 0.98951334,  0.00762879,  0.00285789],\n",
       "       [ 0.00144433,  0.00175599,  0.99679971],\n",
       "       [ 0.00734784,  0.98798394,  0.00466826],\n",
       "       [ 0.01831432,  0.77296585,  0.20871979],\n",
       "       [ 0.00280043,  0.98957962,  0.00761993],\n",
       "       [ 0.01017746,  0.98426396,  0.0055586 ],\n",
       "       [ 0.00280547,  0.99135953,  0.00583497],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.98951334,  0.00762879,  0.00285789],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00303177,  0.98797578,  0.00899245],\n",
       "       [ 0.00144433,  0.00175599,  0.99679971],\n",
       "       [ 0.00264302,  0.00699626,  0.99036074],\n",
       "       [ 0.98951334,  0.00762879,  0.00285789],\n",
       "       [ 0.00534335,  0.01885595,  0.97580069],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00555424,  0.99058503,  0.00386067],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00555424,  0.99058503,  0.00386067],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00203299,  0.00247168,  0.99549532],\n",
       "       [ 0.00177165,  0.00234148,  0.99588686],\n",
       "       [ 0.00144433,  0.00175599,  0.99679971],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.0016053 ,  0.0019783 ,  0.99641645],\n",
       "       [ 0.00347129,  0.02057634,  0.97595233],\n",
       "       [ 0.00305799,  0.98922312,  0.00771887],\n",
       "       [ 0.00464736,  0.99226052,  0.00309213],\n",
       "       [ 0.98942995,  0.00762815,  0.00294191],\n",
       "       [ 0.00533606,  0.0201945 ,  0.97446942],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00883742,  0.0804726 ,  0.91069001],\n",
       "       [ 0.00532427,  0.99108094,  0.00359482],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.99012917,  0.00763354,  0.00223734],\n",
       "       [ 0.98951334,  0.00762879,  0.00285789],\n",
       "       [ 0.00225921,  0.00278414,  0.99495667],\n",
       "       [ 0.00281657,  0.99528176,  0.00190168],\n",
       "       [ 0.01020344,  0.13248684,  0.85730976],\n",
       "       [ 0.0016053 ,  0.0019783 ,  0.99641645],\n",
       "       [ 0.00298472,  0.98776555,  0.00924974],\n",
       "       [ 0.98951334,  0.00762879,  0.00285789],\n",
       "       [ 0.00520541,  0.99128002,  0.00351457],\n",
       "       [ 0.0016053 ,  0.0019783 ,  0.99641645]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "proba = model_xgb.predict_proba(X_train)\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "            <thead>\n",
       "            <tr style=\"border: none;\">\n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "                <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            </tr>\n",
       "            </thead>\n",
       "            <tbody>\n",
       "            \n",
       "                <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "                    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                        0.6886\n",
       "                        \n",
       "                    </td>\n",
       "                    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                        f2\n",
       "                    </td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr style=\"background-color: hsl(120, 100.00%, 89.69%); border: none;\">\n",
       "                    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                        0.2672\n",
       "                        \n",
       "                    </td>\n",
       "                    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                        f3\n",
       "                    </td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr style=\"background-color: hsl(120, 100.00%, 97.95%); border: none;\">\n",
       "                    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                        0.0265\n",
       "                        \n",
       "                    </td>\n",
       "                    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                        f0\n",
       "                    </td>\n",
       "                </tr>\n",
       "            \n",
       "                <tr style=\"background-color: hsl(120, 100.00%, 98.46%); border: none;\">\n",
       "                    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                        0.0176\n",
       "                        \n",
       "                    </td>\n",
       "                    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                        f1\n",
       "                    </td>\n",
       "                </tr>\n",
       "            \n",
       "            \n",
       "            </tbody>\n",
       "        </table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\n       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\\n       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\\n       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\\n       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\\n       silent=True, subsample=1)\", description='\\nXGBoost feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=False, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='f2', weight=0.68861258, std=None, value=None), FeatureWeight(feature='f3', weight=0.26723063, std=None, value=None), FeatureWeight(feature='f0', weight=0.026507288, std=None, value=None), FeatureWeight(feature='f1', weight=0.017649557, std=None, value=None)], remaining=0), decision_tree=None, highlight_spaces=None, transition_features=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eli5 import explain_weights\n",
    "explain_weights(model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.dump_model('temp.txt')\n",
    "booster = model_xgb.get_booster()\n",
    "original_feature_names = booster.feature_names\n",
    "\n",
    "features_names = iris.feature_names\n",
    "booster.feature_names = features_names\n",
    "features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[petal length (cm)<2.3] yes=1,no=2,missing=1\n",
      "\t1:leaf=0.141176\n",
      "\t2:leaf=-0.0730435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgdump = booster.get_dump()\n",
    "xgdump[0]\n",
    "print(booster.get_dump()[0])\n",
    "# recover original feature names\n",
    "booster.feature_names = original_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size = 0.2, random_state = 14)\n",
    "\n",
    "model_rf = RandomForestClassifier(max_depth = 6)\n",
    "model_rf.fit(X_train, y_train)\n",
    "accuracy_score(y_test, model_rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tree_explainer import RandomForestExplainer\n",
    "\n",
    "rf_explain = RandomForestExplainer(model_rf, iris.feature_names)\n",
    "df_explained, pred_info = rf_explain.explain(X_train[0])\n",
    "\n",
    "model_rf_pred = pred_info['predict']\n",
    "bias = rf_explain.bias_[model_rf_pred]\n",
    "model_rf_pred_proba = pred_info['predict_proba'][model_rf_pred]\n",
    "\n",
    "print('bias:', bias)\n",
    "print('predicted class: ', model_rf_pred)\n",
    "print('predicted proba:', model_rf_pred_proba)\n",
    "actual_sum = bias + df_explained['contrib'].sum()\n",
    "equal = np.allclose(actual_sum, model_rf_pred_proba)\n",
    "print('bias + contribution = prediction:', equal)\n",
    "\n",
    "df_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62189479247970103"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "feature_names = boston.feature_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state = 14)\n",
    "\n",
    "model_tree = DecisionTreeRegressor(max_depth = 2, random_state = 1234)\n",
    "model_tree.fit(X_train, y_train)\n",
    "model_tree_pred = model_tree.predict(X_test)\n",
    "r2_score(y_test, model_tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias: 23.0051980198\n",
      "prediction: 15.197826087\n",
      "bias + contribution = prediction: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrib</th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.895377</td>\n",
       "      <td>RM</td>\n",
       "      <td>5.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.911995</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>15.940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    contrib feature   value\n",
       "0 -2.895377      RM   5.782\n",
       "1 -4.911995   LSTAT  15.940"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tree_explainer import DecisionTreeExplainer\n",
    "\n",
    "tree_explain = DecisionTreeExplainer(model_tree, feature_names)\n",
    "df_explained, pred_info = tree_explain.explain(X_train[0])\n",
    "\n",
    "print('bias:', tree_explain.bias_)\n",
    "print('prediction:', pred_info['predict'])\n",
    "equal = tree_explain.bias_ + df_explained['contrib'].sum() == pred_info['predict']\n",
    "print('bias + contribution = prediction:', equal)\n",
    "\n",
    "df_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87631195942587714"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestRegressor(max_depth = 6)\n",
    "model_rf.fit(X_train, y_train)\n",
    "r2_score(y_test, model_rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias: 23.1832673267\n",
      "prediction: 19.9045053568\n",
      "bias + contribution = prediction: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrib</th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.737952</td>\n",
       "      <td>NOX</td>\n",
       "      <td>0.54400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.070727</td>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>18.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.940180</td>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.24522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.628056</td>\n",
       "      <td>AGE</td>\n",
       "      <td>71.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.160120</td>\n",
       "      <td>B</td>\n",
       "      <td>396.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.079076</td>\n",
       "      <td>DIS</td>\n",
       "      <td>4.03170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.085559</td>\n",
       "      <td>INDUS</td>\n",
       "      <td>9.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.171130</td>\n",
       "      <td>TAX</td>\n",
       "      <td>304.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.348453</td>\n",
       "      <td>RM</td>\n",
       "      <td>5.78200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.289730</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>15.94000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    contrib  feature      value\n",
       "0  1.737952      NOX    0.54400\n",
       "1  1.070727  PTRATIO   18.40000\n",
       "2  0.940180     CRIM    0.24522\n",
       "3  0.628056      AGE   71.70000\n",
       "4  0.160120        B  396.90000\n",
       "5  0.079076      DIS    4.03170\n",
       "6 -0.085559    INDUS    9.90000\n",
       "7 -0.171130      TAX  304.00000\n",
       "8 -2.348453       RM    5.78200\n",
       "9 -5.289730    LSTAT   15.94000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tree_explainer import RandomForestExplainer\n",
    "\n",
    "rf_explain = RandomForestExplainer(model_rf, feature_names)\n",
    "df_explained, pred_info = rf_explain.explain(X_train[0])\n",
    "\n",
    "print('bias:', rf_explain.bias_)\n",
    "print('prediction:', pred_info['predict'])\n",
    "actual_sum = rf_explain.bias_ + df_explained['contrib'].sum()\n",
    "equal = np.allclose(actual_sum, pred_info['predict'])\n",
    "print('bias + contribution = prediction:', equal)\n",
    "\n",
    "df_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"490pt\" height=\"300pt\"\n",
       " viewBox=\"0.00 0.00 489.71 300.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 296)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-296 485.713,-296 485.713,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.262745\" stroke=\"black\" points=\"293.57,-292 187.143,-292 187.143,-214 293.57,-214 293.57,-292\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.356\" y=\"-276.8\" font-family=\"Times,serif\" font-size=\"14.00\">node #0</text>\n",
       "<text text-anchor=\"middle\" x=\"240.356\" y=\"-262.8\" font-family=\"Times,serif\" font-size=\"14.00\">RM &lt;= 6.941</text>\n",
       "<text text-anchor=\"middle\" x=\"240.356\" y=\"-248.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 88.4295</text>\n",
       "<text text-anchor=\"middle\" x=\"240.356\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 404</text>\n",
       "<text text-anchor=\"middle\" x=\"240.356\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 23.0052</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.164706\" stroke=\"black\" points=\"231.57,-178 125.143,-178 125.143,-100 231.57,-100 231.57,-178\"/>\n",
       "<text text-anchor=\"middle\" x=\"178.356\" y=\"-162.8\" font-family=\"Times,serif\" font-size=\"14.00\">node #1</text>\n",
       "<text text-anchor=\"middle\" x=\"178.356\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\">LSTAT &lt;= 14.4</text>\n",
       "<text text-anchor=\"middle\" x=\"178.356\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 39.5192</text>\n",
       "<text text-anchor=\"middle\" x=\"178.356\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 336</text>\n",
       "<text text-anchor=\"middle\" x=\"178.356\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 20.1098</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M219.193,-213.769C214.405,-205.119 209.267,-195.838 204.306,-186.877\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"207.33,-185.112 199.425,-178.058 201.206,-188.503 207.33,-185.112\"/>\n",
       "<text text-anchor=\"middle\" x=\"192.52\" y=\"-197.886\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.741176\" stroke=\"black\" points=\"356.557,-178 250.156,-178 250.156,-100 356.557,-100 356.557,-178\"/>\n",
       "<text text-anchor=\"middle\" x=\"303.356\" y=\"-162.8\" font-family=\"Times,serif\" font-size=\"14.00\">node #4</text>\n",
       "<text text-anchor=\"middle\" x=\"303.356\" y=\"-148.8\" font-family=\"Times,serif\" font-size=\"14.00\">RM &lt;= 7.435</text>\n",
       "<text text-anchor=\"middle\" x=\"303.356\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 84.0034</text>\n",
       "<text text-anchor=\"middle\" x=\"303.356\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 68</text>\n",
       "<text text-anchor=\"middle\" x=\"303.356\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 37.3118</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M261.861,-213.769C266.727,-205.119 271.948,-195.838 276.988,-186.877\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.096,-188.49 281.949,-178.058 273.995,-185.058 280.096,-188.49\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.689\" y=\"-197.933\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.278431\" stroke=\"black\" points=\"106.57,-64 0.143169,-64 0.143169,-0 106.57,-0 106.57,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"53.3564\" y=\"-48.8\" font-family=\"Times,serif\" font-size=\"14.00\">node #2</text>\n",
       "<text text-anchor=\"middle\" x=\"53.3564\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 26.338</text>\n",
       "<text text-anchor=\"middle\" x=\"53.3564\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 198</text>\n",
       "<text text-anchor=\"middle\" x=\"53.3564\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 23.5333</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M132.875,-99.7956C121.532,-90.2671 109.378,-80.0585 98.0723,-70.5614\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.309,-67.8692 90.4007,-64.1172 95.8066,-73.2291 100.309,-67.8692\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"231.57,-64 125.143,-64 125.143,-0 231.57,-0 231.57,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"178.356\" y=\"-48.8\" font-family=\"Times,serif\" font-size=\"14.00\">node #3</text>\n",
       "<text text-anchor=\"middle\" x=\"178.356\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 17.4873</text>\n",
       "<text text-anchor=\"middle\" x=\"178.356\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 138</text>\n",
       "<text text-anchor=\"middle\" x=\"178.356\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 15.1978</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M178.356,-99.7956C178.356,-91.4581 178.356,-82.6 178.356,-74.1534\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.857,-74.1171 178.356,-64.1172 174.857,-74.1172 181.857,-74.1171\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<polygon fill=\"#e58139\" fill-opacity=\"0.564706\" stroke=\"black\" points=\"356.57,-64 250.143,-64 250.143,-0 356.57,-0 356.57,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"303.356\" y=\"-48.8\" font-family=\"Times,serif\" font-size=\"14.00\">node #5</text>\n",
       "<text text-anchor=\"middle\" x=\"303.356\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 46.2365</text>\n",
       "<text text-anchor=\"middle\" x=\"303.356\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 40</text>\n",
       "<text text-anchor=\"middle\" x=\"303.356\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 31.9525</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M303.356,-99.7956C303.356,-91.4581 303.356,-82.6 303.356,-74.1534\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"306.857,-74.1171 303.356,-64.1172 299.857,-74.1172 306.857,-74.1171\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"481.57,-64 375.143,-64 375.143,-0 481.57,-0 481.57,-64\"/>\n",
       "<text text-anchor=\"middle\" x=\"428.356\" y=\"-48.8\" font-family=\"Times,serif\" font-size=\"14.00\">node #6</text>\n",
       "<text text-anchor=\"middle\" x=\"428.356\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 38.3093</text>\n",
       "<text text-anchor=\"middle\" x=\"428.356\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 28</text>\n",
       "<text text-anchor=\"middle\" x=\"428.356\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 44.9679</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M348.838,-99.7956C360.181,-90.2671 372.334,-80.0585 383.641,-70.5614\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"385.906,-73.2291 391.312,-64.1172 381.404,-67.8692 385.906,-73.2291\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x114310208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_graphviz(model_tree, feature_names = boston.feature_names,\n",
    "                filled = True, node_ids = True, out_file = 'tree.dot')\n",
    "\n",
    "# read it in and visualize it, or if we wish to\n",
    "# convert the .dot file into other formats, we can do:\n",
    "# import os\n",
    "# os.system('dot -Tpng tree1.dot -o tree1.jpeg')\n",
    "with open('tree.dot') as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 0 left child 1\n",
      "node 1 left child 2\n",
      "value for representing leaf node: -1\n",
      "total number of nodes: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import _tree\n",
    "\n",
    "# for instance we can see that\n",
    "# node 0's (node 0 is the root node) \n",
    "# left children is node 1, so if we \n",
    "# do a search on the left children\n",
    "node_id = 0\n",
    "left_child = model_tree.tree_.children_left[node_id]\n",
    "print('node {} left child {}'.format(node_id, left_child))\n",
    "\n",
    "# and node 1 is a leaf node (no left or right children)\n",
    "node_id = 1\n",
    "left_child = model_tree.tree_.children_left[node_id]\n",
    "print('node {} left child {}'.format(node_id, left_child))\n",
    "\n",
    "# we can see that sklearn represents the leaf node using\n",
    "# the number -1, and we'll use this information to obtain\n",
    "# the decision tree path later\n",
    "print('value for representing leaf node:', _tree.TREE_LEAF)\n",
    "\n",
    "# we can confirm that the node count matches the total count\n",
    "# that was shown on the decision tree graph above\n",
    "print('total number of nodes:', model_tree.tree_.node_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.tree_` attribute provides the tree object of the DecisionTree model (looking up the docstring by doing `?model_tree.tree_` provides lots of useful documentation of the information it contains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_tree_paths(tree, node_id, depth = 0):\n",
    "    \"\"\"\n",
    "    returns all paths through the tree as list\n",
    "    of node_ids, note that the path here will\n",
    "    be the sequence of nodes from the leaf node\n",
    "    to the root node\n",
    "    \"\"\"\n",
    "    left_node = tree.children_left[node_id]\n",
    "    right_node = tree.children_right[node_id]\n",
    "\n",
    "    if left_node != _tree.TREE_LEAF:\n",
    "        left_paths = _get_tree_paths(tree, left_node, depth + 1)\n",
    "        right_paths = _get_tree_paths(tree, right_node, depth + 1)\n",
    "\n",
    "        for path in left_paths:\n",
    "            path.append(node_id)\n",
    "\n",
    "        for path in right_paths:\n",
    "            path.append(node_id)\n",
    "\n",
    "        paths = left_paths + right_paths\n",
    "    else:\n",
    "        paths = [[node_id]]\n",
    "    \n",
    "    # recursive algorithm can be unintuitive sometimes,\n",
    "    # we can print the path to see the steps along the way\n",
    "    # print(paths)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [0, 1, 2], 3: [0, 1, 3], 5: [0, 4, 5], 6: [0, 4, 6]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = _get_tree_paths(tree = model_tree.tree_, node_id = 0)\n",
    "\n",
    "# map leaves to paths,\n",
    "# and reverse the path so\n",
    "# that the sequence starts with the root node\n",
    "leaf_to_path = {}\n",
    "for path in paths:\n",
    "    path.reverse()\n",
    "    leaf_to_path[path[-1]] = path\n",
    "    \n",
    "leaf_to_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_contrib(model_tree, values, leaf_to_path):\n",
    "    \"\"\"\n",
    "    compute the contribution vector for each unique tree leaf nodes\n",
    "    and store the result into a dictionary, whose keys are leaf nodes\n",
    "    and the corresponding value refers to the contribution vector of the leaf node.\n",
    "    after that we can simply assign the contribution vector to each observation\n",
    "    by looking up which leaf node it is assigned\n",
    "    \"\"\"\n",
    "    # convert numpy array into python list,\n",
    "    # accessing values will be faster\n",
    "    # https://stackoverflow.com/questions/35020604/why-is-numpy-list-access-slower-than-vanilla-python\n",
    "    values = list(values)\n",
    "\n",
    "    # feature[i] holds the feature to split on,\n",
    "    # for the internal node i\n",
    "    feature = list(model_tree.tree_.feature)\n",
    "\n",
    "    unique_contribs = {}\n",
    "    for leaf, path in leaf_to_path.items():\n",
    "        # compute the contribution of each feature\n",
    "        # for a given observation\n",
    "        contribs = np.zeros(model_tree.n_features_)\n",
    "        for depth in range(len(path) - 1):\n",
    "            contrib = values[path[depth + 1]] - values[path[depth]]\n",
    "            feature_idx = feature[path[depth]]\n",
    "            contribs[feature_idx] += contrib\n",
    "\n",
    "        unique_contribs[leaf] = contribs\n",
    "\n",
    "    return unique_contribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -2.89537659,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  3.4235119 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the single-dimensional inner arrays\n",
    "values = model_tree.tree_.value.squeeze()\n",
    "\n",
    "# the bias is always simply the value at the root node\n",
    "bias = values[0]\n",
    "\n",
    "unique_contribs = compute_contrib(model_tree, values, leaf_to_path)\n",
    "\n",
    "# e.g. if the data point ends up in node 2\n",
    "unique_contribs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrib</th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.895377</td>\n",
       "      <td>RM</td>\n",
       "      <td>5.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.911995</td>\n",
       "      <td>LSTAT</td>\n",
       "      <td>15.940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    contrib feature   value\n",
       "0 -2.895377      RM   5.782\n",
       "1 -4.911995   LSTAT  15.940"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the leaf index each data points ends up in\n",
    "# and obtain prediction for each observation\n",
    "# by using which leaf it belongs to;\n",
    "# prediction is essentially the same as calling\n",
    "# model_tree.predict(X) for regression tree\n",
    "data_row = X_train[0]\n",
    "X = np.atleast_2d(data_row)\n",
    "leaf = model_tree.apply(X)[0]\n",
    "prediction = values[leaf]\n",
    "contrib = unique_contribs[leaf]\n",
    "\n",
    "# convert the explanation to dataframe for better interpretation\n",
    "value_col = 'value'\n",
    "contrib_col = 'contrib'\n",
    "feature_col = 'feature'\n",
    "explained = {value_col: data_row,\n",
    "             contrib_col: contrib,\n",
    "             feature_col: feature_names}\n",
    "df_explained = pd.DataFrame(explained, columns = [contrib_col, feature_col, value_col])\n",
    "df_explained = (df_explained\n",
    "                .loc[df_explained[contrib_col] != 0.0]\n",
    "                .sort_values(contrib_col, ascending = False)\n",
    "                .reset_index(drop = True))\n",
    "df_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias + df_explained['contrib'].sum() == prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Feature Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "instances = boston.data[[300, 309]]\n",
    "print(\"Instance 0 prediction:\", model_tree_reg.predict([instances[0]]))\n",
    "print(\"Instance 1 prediction:\", model_tree_reg.predict([instances[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaf_to_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# contributions = []\n",
    "# for row, leaf in enumerate(leaves):\n",
    "#     path = leaf_to_path[leaf]\n",
    "\n",
    "# leaf = leaves[0]\n",
    "path = leaf_to_path[leaf]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = list(model_tree.tree_.feature)\n",
    "\n",
    "path_features = set()\n",
    "path_features_dict = {}\n",
    "\n",
    "for depth in range(len(path) - 1):\n",
    "    path_feature = feature[path[depth]]\n",
    "    path_features.add(path_feature)\n",
    "    contrib = values[path[depth + 1]] - values[path[depth]]\n",
    "    \n",
    "    joint_features = tuple(sorted(path_features))\n",
    "    contrib += path_features_dict.get(joint_features, 0)\n",
    "    path_features_dict[joint_features] = contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias - 2.8953765912305585 - 4.9119953416149027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contributions = []\n",
    "for leaf in leaves:\n",
    "    path = leaf_to_path[leaf]\n",
    "    path_features = set()\n",
    "    path_features_dict = {}\n",
    "\n",
    "    for depth in range(len(path) - 1):\n",
    "        path_feature = feature[path[depth]]\n",
    "        path_features.add(path_feature)\n",
    "        contrib = values[path[depth + 1]] - values[path[depth]]\n",
    "\n",
    "        joint_features = tuple(sorted(path_features))\n",
    "        contrib += path_features_dict.get(joint_features, 0)\n",
    "        path_features_dict[joint_features] = contrib\n",
    "    \n",
    "    contributions.append(path_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contributions = []\n",
    "\n",
    "for leaf in leaves:\n",
    "    # for each leaf, check which is the path\n",
    "    # that it took to get to the leaf\n",
    "    for path in paths:\n",
    "        if leaf == path[-1]:\n",
    "            break\n",
    "    \n",
    "    # compute the contribution of each feature \n",
    "    # for a given observation\n",
    "    contribs = np.zeros(line_shape)\n",
    "    for depth in range(len(path) - 1):\n",
    "        contrib = values[path[depth + 1]] - values[path[depth]]\n",
    "        feature_idx = feature[path[depth]]\n",
    "        contribs[feature_idx] += contrib\n",
    "    \n",
    "    contributions.append(contribs)\n",
    "    \n",
    "contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_predict_tree(model, X, joint_contribution=joint_contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tree_explainer import TreeExplainer\n",
    "\n",
    "tree_explain = TreeExplainer(model_tree, iris.feature_names)\n",
    "best_idx, prediction, df_explained = tree_explain.explain(X_train[0])\n",
    "\n",
    "# style the contribution weight\n",
    "# https://pandas.pydata.org/pandas-docs/stable/style.html#Builtin-Styles\n",
    "# http://seaborn.pydata.org/tutorial/color_palettes.html#custom-diverging-palettes-with-diverging-palette\n",
    "cmap = sns.diverging_palette(10, 133, s = 85, l = 60, n = 4, as_cmap = True)\n",
    "df_explained = df_explained.style.background_gradient(cmap = cmap, subset = 'contrib')\n",
    "\n",
    "print('predicted class: ', best_idx)\n",
    "print('prediction: ', prediction)\n",
    "df_explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500)\n",
    "rf.fit(X_train, y_train)\n",
    "accuracy_score(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explainer = LimeTabularExplainer(X_train, feature_names = iris.feature_names, \n",
    "                                 class_names = iris.target_names, discretize_continuous = True)\n",
    "\n",
    "i = np.random.randint(0, X_test.shape[0])\n",
    "exp = explainer.explain_instance(X_test[i], rf.predict_proba, num_features=2, top_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp.available_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table = True, show_all = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "- [Blog: Interpreting random forests](http://blog.datadive.net/interpreting-random-forests/)\n",
    "- [Blog: Random forest interpretation with scikit-learn](http://blog.datadive.net/random-forest-interpretation-with-scikit-learn/)\n",
    "- [Blog: Random forest interpretation – conditional feature contributions](http://blog.datadive.net/random-forest-interpretation-conditional-feature-contributions/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
