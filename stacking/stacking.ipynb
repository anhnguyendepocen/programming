{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # code for loading the format for the notebook\n",
    "# import os\n",
    "\n",
    "# # path : store the current path to convert back to it later\n",
    "# path = os.getcwd()\n",
    "# os.chdir( os.path.join('..', 'notebook_format') )\n",
    "# from formats import load_style\n",
    "# load_style(css_style = 'custom2.css', plot_style = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2017-06-17 16:45:07 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 5.3.0\n",
      "\n",
      "numpy 1.12.1\n",
      "pandas 0.19.2\n",
      "sklearn 0.18.1\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(path)\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions:  (10000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Yearly Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>BikeBuyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Manual</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>47</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>High School</td>\n",
       "      <td>Manual</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>46</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Single</td>\n",
       "      <td>Female</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>High School</td>\n",
       "      <td>Manual</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>46</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>High School</td>\n",
       "      <td>Manual</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>46</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Manual</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>64</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Marital Status  Gender  Yearly Income  Children        Education Occupation  \\\n",
       "0        Married  Female          20000         0  Partial College     Manual   \n",
       "1        Married  Female          10000         1      High School     Manual   \n",
       "2         Single  Female          10000         1      High School     Manual   \n",
       "3         Single    Male          10000         1      High School     Manual   \n",
       "4         Single    Male          10000         0  Partial College     Manual   \n",
       "\n",
       "  Home Owner  Cars Commute Distance  Region  Age BikeBuyer  \n",
       "0         No     1        0-1 Miles  Europe   47       Yes  \n",
       "1         No     1        1-2 Miles  Europe   46        No  \n",
       "2         No     1        2-5 Miles  Europe   46        No  \n",
       "3         No     1        1-2 Miles  Europe   46        No  \n",
       "4         No     1        2-5 Miles  Europe   64        No  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'BikeBuyerWithLocation.csv'\n",
    "data = pd.read_csv(filename, encoding = 'latin1')\n",
    "\n",
    "# columns that we won't be using at all\n",
    "drop_cols = ['ID', 'Latitude', 'Longitude', 'City', 'Zip Code', 'Country']\n",
    "data = data.drop(drop_cols, axis = 1)\n",
    "print('dimensions: ', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original labels:  ['No' 'Yes']\n",
      "encoded labels distribution: [9000 1000]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "label_col = 'BikeBuyer'\n",
    "label = data[label_col]\n",
    "data = data.drop(label_col, axis = 1)\n",
    "label_encode = LabelEncoder()\n",
    "y = label_encode.fit_transform(label)\n",
    "\n",
    "# slightly imbalanced problem\n",
    "print('original labels: ', label_encode.classes_)\n",
    "print('encoded labels distribution:', np.bincount(y))\n",
    "\n",
    "test_size = 0.2\n",
    "random_state = 1234\n",
    "data_train, data_test, y_train, y_test = train_test_split(\n",
    "    data, y, test_size = test_size, random_state = random_state, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Preprocess(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, num_cols, cat_cols):\n",
    "        self.num_cols = num_cols\n",
    "        self.cat_cols = cat_cols\n",
    "\n",
    "    def fit(self, data):\n",
    "        data = data.copy()\n",
    "        \n",
    "        # Label encoding across multiple columns in scikit-learn\n",
    "        # https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "        self.label_encode_dict_ = defaultdict(LabelEncoder)\n",
    "        label_encoded = (data[self.cat_cols]\n",
    "                         .apply(lambda x: self.label_encode_dict_[x.name].fit_transform(x)))\n",
    "\n",
    "        self.cat_encode_ = OneHotEncoder(sparse = False)\n",
    "        self.cat_encode_.fit(label_encoded)\n",
    "\n",
    "        self.scaler_ = StandardScaler().fit(data[self.num_cols])\n",
    "        \n",
    "        # store the column names (numeric columns comes before the\n",
    "        # categorical columns) so we can refer to them later\n",
    "        colnames = self.num_cols.copy()\n",
    "        for col in self.cat_cols:\n",
    "            cat_colnames = [col + '_' + classes \n",
    "                            for classes in self.label_encode_dict_[col].classes_]\n",
    "            colnames += cat_colnames\n",
    "\n",
    "        self.colnames = colnames\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        label_encoded = (data[self.cat_cols]\n",
    "                         .apply(lambda x: self.label_encode_dict_[x.name].transform(x)))\n",
    "        cat_encoded = self.cat_encode_.transform(label_encoded)\n",
    "        scaled = self.scaler_.transform(data[self.num_cols])\n",
    "\n",
    "        # combine encoded categorical columns and scaled numerical\n",
    "        # columns, it's the same as concatenate it along axis 1\n",
    "        X = np.hstack((scaled, cat_encoded))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11431662, -0.69821864,  0.29928303, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.35562367,  2.41917677,  2.07544344, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.81666367,  1.17221861,  0.29928303, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.73497015, -0.69821864,  0.29928303, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.19601014, -0.69821864,  0.29928303, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.12699043, -0.69821864,  0.29928303, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = ['Yearly Income', 'Children', 'Cars', 'Age']\n",
    "cat_cols = ['Marital Status', 'Gender', 'Education', 'Occupation',\n",
    "            'Home Owner', 'Commute Distance', 'Region']\n",
    "\n",
    "preprocess = Preprocess(num_cols, cat_cols)\n",
    "X_train = preprocess.fit_transform(data_train)\n",
    "X_test = preprocess.transform(data_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state = 1234)\n",
    "X_resampled, y_resampled = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('label_encode', LabelEncoder()), ('onehot_encode', OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode = Pipeline([\n",
    "#     ('label_encode', label_encode), \n",
    "#     ('onehot_encode', onehot_encode)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Stacking is an ensemble learning technique to combine multiple predictive models (also referred to as base models) via a meta-classifier. Often times (especially in multi-class classification problems) the stacked model will outperform each of the individual models due its prowess to highlight each individual models where it performs best and discredit where it performs poorly. \n",
    "\n",
    "Thus, in order for this strategy to be effective it should be obvious that the base models should be different in some way so they don't all create the same error. Popular and powerful non-linear algorithms that are commonly used as base models includes [Random Forest, ExtraTrees](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/random_forest.ipynb), [Gradient Boosting Machine](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/trees/gbm/gbm.ipynb), [Feed Forward Deep Learning](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/nn_tensorflow.ipynb). As for the meta-classifier, logistic regression is one of the most common ways of stacking the base models. We can probably use any model as the meta-classifier, but sticking with simpler ones like logistic regression or decision tree will most likely be a safer bet that prevents overfitting.\n",
    "\n",
    "Let’s say we want to perform 2-fold stacking (we can choose the number of folds we wish to use, the 2 is simply for easier illustration purpose), then the overall process will be:\n",
    "\n",
    "- Split the train set in 2 parts: train_a and train_b\n",
    "- Fit the base model(s) on train_a and create predictions for train_b\n",
    "- Fit the same model on train_b and create predictions for train_a\n",
    "- Train the meta-classifier/stacking model on the probabilities generated from the base model(s)\n",
    "- Finally fit the model on the entire train set and create predictions for the test set.\n",
    "\n",
    "\n",
    "\n",
    "That was a mouthful, in the next section, we will look at how this can be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.datasets import make_classification, load_iris, load_digits\n",
    "import numpy as np\n",
    "\n",
    "# n_features = 20\n",
    "# n_samples = 10000\n",
    "# X, y = make_classification(n_features = n_features, n_samples = n_samples)\n",
    "\n",
    "#digits = load_digits()\n",
    "#X, y = digits.data, digits.target\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1234, stratify = y)\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.7946527777777779, testing score: 0.7022222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_tree = DecisionTreeClassifier(max_depth = 13)\n",
    "# model_tree.fit(X_train, y_train)\n",
    "model_tree.fit(X_resampled, y_resampled)\n",
    "\n",
    "tree_train_pred = model_tree.predict(X_train)\n",
    "tree_test_pred = model_tree.predict(X_test)\n",
    "\n",
    "# accuracy_score(y_test, y_pred)\n",
    "tree_train_score = roc_auc_score(y_train, tree_train_pred)\n",
    "tree_test_score = roc_auc_score(y_test, tree_test_pred)\n",
    "score_output = 'training score: {}, testing score: {}'.format(tree_train_score, tree_test_score)\n",
    "print(score_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.7910416666666668, testing score: 0.7208333333333334\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from mlxtend.classifier import StackingCVClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(max_depth = 11, learning_rate = 0.01, \n",
    "                          colsample_bytree = 0.9)\n",
    "# model_xgb.fit(X_train, y_train)\n",
    "\n",
    "model_xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "xgb_train_pred = model_xgb.predict(X_train)\n",
    "xgb_test_pred = model_xgb.predict(X_test)\n",
    "xgb_train_score = roc_auc_score(y_train, xgb_train_pred)\n",
    "xgb_test_score = roc_auc_score(y_test, xgb_test_pred)\n",
    "score_output = 'training score: {}, testing score: {}'.format(xgb_train_score, xgb_test_score)\n",
    "print(score_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class StackingClassifier(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, classifiers, meta_classifier, kfold):\n",
    "        self.kfold = kfold\n",
    "        self.classifiers = classifiers\n",
    "        self.meta_classifier = meta_classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.clfs_ = [deepcopy(clf) for clf in self.classifiers]\n",
    "        self.meta_clf_ = deepcopy(self.meta_classifier)\n",
    "        \n",
    "        n_rows = X.shape[0]\n",
    "        self._n_models = len(self.clfs_)\n",
    "        self._n_classes = np.unique(y).shape[0] - 1\n",
    "        \n",
    "        all_model_predictions = np.zeros((n_rows, self._n_models * self._n_classes))\n",
    "        for model_idx, model in enumerate(self.clfs_):\n",
    "            \n",
    "            model_prediction = np.zeros((n_rows, self._n_classes))\n",
    "            for fold_idx, (train_idx, test_idx) in enumerate(self.kfold.split(X, y)):\n",
    "                model.fit(X[train_idx], y[train_idx])\n",
    "                # do we need just n_classes - 1 prediction ??\n",
    "                model_prediction[test_idx] = model.predict_proba(X[test_idx])[:, self._n_classes:]\n",
    "            \n",
    "            # do we need just n_classes - 1 prediction ??\n",
    "            start_idx = model_idx * self._n_classes\n",
    "            columns = slice(start_idx, start_idx + self._n_classes)\n",
    "            all_model_predictions[:, columns] = model_prediction\n",
    "        \n",
    "        print(all_model_predictions.shape)\n",
    "        # is calling split multiple times a runtime bottleneck ??\n",
    "        # compare this memory efficient way versus storing it directly as a list\n",
    "        # and re-use the index multiple times\n",
    "        reordered_labels = np.zeros(n_rows)\n",
    "        for _, test_idx in self.kfold.split(X, y):\n",
    "            reordered_labels[test_idx] = y[test_idx]\n",
    "        \n",
    "        # stacking\n",
    "        self.meta_clf_.fit(all_model_predictions, reordered_labels)\n",
    "        \n",
    "        # fit the base models this time using all the input data\n",
    "        for model in self.clfs_:\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        n_rows = X.shape[0]\n",
    "        all_model_predictions = np.zeros((n_rows, self._n_models * self._n_classes))\n",
    "        for model_idx, model in enumerate(self.clfs_):\n",
    "            model_prediction = model.predict_proba(X)[:, self._n_classes:]\n",
    "            \n",
    "            # do we need just n_classes - 1 prediction ??\n",
    "            start_idx = model_idx * self._n_classes\n",
    "            columns = slice(start_idx, start_idx + self._n_classes)\n",
    "            all_model_predictions[:, columns] = model_prediction\n",
    "            \n",
    "        y_pred_proba = self.meta_clf_.predict_proba(all_model_predictions)\n",
    "        return y_pred_proba\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred_proba = self.predict_proba(X)\n",
    "        y_pred = np.argmax(y_pred_proba, axis = 1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(max_depth = 12, learning_rate = 0.01, \n",
    "                          colsample_bytree = 0.9)\n",
    "model_rf = RandomForestClassifier(max_depth = 12)\n",
    "model_lr = LogisticRegression()\n",
    "\n",
    "n_splits = 10\n",
    "shuffle = True\n",
    "random_state = 1234\n",
    "skf = StratifiedKFold(n_splits = n_splits, shuffle = shuffle, random_state = random_state)\n",
    "stack_param = {\n",
    "    'classifiers': [model_rf, model_xgb],\n",
    "    'meta_classifier': model_lr,\n",
    "    'kfold': skf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.16835025,  2.13210661, -4.54822883,  4.51198521]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stacking.meta_clf_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 2)\n",
      "training score: 0.8228472222222222, testing score: 0.7122222222222222\n"
     ]
    }
   ],
   "source": [
    "model_stacking = StackingClassifier(**stack_param)\n",
    "# model_stacking.fit(X_train, y_train)\n",
    "model_stacking.fit(X_resampled, y_resampled)\n",
    "\n",
    "stacking_train_pred = model_stacking.predict(X_train)\n",
    "stacking_test_pred = model_stacking.predict(X_test)\n",
    "stacking_train_score = roc_auc_score(y_train, stacking_train_pred)\n",
    "stacking_test_score = roc_auc_score(y_test, stacking_test_pred)\n",
    "score_output = 'training score: {}, testing score: {}'.format(stacking_train_score, stacking_test_score)\n",
    "print(score_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 4)\n",
      "training score: 0.8227083333333334, testing score: 0.7061111111111111\n"
     ]
    }
   ],
   "source": [
    "model_stacking = StackingClassifier(**stack_param)\n",
    "# model_stacking.fit(X_train, y_train)\n",
    "model_stacking.fit(X_resampled, y_resampled)\n",
    "\n",
    "stacking_train_pred = model_stacking.predict(X_train)\n",
    "stacking_test_pred = model_stacking.predict(X_test)\n",
    "stacking_train_score = roc_auc_score(y_train, stacking_train_pred)\n",
    "stacking_test_score = roc_auc_score(y_test, stacking_test_pred)\n",
    "score_output = 'training score: {}, testing score: {}'.format(stacking_train_score, stacking_test_score)\n",
    "print(score_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.8174999999999999, testing score: 0.7144444444444445\n"
     ]
    }
   ],
   "source": [
    "model_stacking = StackingClassifier(**stack_param)\n",
    "# model_stacking.fit(X_train, y_train)\n",
    "model_stacking.fit(X_resampled, y_resampled)\n",
    "\n",
    "stacking_train_pred = model_stacking.predict(X_train)\n",
    "stacking_test_pred = model_stacking.predict(X_test)\n",
    "stacking_train_score = roc_auc_score(y_train, stacking_train_pred)\n",
    "stacking_test_score = roc_auc_score(y_test, stacking_test_pred)\n",
    "score_output = 'training score: {}, testing score: {}'.format(stacking_train_score, stacking_test_score)\n",
    "print(score_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking accuracy: 0.9656\n",
      "a single model accuracy:  0.9656\n"
     ]
    }
   ],
   "source": [
    "stacking = StackingCVClassifier(classifiers = [rf, xgb], \n",
    "                                meta_classifier = lr, n_folds = 10)\n",
    "stacking.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking.predict(X_test)\n",
    "\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "print('stacking score:', roc_auc_score(y_test, y_pred_stacking))\n",
    "print('single model score: ', xgb_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits = n_splits, random_state = 1234)\n",
    "\n",
    "n_models = 3\n",
    "clfs = [DecisionTreeClassifier()] * n_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level1_train = np.zeros((X_train.shape[0], n_models))\n",
    "level1_test = np.zeros((X_test.shape[0], n_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for clf_idx, clf in enumerate(clfs):\n",
    "    level1_test_fold = np.zeros((X_test.shape[0], n_splits))\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold = X_train[train_idx]\n",
    "        X_test_fold = X_train[test_idx]      \n",
    "        y_train_fold = y_train[train_idx]\n",
    "        y_test_fold = y_train[test_idx]\n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # only need the positive class for 2-class classification\n",
    "        level1_train[test_idx, clf_idx] = clf.predict_proba(X_test_fold)[:, 1]\n",
    "        level1_test_fold[:, fold_idx] = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    level1_test[:, clf_idx] = level1_test_fold.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94079999999999997"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "lr = LogisticRegression()\n",
    "lr.fit(level1_train, y_train)\n",
    "pred = lr.predict(level1_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7500 is out of bounds for axis 0 with size 7500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-80b94a612a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# L^(-j), L_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0my_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7500 is out of bounds for axis 0 with size 7500"
     ]
    }
   ],
   "source": [
    "for k, clf in enumerate(clfs):\n",
    "    for j, (train_index, test_index) in enumerate(skf.split(X_train, y)):\n",
    "        # L^(-j), L_j \n",
    "        X_train_cv, X_test_cv = X_train[train_index], X_test[test_index]\n",
    "        y_train_cv, y_test_cv = y_train[train_index], y_test[test_index]\n",
    "        \n",
    "        # M_k^(-j) - level 0 model (M_k) on the training set L^{-j}\n",
    "        clf.fit(X_train_cv, y_train_cv)\n",
    "        \n",
    "        # L_cv = z_kj \n",
    "        # we use this dataset to train the level-1 model \n",
    "        # this is a 2-class problems, so we consider only the probability\n",
    "        # p of class 0. \n",
    "        level_1_train[test_index, k] = clf.predict_proba(X_test_cv)[:, 0]\n",
    "        \n",
    "        # We build a level-1 test set to be used with the level 1 classifier.\n",
    "        # This is the output of model M_k^(-j) on the held out test set\n",
    "        level_1_test[:, k, j] = clf.predict_proba(X_test)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "- [Blog: KAGGLE ENSEMBLING GUIDE](https://mlwave.com/kaggle-ensembling-guide/)\n",
    "- [mlxtend Documentation: StackingClassifier](https://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
