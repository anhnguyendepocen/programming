{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading\n",
    "\n",
    "In Python, threading allows us to run multiple I/O bound tasks concurrently, so if we have two tasks on our hand, task A and task B, we can run them simultaneously without having to wait for task A to finish before running running task B. The keyword here is \"I/O bound\". The **GIL (Global Interpreter Lock)** in Python that prevents threads from actually running in parallel. The GIL is necessary because the Python interpreter is not thread safe. This means that there is a globally enforced lock when trying to safely access Python objects from within threads. At any time only a single thread can acquire a lock for a Python object or C API. This is the reason that makes threads unsuitable for CPU intensive tasks in Python.\n",
    "\n",
    "On the other hand, threads are very efficient and beneficial for task that are not CPU intensive. The benefit of threading in Python appears when our problems are network bound or data input/output (I/O) bound. This means that the Python interpreter is waiting for the result of a function call that's manipulating with data from an external source, such as network address or hard disk. \n",
    "\n",
    "For example, consider a Python code that is scraping many web URLs. By adding a new thread for each download resource, the code can download multiple data sources in parallel and combine the results at the end of every download. This means that each subsequent download is not waiting on the download of earlier web pages. In this case the program is now bound by the bandwidth limitations of the client/server(s) instead.\n",
    "\n",
    "Let's look at some examples of working with threads. Before creating our thread, we first define a function that does nothing but sleeps for a specified amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sleeper(n_time):\n",
    "    name = threading.current_thread().name\n",
    "    print('I am {}. Going to sleep for {} seconds'.format(name, n_time))\n",
    "    time.sleep(n_time)\n",
    "    print('{} has woken up from sleep'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then initialize our thread with the `Thread` class from the `threading` module.\n",
    "\n",
    "- `target`: accepts the function that we're going to execute.\n",
    "- `name`: naming the thread; this allows us to easily differentiate between threads when we have multiple threads.\n",
    "- `args`: pass in the argument to our function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am thread1. Going to sleep for 2 seconds\n",
      "thread1 has woken up from sleep\n"
     ]
    }
   ],
   "source": [
    "# we call .start to start executing the function from the thread\n",
    "n_time = 2\n",
    "thread = threading.Thread(target = sleeper, name = 'thread1', args = (n_time,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run a program and something is sleeping for a few seconds, we would have to wait for that portion to wake up before we can continue with the rest of the program, but the concurrency of threads can bypass this behavior. Suppose we consider the main program as the main thread and our thread as its own separate thread, the code chunk below demonstrates the concurrency property, i.e. we don't have to wait for the calling thread to finish before running the rest of our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am thread2. Going to sleep for 2 seconds\n",
      "\n",
      "hello\n",
      "thread2 has woken up from sleep\n"
     ]
    }
   ],
   "source": [
    "# hello is printed \"before\" the wake up message from the function\n",
    "thread = threading.Thread(target = sleeper, name = 'thread2', args = (n_time,))\n",
    "thread.start()\n",
    "\n",
    "print()\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we don't want Python to switch to the main thread until the thread we defined has finished executing its function. To do this, we can use `.join` method, this is essentially what people called the blocking call. It blocks the interpreter from accessing or executing the main program until the thread finishes it task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'threading' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0baf70d0fb76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# hello is printed \"after\" the wake up message from the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mthread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msleeper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'thread3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'threading' is not defined"
     ]
    }
   ],
   "source": [
    "# hello is printed \"after\" the wake up message from the function\n",
    "thread = threading.Thread(target = sleeper, name = 'thread3', args = (n_time,))\n",
    "thread.start()\n",
    "thread.join()\n",
    "\n",
    "print()\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading\n",
    "\n",
    "The following code chunk showcase how to initialize and utilize multiple threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am thread_0. Going to sleep for 2 seconds\n",
      "I am thread_1. Going to sleep for 2 seconds\n",
      "I am thread_2. Going to sleep for 2 seconds\n",
      "I am thread_3. Going to sleep for 2 secondsI am thread_4. Going to sleep for 2 seconds\n",
      "\n",
      "thread_0 has woken up from sleepthread_2 has woken up from sleepthread_3 has woken up from sleepthread_1 has woken up from sleepthread_4 has woken up from sleep\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Elapse time: \n",
      " 2.0075490474700928\n"
     ]
    }
   ],
   "source": [
    "n_time = 2\n",
    "n_threads = 5\n",
    "start = time.time()\n",
    "\n",
    "# create n_threads number of threads and store them in a list\n",
    "threads = []\n",
    "for i in range(n_threads):\n",
    "    name = 'thread_{}'.format(i)\n",
    "    args = n_time, name\n",
    "    thread = threading.Thread(target = sleeper, name = name, args = args)\n",
    "    threads.append(thread)\n",
    "    # we can start the thread while we're creating it, or move\n",
    "    # this to its own loop\n",
    "    thread.start()\n",
    "\n",
    "# we could instead start the thread in a separate loop\n",
    "# for thread in threads:\n",
    "#     thread.start()\n",
    "\n",
    "# ensure all threads have finished before executing main program\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "elapse = time.time() - start\n",
    "print()\n",
    "print('Elapse time: ', elapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, we can observe from the elapse time that it doesn't take n_threads * (the time we told the sleep function to sleep) amount of time to finish all the task.\n",
    "\n",
    "## Locks\n",
    "\n",
    "The next topic is to introduce **Locks**. Locks are used when multiple threads are trying to access the same variable. By using locks we can guard ourselves from accessing the same object from multiple threads simultaneously, which can potentially corrupt our data.\n",
    "\n",
    "For example, consider we have a program that does some kind of I/O processing and simply keeps track of how many items have we processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    \"\"\"Just count some stuff\"\"\"\n",
    "    def __init__(self, count = 0):\n",
    "        self.count = count\n",
    "        \n",
    "    def increment(self):\n",
    "        self.count += 1\n",
    "\n",
    "\n",
    "def worker(counter, n_times):\n",
    "    \"\"\"increment by Counter class object for n_times\"\"\"\n",
    "    for _ in range(n_times):\n",
    "        counter.increment()\n",
    "\n",
    "\n",
    "def run_threads(n_threads, target, args):\n",
    "    threads = []\n",
    "    for i in range(n_threads):\n",
    "        thread = threading.Thread(target = target, args = args)\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count should be 500000, got 400154\n"
     ]
    }
   ],
   "source": [
    "n_threads = 5\n",
    "n_times = 10 ** 5\n",
    "counter = Counter()\n",
    "args = counter, n_times\n",
    "\n",
    "run_threads(n_threads, target = worker, args = args)\n",
    "print('count should be {}, got {}'.format(n_threads * n_times, counter.count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we ran the program from more than one thread, we find that the final counter value isn't necessarily correct (you can get correct results from time to time, but keep in mind that that's just a coincidence). The reason for this is that the increment operation is actually executed in three steps behind the scenes.\n",
    "\n",
    "1. The Python interpreter fetches the current value of the counter\n",
    "2. Calculates the new value (in this case just increment it)\n",
    "3. Finally, writes the new value back to the variable\n",
    "\n",
    "```python\n",
    "# normal increment for thread A\n",
    "value_a = counter.count\n",
    "value_a += 1\n",
    "counter.count = value_a\n",
    "```\n",
    "\n",
    "This can be problematic if another thread gets a hold of the old variable before the current thread writes back the new value. i.e.\n",
    "\n",
    "```python\n",
    "# thread A\n",
    "value_a = counter.count\n",
    "# thread B\n",
    "value_b = counter.count\n",
    "\n",
    "# thread A and thread B both increment on the old count\n",
    "value_b += 1\n",
    "value_a += 1\n",
    "counter.count = value_b\n",
    "counter.count = value_a\n",
    "```\n",
    "\n",
    "Since both threads are seeing the same original value, only one increment will be accounted for. To prevent this type of problems from occuring when accessing a shared resource, the threading module provides the Lock class. By using the lock, only one thread will be able to acquire the lock at any given point of time. If a thread attemps to hold a lock that's already held by some other thread, its exeuction is postponed until the lock is released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    \n",
    "    def __init__(self, count = 0):\n",
    "        self.count = count\n",
    "        self._lock = threading.Lock()\n",
    "        \n",
    "    def increment(self):\n",
    "        \"\"\"\n",
    "        putting the shared resource count\n",
    "        within the with block will acquire\n",
    "        and release the lock for us\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            self.count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count should be 500000, got 500000\n"
     ]
    }
   ],
   "source": [
    "n_threads = 5\n",
    "n_times = 10 ** 5\n",
    "counter = Counter()\n",
    "args = counter, n_times\n",
    "run_threads(n_threads, target = worker, args = args)\n",
    "print('count should be {}, got {}'.format(n_threads * n_times, counter.count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue\n",
    "\n",
    "Queues are basically a container of data/commands that are waiting to be retrieved. We can utilize them to control the flow of our tasks. Say we're receiving data from a website, we need to manipulate the data and write the data to a file. We have this three step process where each step sort of relies on the previous step (we can't manipulate the data if we haven't received the data and we don't want to save the data to the file if it hasn't gone through the preprocessing step). Queues help ensure this workflow is done in a very clean and organized manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# the following example demonstrates\n",
    "# FIFO Queue (First in First out, whatever we put in first will be\n",
    "# the first that gets pulled out);\n",
    "# there's also LIFO (Last in First out) and Priority Queue\n",
    "from queue import Queue\n",
    "\n",
    "# initialize the queue\n",
    "queue = Queue()\n",
    "\n",
    "# put items in the queue\n",
    "queue.put(5)\n",
    "\n",
    "# get the item out of the queue\n",
    "print(queue.get())\n",
    "\n",
    "# the queue is now empty because\n",
    "# we put 1 item in and pulled 1 item out\n",
    "print(queue.empty())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using queues one important thing to note is that if we try to pull more items than there are available from the queue our program will freeze. e.g.\n",
    "\n",
    "```python\n",
    "# we call a second get when there's only 1 item in the queue\n",
    "# which will result in a freeze\n",
    "queue = Queue()\n",
    "queue.put(5)\n",
    "queue.get()\n",
    "queue.get()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer waiting\n",
      "Producer puttingConsumer done\n",
      "\n",
      "Producer done\n"
     ]
    }
   ],
   "source": [
    "queue = Queue()\n",
    "\n",
    "def consumer(queue):\n",
    "    print('Consumer waiting')\n",
    "    queue.get()                # Runs after put() below\n",
    "    print('Consumer done')\n",
    "\n",
    "thread = threading.Thread(target = consumer, args = (queue,))\n",
    "thread.start()\n",
    "\n",
    "# Example 12\n",
    "print('Producer putting')\n",
    "queue.put(1)            # Runs before get() above\n",
    "thread.join()\n",
    "print('Producer done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def putting(queue):\n",
    "    while True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daemon Threads\n",
    "\n",
    "Daemon is an attribute for our threads. i.e. when we initialize the threads we have an option to set daemon as true or false. What daemon does is that it ends the thread when the main program finishes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclassing\n",
    "\n",
    "When we subclass the `Thread` class we actually gain some flexibility such as making tweaks as to how the threads execute. When subclassing the `Thread` class it's advisable to only make changes to the `__init__` and `run` method.\n",
    "\n",
    "The `run` method is closely related to the `.start()` method that we're calling. What happens is when we call the `.start()` method it actually calls the `run` method underneath the hood. The `run` method is then responsible for running the function that we gave. Let's look at the source code of the `run` method (with some additional added comments) to see where we can make our tweaks.\n",
    "\n",
    "```python\n",
    "def run(self):\n",
    "    \"\"\"Method representing the thread's activity.\n",
    "    You may override this method in a subclass. \n",
    "    The standard run() method\n",
    "    invokes the callable object passed to \n",
    "    the object's constructor as the\n",
    "    target argument, if any, with sequential and \n",
    "    keyword arguments taken\n",
    "    from the args and kwargs arguments, respectively.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # target is the callable object, a fancy word for\n",
    "        # a function, that we gave to the Thread class;\n",
    "        # and the *self._args and **self._kwargs is simply\n",
    "        # unpacking the argument or keyword argument that we gave\n",
    "        # to the function\n",
    "        if self._target:\n",
    "            self._target(*self._args, **self._kwargs)\n",
    "    finally:\n",
    "        # Avoid a refcycle if the thread is running a function with\n",
    "        # an argument that has a member that points to the thread.\n",
    "        del self._target, self._args, self._kwargs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thread = threading.Thread(target = sleeper, name = 'thread1', args = (3, 'thread1'))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to actually run tasks concurrently, Python uses another technique called task switching. Python rapidly switches between each thread to make it seem like our program is actually running multiple tasks in parallel.\n",
    "\n",
    "This can actually be very useful for event-driven tasks that have a lot of downtime and are waiting for the user to input something.\n",
    "\n",
    "Threads are really efficient at using any downtime or idle time, so when one thread is waiting for something we can have another thread performing another task. So in our first example, when one thread is sleeping or not using much of the CPU resources, we can switch to execute another task to make sure the CPU is always busy.\n",
    "\n",
    "When we have something that's CPU intensive, there's actually something called multiprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- youtube threading, blog and maybe safari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "- [Blog: Thread Synchronization Mechanisms in Python](http://effbot.org/zone/thread-synchronization.htm)\n",
    "- [Forum: Python Parallel Processing - Tips and Applications](http://forums.fast.ai/t/python-parallel-processing-tips-and-applications/2092)\n",
    "- [Youtube: Python Threading - Multithreading Playlist](https://www.youtube.com/playlist?list=PLGKQkV4guDKEv1DoK4LYdo2ZPLo6cyLbm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
