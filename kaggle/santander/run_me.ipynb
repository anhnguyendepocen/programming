{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('http://fonts.googleapis.com/css?family=Source+Code+Pro');\n",
       "@import url('http://fonts.googleapis.com/css?family=Vollkorn');\n",
       "@import url('http://fonts.googleapis.com/css?family=Arimo');\n",
       "@import url('http://fonts.googleapis.com/css?family=Fira_sans');\n",
       "    \n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "    div.text_cell code {\n",
       "        background: transparent;\n",
       "        color: #000000;\n",
       "        font-weight: 600;\n",
       "        font-size: 12pt;\n",
       "        font-style: bold;\n",
       "        font-family:  'Source Code Pro', Consolas, monocco, monospace;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "\t}\n",
       "\t\n",
       "    div.input_area {\n",
       "        background: #F6F6F9;\n",
       "        border: 1px solid #586e75;\n",
       "    }\n",
       "\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 30pt;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h2 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "        text-align: left;\n",
       "    }\n",
       "    .text_cell_render h2 {\n",
       "        font-weight: 200;\n",
       "        font-size: 16pt;\n",
       "        font-style: italic;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1.5em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h3 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h3 {\n",
       "        font-weight: 200;\n",
       "        font-size: 14pt;\n",
       "        line-height: 100%;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 2em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    }\n",
       "    h4 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h4 {\n",
       "        font-weight: 100;\n",
       "        font-size: 14pt;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    h5 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 200;\n",
       "        font-style: normal;\n",
       "        color: #1d3b84;\n",
       "        font-size: 16pt;\n",
       "        margin-bottom: 0em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: 'Fira sans', verdana,arial,sans-serif;\n",
       "        line-height: 125%;\n",
       "        font-size: 115%;\n",
       "        text-align:justify;\n",
       "        text-justify:inter-word;\n",
       "    }\n",
       "    div.output_wrapper{\n",
       "        margin-top:0.2em;\n",
       "        margin-bottom:0.2em;\n",
       "    }\n",
       "\n",
       "    code{\n",
       "      font-size: 70%;\n",
       "    }\n",
       "    .rendered_html code{\n",
       "    background-color: transparent;\n",
       "    }\n",
       "    ul{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li li{\n",
       "        padding-left: 0.2em; \n",
       "        margin-bottom: 0.2em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    ol{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ol li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "    .rendered_html :hover {\n",
       "       text-decoration: none; \n",
       "    }\n",
       "    .rendered_html :visited {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :focus {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :active {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "    } \n",
       "    hr {\n",
       "      color: #f3f3f3;\n",
       "      background-color: #f3f3f3;\n",
       "      height: 1px;\n",
       "    }\n",
       "    blockquote{\n",
       "      display:block;\n",
       "      background: #fcfcfc;\n",
       "      border-left: 5px solid #c76c0c;\n",
       "      font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "      width:680px;\n",
       "      padding: 10px 10px 10px 10px;\n",
       "      text-align:justify;\n",
       "      text-justify:inter-word;\n",
       "      }\n",
       "      blockquote p {\n",
       "        margin-bottom: 0;\n",
       "        line-height: 125%;\n",
       "        font-size: 100%;\n",
       "      }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir( os.path.join('..', '..', 'notebook_format') )\n",
    "from formats import load_style\n",
    "load_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethen 2016-11-08 22:54:46 \n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.11.2\n",
      "pandas 0.18.1\n",
      "matplotlib 1.5.1\n",
      "xgboost 0.6\n",
      "scikit-learn 0.18\n",
      "scipy 0.18.1\n",
      "keras 1.1.1\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 8, 6 # change default figure size\n",
    "\n",
    "# 1. magic to print version\n",
    "# 2. magic so that the notebook will reload external python modules\n",
    "%load_ext watermark\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "# if you get a deprecation warning, \n",
    "# it is coming from XGBClassifier, since it's still using\n",
    "# from sklearn.cross_validation import RandomizedSearchCV\n",
    "# instead of the preferable new api\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "#from scipy.stats import randint, uniform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# import xgboost as xgb\n",
    "# from operator import itemgetter\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,matplotlib,xgboost,scikit-learn,scipy,keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### santander : 2016.05.16 (will come back to this in the future)\n",
    "\n",
    "Kaggle competition on predicting customer satisfaction. The goal is to familiarize myself with python's xgboost and H2O's API. Note that the script's auc store 0.823068 is still far off from the best score for the competition, 0.829072.\n",
    "\n",
    "- Includes scripts for performing cross validation with xgboost; Obtaining feature importance, saving and loading the model for xgboost and H2O. Details are commented in the following notebooks. \n",
    "- Data preprocessing and xgboost. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/kaggle/santander/run_me.ipynb)]\n",
    "- H2O's randomforest and gradient boosting on the already preprocessed data. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/kaggle/santander/h2o.ipynb)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Customers are Happy Customers?\n",
    "\n",
    "Kaggle's Santander Customer Satisfaction competition's [homepage](https://www.kaggle.com/c/santander-customer-satisfaction).\n",
    "\n",
    "Customer satisfaction is a key measure of success. Unhappy customers don't stick around. What's more, unhappy customers rarely voice their dissatisfaction before leaving. Santander Bank is asking Kagglers to help them identify dissatisfied customers early in their relationship. Doing so would allow Santander to take proactive steps to improve a customer's happiness before it's too late. In this competition, you'll predict if a customer is satisfied or dissatisfied with their banking experience. \n",
    "\n",
    "You are provided with an anonymized dataset containing a large number of numeric variables. The \"TARGET\" column is the variable to predict. It equals 1 for unsatisfied customers and 0 for satisfied customers. The task is to predict the probability that each customer in the test set is an unsatisfied customer.\n",
    "\n",
    "**Evaluation:** Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n",
    "\n",
    "**Submission File:** For each ID in the test set, you must predict a probability for the TARGET variable. The file should contain a header and have the following format:\n",
    "\n",
    "```\n",
    "ID,TARGET\n",
    "2,0\n",
    "5,0\n",
    "6,0\n",
    "```\n",
    "\n",
    "To run the script please download the training and testing dataset from the competition webpage and store both of them in the same directory called `data`.\n",
    "\n",
    "## Some Tricks Worth Noting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         inf\n",
       "1         NaN\n",
       "2    0.000000\n",
       "3    0.033333\n",
       "4        -inf\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame.isnull().any().any()\n",
    "# with .isnull().any(), you can find just the columns that have NaN values,\n",
    "# and another .any() indicates whether there're any missing values in the entire dataframe\n",
    "\n",
    "# with DataFrame, 0 / 0 results in NaN, while some number / 0 results in +- inf\n",
    "# remember to fix this in data preprocessing\n",
    "df = pd.DataFrame({ 'a': [ 1, 0, 0, 1, -5 ], 'b': [ 0, 0, 20, 30, 0 ] })\n",
    "df['a'] / df['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "training data dimension: (76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3   ...    \\\n",
       "0                      0.0                      0.0   ...     \n",
       "1                      0.0                      0.0   ...     \n",
       "2                      0.0                      0.0   ...     \n",
       "3                      0.0                      0.0   ...     \n",
       "4                      0.0                      0.0   ...     \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "train = pd.read_csv( os.path.join('data', 'train.csv') )\n",
    "test = pd.read_csv( os.path.join('data', 'test.csv') )\n",
    "print( 'training data dimension: {}'.format(train.shape) )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73012</td>\n",
       "      <td>96.043147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3008</td>\n",
       "      <td>3.956853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET  Percentage\n",
       "0   73012   96.043147\n",
       "1    3008    3.956853"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of the TARGET variable. \n",
    "# It's important to understand whether the data is balanced or not.\n",
    "# The result tells us that a little less then 4% are unhappy and \n",
    "# it is an unbalanced dataset\n",
    "df_target = pd.DataFrame( train['TARGET'].value_counts() )\n",
    "df_target['Percentage'] = 100 * df_target['TARGET'] / train.shape[0]\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Data shape after removing constant columns: (60816, 334)\n",
      "Data shape after removing duplicated columns: (60816, 305)\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessing data...')\n",
    "\n",
    "# extract the output (target) and id column for both train and test\n",
    "train_id = train['ID'].values\n",
    "target = train['TARGET'].values\n",
    "train = train.drop( ['ID', 'TARGET'], axis = 1 )\n",
    "test_id = test['ID'].values\n",
    "test = test.drop('ID', axis = 1)\n",
    "\n",
    "# split train into train, validation\n",
    "# pass in the target class's column to perform stratified sampling,\n",
    "# which is preferred for unbalanced dataset, since the splitted folds are \n",
    "# made by preserving the percentage of samples for each output class\n",
    "train, val, y_train, y_val = train_test_split( \n",
    "    train,\n",
    "    target,\n",
    "    test_size = 0.2,\n",
    "    random_state = 1234,\n",
    "    stratify = target\n",
    ")\n",
    "\n",
    "# removing outliers and replacing it with mode\n",
    "# 116 values in column var3 are -999999. This value suggests that the \n",
    "# column value for this customer is unknown and should be dealt with. \n",
    "# e.g. replace it with the mode of the column, which is 2. \n",
    "# In real world situations, it's better to consult with domain expert \n",
    "# and check the exact cause of this number.\n",
    "outliers = -999999\n",
    "mode = int( train['var3'].mode() )\n",
    "train['var3'] = train['var3'].replace(outliers, mode)\n",
    "val['var3'] = val['var3'].replace(outliers, mode)\n",
    "test['var3'] = test['var3'].replace(outliers, mode)\n",
    "\n",
    "# add feature that counts the number of zeros in a row\n",
    "train['zeroes'] = np.sum(train == 0, axis = 1)\n",
    "val['zeroes'] = np.sum(val == 0, axis = 1)\n",
    "test['zeroes'] = np.sum(test == 0, axis = 1)\n",
    "\n",
    "# remove constant columns where its standard deviation is 0 (value of each row is identical)\n",
    "constant_cols = [ col for col in train.columns if train[col].std() == 0 ]\n",
    "train = train.drop(constant_cols, axis = 1)\n",
    "val = val.drop(constant_cols, axis = 1)\n",
    "test = test.drop(constant_cols, axis = 1)\n",
    "print( 'Data shape after removing constant columns: {}'.format(train.shape) )\n",
    "\n",
    "# 1. remove duplicated columns (columns that have the exact same values),\n",
    "#    keep only 1 of them. Do not check the ones that have been confirmed as not duplicates\n",
    "# 2. cols are the columns that needs to be checked for duplicates\n",
    "remove_col = []\n",
    "cols = [ col for col in train.columns if col not in ['var3', 'var15', 'var38'] ]\n",
    "for i in range( len(cols) - 1 ):\n",
    "    v = train[ cols[i] ].values\n",
    "    for j in range( i + 1, len(cols) ):\n",
    "        if np.array_equal( v, train[ cols[j] ].values ):\n",
    "            remove_col.append(cols[j])\n",
    "\n",
    "train = train.drop(remove_col, axis = 1)\n",
    "val = val.drop(remove_col, axis = 1)\n",
    "test = test.drop(remove_col, axis = 1)\n",
    "print( 'Data shape after removing duplicated columns: {}'.format(train.shape) )\n",
    "\n",
    "# standardize\n",
    "std = StandardScaler()\n",
    "X_train_std = std.fit_transform(train)\n",
    "X_val_std  = std.transform(val)\n",
    "X_test_std = std.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 13.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score obtained: 0.834778567766767\n",
      "Parameters:\n",
      "\tcolsample_bytree: 0.8580929395024223\n",
      "\tmax_depth: 5\n",
      "\tsubsample: 0.7086327849808082\n"
     ]
    }
   ],
   "source": [
    "from model_xgb import build_model_xgb\n",
    "rs_xgb = build_model_xgb(X_train_std, y_train, X_val_std, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_submission(models, X_test):\n",
    "    # create a submission directory\n",
    "    # all the predicted result's .csv file will be stored in it\n",
    "    dir_submission = 'submission'\n",
    "    if not os.path.isdir(dir_submission):\n",
    "        os.makedirs(dir_submission)\n",
    "    \n",
    "    for model in models:      \n",
    "        best = model.best_estimator_\n",
    "        model_name = best.__class__.__name__\n",
    "        \n",
    "        if model_name == 'XGBClassifier':\n",
    "            # access the best number of trees to make prediction on the test set\n",
    "            ntree_limit = best.best_ntree_limit\n",
    "            y_pred_prob = best.predict_proba(X_test, ntree_limit = ntree_limit)[:, 1]\n",
    "        else:\n",
    "            y_pred_prob = best.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        submission = pd.DataFrame({ 'ID': test_id, 'TARGET': y_pred_prob })\n",
    "        submission.to_csv( os.path.join(dir_submission, model_name + '.csv'), index = False )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_submission(models = [rs_xgb], X_test = X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "12163/12163 [==============================] - 12s    \n",
      "12163/12163 [==============================] - 12s    \n",
      "48653/48653 [==============================] - 46s    \n",
      "  992/12163 [=>............................] - ETA: 10s\n",
      " 5952/12163 [=============>................] - ETA: 5s\n",
      "11072/48652 [=====>........................] - ETA: 35s\n",
      "13216/48653 [=======>......................] - ETA: 31s\n",
      "37440/48652 [======================>.......] - ETA: 9s\n",
      "13184/48653 [=======>......................] - ETA: 18s\n",
      "26144/48653 [===============>..............] - ETA: 11s\n",
      " 5120/12163 [===========>..................] - ETA: 1s\n",
      " 7488/12163 [=================>............] - ETA: 1s\n",
      "48653/48653 [==============================] - 12s    \n",
      "48653/48653 [==============================] - 18s    \n",
      "12163/12163 [==============================] - 12s    \n",
      "39680/48653 [=======================>......] - ETA: 8s\n",
      " 3968/12163 [========>.....................] - ETA: 2s\n",
      "23264/48653 [=============>................] - ETA: 5s\n",
      "43296/48653 [=========================>....] - ETA: 1s\n",
      "48653/48653 [==============================] - 9s     \n",
      "48640/48653 [============================>.] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score obtained: 0.960438042620363\n",
      "Parameters:\n",
      "\tdropout_rate: 0.2\n",
      "\thidden_layers: [64, 64, 64]\n",
      "\tl2_penalty: 0.5\n"
     ]
    }
   ],
   "source": [
    "from model_keras import build_model_keras\n",
    "rs_keras = build_model_keras(X_train_std, y_train, X_val_std, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75680/75818 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# add class weight\n",
    "# https://www.kaggle.com/c/santander-customer-satisfaction/forums/t/19978/help-with-keras/114566\n",
    "write_submission(models = [rs_keras], X_test = X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>f137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>f165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>f166</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>f167</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>f168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importances\n",
       "137    f137          0.0\n",
       "165    f165          0.0\n",
       "166    f166          0.0\n",
       "167    f167          0.0\n",
       "168    f168          0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also access the feature importance and visualize it\n",
    "importances = rs_xgb.best_estimator_.feature_importances_\n",
    "\n",
    "# give a name for each feature, here it is 'f' + the feature column number \n",
    "features = [ 'f' + str(imp) for imp in np.arange(len(importances)) ]\n",
    "# create df\n",
    "importances_df = pd.DataFrame({\n",
    "    'importances': importances,\n",
    "    'feature': features\n",
    "}).sort_values( by = 'importances' )\n",
    "\n",
    "importances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00742574,  0.14480197,  0.00990099,  0.00866337,  0.00495049,\n",
       "        0.00123762,  0.        ,  0.00742574,  0.        ,  0.00123762,\n",
       "        0.00123762,  0.00123762,  0.01980198,  0.01361386,  0.00866337,\n",
       "        0.00495049,  0.00247525,  0.00990099,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.00495049,  0.00123762,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.00247525,  0.        ,\n",
       "        0.00123762,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.00247525,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.00123762,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.00123762,\n",
       "        0.00123762,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.00618812,  0.        ,  0.00123762,  0.00247525,  0.        ,\n",
       "        0.        ,  0.00123762,  0.00123762,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.00371287,  0.00123762,  0.00123762,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.01237624,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.01237624,  0.        ,\n",
       "        0.00371287,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.00247525,  0.        ,  0.10519802,  0.00247525,\n",
       "        0.00123762,  0.        ,  0.        ,  0.01113861,  0.        ,\n",
       "        0.00495049,  0.        ,  0.00123762,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.00866337,  0.00371287,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.01361386,  0.01113861,  0.02351485,  0.03465347,\n",
       "        0.02970297,  0.00495049,  0.00495049,  0.00742574,  0.00247525,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.00866337,  0.        ,  0.00371287,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.00371287,  0.        ,  0.00371287,  0.        ,  0.00247525,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.00123762,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.00990099,  0.03465347,  0.00371287,  0.01608911,\n",
       "        0.05816832,  0.03465347,  0.02722772,  0.0259901 ,  0.00247525,\n",
       "        0.        ,  0.00618812,  0.00495049,  0.        ,  0.        ,\n",
       "        0.        ,  0.00247525,  0.00371287,  0.00123762,  0.        ,\n",
       "        0.00123762,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.12376238,  0.03589109], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_xgb.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define xgboost parameters\n",
    "# for complete list and detailed explanation\n",
    "# http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "xgb_params = {\n",
    "    'eta': 0.1, # learning rate\n",
    "    'objective': 'binary:logistic', # 'multi:softprob' for multi-class \n",
    "    'max_depth': 6, # length of the longest path from a root to a leaf\n",
    "    'colsample_bytree': 0.8, # subsample ratio of columns when constructing each tree\n",
    "    'max_delta_step': 1, # setting it might help when class is extremely imbalanced\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': -1,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retain_important_features( train, test, target, xgb_params ):\n",
    "    \"\"\"\n",
    "    Pass in the DataFrame training, testing data; the target column\n",
    "    and the dictionary that contains the parameters for the xgboost model\n",
    "    to build the model, return the important features and predict the target column's\n",
    "    probability. Note that the training and testing set's data type has to be the \n",
    "    same, or else xgboost's prediction might fail\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train, test : DataFrame\n",
    "        the training and testing data with only the important features retained, the \n",
    "        important features are calculated by the xgboost model\n",
    "    \n",
    "    imp_df : DataFrame with column name 'feature' and 'fscore'\n",
    "        consists of the important feature and its relative importance score, note that\n",
    "        only features with relative importance score about the mean are retained\n",
    "    \n",
    "    probs : 1d-array\n",
    "        probability of the target, predicted by the xgboost model during the best round\n",
    "    \"\"\"\n",
    "    \n",
    "    # pass in the target class's column to perform stratified sampling,\n",
    "    # which is preferred for unbalanced dataset, since the splitted folds are \n",
    "    # made by preserving the percentage of samples for each output class\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split( \n",
    "        train, # X\n",
    "        target, # y\n",
    "        test_size = 0.3,\n",
    "        stratify = target\n",
    "    )\n",
    "    \n",
    "    # check that the class's percentage in train and test are the same\n",
    "    print( 'train class dist: {}'.format( np.bincount(y_train) / y_train.shape[0] ) )\n",
    "    print( 'valid class dist: {}'.format( np.bincount(y_valid) / y_valid.shape[0] ) )\n",
    "    \n",
    "    # construct the DMatrix data structure used for xgboost,\n",
    "    # and the watchlist that evaluates the training and testing,\n",
    "    # this is used with early stopping that prevents the algorithm\n",
    "    # from over-training the training set\n",
    "    X_dtrain = xgb.DMatrix( X_train, label = y_train )\n",
    "    X_dvalid = xgb.DMatrix( X_valid, label = y_valid )\n",
    "    watchlist = [ ( X_dtrain, 'train' ), ( X_dvalid, 'test' ) ]\n",
    "\n",
    "    xgb_model = xgb.train( \n",
    "        params = xgb_params, \n",
    "        dtrain = X_dtrain,\n",
    "        num_boost_round = 300, # set it to a large number and let early stopping handle it\n",
    "        evals = watchlist, \n",
    "        early_stopping_rounds = 3,\n",
    "        verbose_eval = 10 # an evaluation metric is printed every specified number of boosting stages\n",
    "    )\n",
    "    \n",
    "    # obtain the important variables calculated by the model\n",
    "    # and re-compute its relative importance score\n",
    "    importance = xgb_model.get_fscore()\n",
    "    importance = sorted( importance.items(), key = itemgetter(1) )\n",
    "    imp_df = pd.DataFrame( importance, columns = [ 'feature', 'fscore' ] ) \n",
    "    imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()\n",
    "    \n",
    "    # only retain the variables that are higher than\n",
    "    # the mean relative importance score (you can change the threshold)\n",
    "    # you can easily tune the cutoff with the quantile\n",
    "    imp_df = imp_df[ imp_df['fscore'] >= imp_df['fscore'].quantile(0.5) ]\n",
    "    imp_cols = imp_df['feature'].values.tolist()\n",
    "    \n",
    "    # predict the entire test set\n",
    "    # If early stopping is enabled during training, \n",
    "    # you can get predicticions from the best iteration by setting \n",
    "    # the specifying the ntree_limit = .best_ntree_limit\n",
    "    dtest = xgb.DMatrix(test)\n",
    "    probs = xgb_model.predict( dtest, ntree_limit = xgb_model.best_ntree_limit )\n",
    "        \n",
    "    return train[imp_cols], test[imp_cols], imp_df, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train class dist: [ 0.96042395  0.03957605]\n",
      "valid class dist: [ 0.960449  0.039551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until test error hasn't decreased in 3 rounds.\n",
      "[0]\ttrain-auc:0.503740\ttest-auc:0.502635\n",
      "[10]\ttrain-auc:0.725146\ttest-auc:0.706908\n",
      "[20]\ttrain-auc:0.837847\ttest-auc:0.814148\n",
      "Stopping. Best iteration:\n",
      "[25]\ttrain-auc:0.855341\ttest-auc:0.825456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model for the first time\n",
    "train1, test1, imp_df1, probs1 = retain_important_features( \n",
    "    train = train, \n",
    "    test = test,\n",
    "    target = target, \n",
    "    xgb_params = xgb_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 45)\n"
     ]
    }
   ],
   "source": [
    "print(train1.shape)\n",
    "\n",
    "# auc 0.806928\n",
    "submission1 = pd.DataFrame({ 'ID': test_id, 'TARGET': probs1 })\n",
    "submission1.to_csv( os.path.join( dirs, 'submission1.csv' ), index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomly generate interaction between all feature combinations\n",
    "# here, it is done by subtracting the first column with the second\n",
    "# and divide it with the first (you can try other interactions),\n",
    "# not a good idea in real world application\n",
    "train_col_len = len(train1.columns)\n",
    "\n",
    "for i in range(train_col_len):\n",
    "    col1 = train1.columns[i]    \n",
    "    \n",
    "    for j in range(train_col_len):        \n",
    "        col2 = train1.columns[j]\n",
    "        col_name = col1 + '_SUBTRACT_' + col2 + '_DIVIDE_' + col1\n",
    "        train1[col_name] = ( train1[col1] - train1[col2] ) / train1[col1]\n",
    "        test1[col_name]  = ( test1[col1] - test1[col2] ) / test1[col1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after randomly generating interations: (76020, 2070)\n"
     ]
    }
   ],
   "source": [
    "# replace the nan and inf generated from the manual interaction\n",
    "# with numbers specifying different conditions (how they were generated)\n",
    "train1 = train1.replace( np.inf, 999999 )\n",
    "train1 = train1.replace( -np.inf, -999999 )\n",
    "train1 = train1.replace( np.nan, -1 )\n",
    "test1  = test1.replace( np.inf, 999999 )\n",
    "test1  = test1.replace( -np.inf, -999999 )\n",
    "test1  = test1.replace( np.nan, -1 )\n",
    "print( 'Data shape after randomly generating interations: {}'.format(train1.shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train class dist: [ 0.96042395  0.03957605]\n",
      "valid class dist: [ 0.960449  0.039551]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until test error hasn't decreased in 3 rounds.\n",
      "[0]\ttrain-auc:0.507234\ttest-auc:0.501343\n",
      "[10]\ttrain-auc:0.616221\ttest-auc:0.606890\n",
      "[20]\ttrain-auc:0.851380\ttest-auc:0.817330\n",
      "[30]\ttrain-auc:0.876209\ttest-auc:0.834318\n",
      "Stopping. Best iteration:\n",
      "[34]\ttrain-auc:0.881701\ttest-auc:0.835357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# include the interaction and train the model for the second time\n",
    "train2, test2, imp_df2, probs2 = retain_important_features( \n",
    "    train = train1, \n",
    "    test = test1, \n",
    "    target = target, \n",
    "    xgb_params = xgb_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 561)\n"
     ]
    }
   ],
   "source": [
    "print(train2.shape)\n",
    "\n",
    "# auc 0.820486\n",
    "submission2 = pd.DataFrame({ 'ID': test_id, 'TARGET': probs2 })\n",
    "submission2.to_csv( os.path.join( dirs, 'submission2.csv' ), index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_preprocessed_data( train, test, target, train_id, test_id ):\n",
    "    \"\"\"\n",
    "    usually a good idea to store the preprocessed data,\n",
    "    add the TARGET and ID column back\n",
    "    \"\"\"\n",
    "    \n",
    "    # copy the train and test to avoid overwriting the original one,\n",
    "    # in case you simply want to write it out and still want to continue to \n",
    "    # perform other actions \n",
    "    train_copy = train.copy()\n",
    "    test_copy  = test.copy()\n",
    "    \n",
    "    train_copy['TARGET'] = target\n",
    "    train_copy['ID'] = train_id\n",
    "    test_copy['ID'] = test_id\n",
    "\n",
    "    train_copy.to_csv( \"df_train.csv\", index = False )\n",
    "    test_copy.to_csv(  \"df_test.csv\" , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_preprocessed_data( \n",
    "    train = train2, \n",
    "    test = test2, \n",
    "    target = target, \n",
    "    train_id = train_id, \n",
    "    test_id = test_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# xgboost's cross validation currently does not return a model according to\n",
    "# https://github.com/dmlc/xgboost/pull/1156\n",
    "def xgboost_cv( train, test, target, n_folds, xgb_params ):\n",
    "    \"\"\"\n",
    "    xgboost cross validation with stratified k-fold;\n",
    "    pass in the DataFrame training and testing set; target column;\n",
    "    number of folds used for cross validation; and the dictionary\n",
    "    that holds the parameter for xgboost.\n",
    "    during the training process, the auc score for each fold is printed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xgb_models : list\n",
    "        stores the xgboost model for each fold\n",
    "        \n",
    "    cv_auc : float\n",
    "        cross validated auc score\n",
    "        \n",
    "    test_pred : 1d-array\n",
    "        predicted target probability of the test set\n",
    "    \"\"\"\n",
    "\n",
    "    predicted_result = np.zeros(train.shape[0]) # prediction on the out of fold sample\n",
    "    test_pred  = [] # stores the predicted probability of the test set\n",
    "    xgb_models = [] # stores each fold's xgb model\n",
    "    dtest = xgb.DMatrix(test.values)\n",
    "    \n",
    "    skf = StratifiedKFold( y = target, n_folds = n_folds )\n",
    "    for idx, ( train_idx, test_idx ) in enumerate(skf):\n",
    "\n",
    "        train_fold, test_fold = train.values[train_idx], train.values[test_idx]\n",
    "        train_target, test_target = target[train_idx], target[test_idx]\n",
    "        dtrain_fold = xgb.DMatrix( train_fold, label = train_target ) \n",
    "        \n",
    "        # without early stopping, this takes too long consider the size of\n",
    "        # of data is still really small\n",
    "        xgb_fold = xgb.train( \n",
    "            params = xgb_params, \n",
    "            dtrain = dtrain_fold, \n",
    "            num_boost_round = 100  \n",
    "        )\n",
    "        xgb_models.append(xgb_fold)\n",
    "\n",
    "        # only predict the folded test set\n",
    "        dtest_fold = xgb.DMatrix(test_fold)\n",
    "        xgb_pred = xgb_fold.predict( dtest_fold, ntree_limit = xgb_fold.best_ntree_limit )    \n",
    "        predicted_result[test_idx] = xgb_pred\n",
    "        fold_auc = roc_auc_score( y_true = test_target, y_score = xgb_pred )\n",
    "        print( 'auc for fold {}: {}'.format( idx + 1, fold_auc ) )\n",
    "\n",
    "        # predict the entire test set\n",
    "        test_pred.append( xgb_fold.predict( dtest, ntree_limit = xgb_fold.best_ntree_limit ) )\n",
    "    \n",
    "    # the final reported predicted probability is the average of all folds\n",
    "    test_pred = np.average( np.array(test_pred), axis = 0 )\n",
    "    \n",
    "    # report the out-of-fold sample's score\n",
    "    cv_auc = roc_auc_score( y_true = target, y_score = predicted_result )\n",
    "\n",
    "    return xgb_models, cv_auc, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'eta': 0.02,\n",
       " 'eval_metric': 'auc',\n",
       " 'max_delta_step': 1,\n",
       " 'max_depth': 6,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'silent': 1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decrease the learning rate eta;\n",
    "# subsample: subsample ratio of rows to fit the model\n",
    "updated_params = {\n",
    "    'eta': 0.02,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'subsample': 0.7\n",
    "}\n",
    "xgb_params.update(updated_params)\n",
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc for fold 0: 0.8307217519252451\n",
      "auc for fold 1: 0.8345786117852387\n",
      "auc for fold 2: 0.8172354763216798\n",
      "auc for fold 3: 0.8354173482811484\n",
      "auc for fold 4: 0.8409597556608319\n",
      "auc for fold 5: 0.8387707777708511\n",
      "auc for fold 6: 0.8509729473184622\n",
      "auc for fold 7: 0.8608139057089982\n",
      "auc for fold 8: 0.8587250604939962\n",
      "auc for fold 9: 0.8246183171255079\n"
     ]
    }
   ],
   "source": [
    "xgb_models, cv_auc, test_pred = xgboost_cv( \n",
    "    train = train2, \n",
    "    test = test2, \n",
    "    target = target, \n",
    "    n_folds = 10,\n",
    "    xgb_params = xgb_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.838307665615\n"
     ]
    }
   ],
   "source": [
    "# auc 0.823068\n",
    "print(cv_auc)\n",
    "submission_cv = pd.DataFrame({ \"ID\": test_id, \"TARGET\": test_pred })\n",
    "submission_cv.to_csv( os.path.join( dirs, 'submission_cv.csv' ), index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. saving and loading the DMatrix data structure\n",
    "# dtest.save_binary('dtest.buffer')\n",
    "# dtest2 = xgb.DMatrix('dtest.buffer')\n",
    "\n",
    "# 2. saving and loading the model\n",
    "# xgb_model.save_model(\"xgb.model\")\n",
    "# xgb2 = xgb.Booster( model_file = \"xgb.model\" ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAGNCAYAAAC2Wc0RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYZWV5rvH7EYSITSM5ioADRtsBJ5qmIQ4o0T4OwUSN\nqEfFkRzjMXGI8eAxJooapwQxoolRoyKKikgGMaghadHYToBNta1oUKZGEREZHVH7PX+sVbApqpqv\ne1evmu7fde2LWuP+9lNF9VvfevfaqSokSZI0nFvM9QAkSZKWGgswSZKkgVmASZIkDcwCTJIkaWAW\nYJIkSQOzAJMkSRqYBZgkSdLALMAkzSjJfyb53DTrP57kjCQ7jKy7Y5K/S/LtJD9L8oMkX07ysiT/\nY2S/zybZPPL4Uf88DxjqdY2M5ZdJntmw33H9WH89Mu5fJ3nyXIxne0tyepJ3z/U4tiTJg/vvw53n\neizStrAAk7QlzwLuk+T/Ta5I8jxgDXB4Vf26X7cSmAAeALwMWAkcBLwKuD/wnJFzFvAh4PbAnsDv\nAFcAn0yyy3Z+PeP4L7rxTj72Av51Tke0BUl2nOsxbC9JbgmE7mdJWpAswCTNqKq+B/wx8Nok+yW5\nJ3AM8H+r6tsju34A2AQcWFX/UlX/XVUXVdVpVfX0qnrzlFP/rKp+WFWXVdVG4LXAbYC7T+6Q5B5J\nTk1ybf84JcndRk+S5NAkZyX5eT/j9vejRVySeyf5dJIrk/w4yTeSHN5vu4Dud+D1s1s3E8d1I2Oe\nfFw38lxPSXJ2P/t3QZJjpozlf/YzSz9KclU/E3jgyPZpx5Pk2Ul+OeV136Hf56H98iH98qFJPp/k\np8Af9tsOSPLvfYaXJfmnrZ016sf9niR/1ed8Zf91krwqyaX9uV835bgLkrwuyT8muTrJD5O8fso+\ny5K8qz/+50nOTPKIke379K/taZM/D8AH6QpigAv77Z/p998/ySf7cV6bbqb2UdOM6zVJ3tp/Py5N\n8pYkt5iy35/0PzOTP18fG9m2Y5JXJzm//55vTPJHW5OrljYLMElbVFUnAR8FPgycAHy2qt45uT3J\nfsB9gb+ubfhss75IeQ7wQ+Db/brfAP4D2Al4CPBQYBnwqcmZnST3Bz4OfJZulu2ZwO8B/zBy+o8A\nl9PNzN0X+DPgyn7bgcBm4MXcMKO1TZI8G/h74GjgXsAz6GYJR8eyrN/nt4EHAucCn06y+82Mp5h+\npme6dW8G3gTsC3wiyb50+XwBWAU8DPgVcFqSnbbyZR4G7Ag8GHgJ8BfAqcAuwMHA/wVeMbXYAV4A\nfA9YDfwp8OIkLxzZfhzwCOBpwH79WP8tyT2mnOdNdD9/9wX+HHhcv341XV5P6JeXAycChwD7A58G\nPp5kxTTjuoRupvYF/eNZkxuTvAZ4I/B3/XM+AvjqyPHvAR4PPJfue/5a4E1JRmd7pZlVlQ8fPnxs\n8QHsBvwYuBrYY8q2JwG/Bvabsv5i4Nr+cerI+tOB60a2bQZ+ADxwZJ8/7J9v95F1ewA/BZ7eL38Q\n+PKU53xsP5Y79ctXAc/cwuv65Za2j+x3XL/vtSOPb45svwD4oynHPKR/bbvNcM5b0F16feqWxkNX\nFFw3Zd0d+nM/tF8+pF9+2jTj/vCUdTsDPwEeu4XXezrw7inL66fs83Vgw5R1E8DfTMnlc1P2eT1w\nUf/1in7cj5qyz1eB9/Rf79Pv84op+zy4/17fueH7NwH8+ZRx/euUfT4JfKj/epf+Z+0lM5zvLv1z\n32PK+lcCZ2/P/xd9LJ6HM2CSWjyDrudmF+CAGfbJlOWD6WY0Pgncasq2f6abtdqPbgbiVOBfktyp\n335v4JyqmpytoqouA/4buM/IPv/FjX2uH8e9++U3A+/tL6EdlWT/m3mdW/LlkTHvBzwKIMlt6YqE\nt4xcLr0W+BTdLNWKfr+7JPlgujcpXE1XzC7vj50NBZw5Zd2BwB9MGdfldEXY3aee4GZsmLJ8KfC1\nadbtMWXdl6YsfwG4Y5JldDN1BXx+yj7/xQ3f50lTX9u0ktw2yTuSfLO/VHot3c/D1JwnpixfQteX\nSP/cO9PNwk5nNd3P2VlTsn0FcLcZjpFuZNE2aUqaHf1lrL8GXkj3D9N7k9y3qq7odzmX7h+jfRn5\nR62qLuqPvwa43ZTTXlNVF/Rfn5/kf9MVJM+la9yfFVX1uiQnAI8GHk53ieyvq2pbnuNnI2MeNfmH\n7IvoLvdN9d3+v6cCl9H11F1MNwv4BbrLrFuyeZp1t5xh359MM7YP0l1Km1og/+hmnneqX05ZrhnW\nba8/7Ke+tpkcD9yR7pLohcDP6C6hT835uinLWzP2W/T7P7A//9TzSDfLGTBJM+r7rU4ATquq99H9\nhf8j4F2T+1TVBrrLUS/PeO+8K26YKfsGcO8kvzkyltsD9wQ2juzz0Cnn+B26guUbI+O7sKreWVVP\npivunj+y/3XADoyhn5m7GLhXVZ0/zeO6/nXsC7ypqv6jqr7VP/fU2aLpxnMZsEOS0SL2ANr+oT8L\nuH9VXTDNuK7elte7DabeXuTBwPeq6sfc8H2a+n18KN3P1JZMFlBT83oI8I6qOrWqvkF3efuuWzdk\nzgF+ATxyhu2TvWD7TJPrdEW6dBMWYJK25K+AvelmpqiqXwBPB34/yTNG9nsW3azDV5IcluReSVYk\nOYzuUuTUdxjeKsnt+8e+wNvpiq9T+u0fprtU9tH+XW0H0DVWXwyc1O9zNLCqf/faPZM8GngbcEJV\nfTfJrdPdl+xh/eW//elmwr4xMo4LgIcl2Ssj9yrbBn8BvCjJK5LcJ907OB+fZPLNClfSvcnguUnu\nnuSB/Wv86ZTzTDeeM+j64d7UZ/poul6jqabOcAG8Adg3yQlJDuxzeFj/7r+7jPF6t8bKdO+UvHuS\np9HNFL4ZoKrOB04G3pHkkf338Vi6mda/uZnzXkRXbB+a5HZJlvfr/xs4PMl9090e5cNs5b91VfUT\nunf7vjrJH/dj3y/Jy/vt59H11/1jkqcnuVuS+yd5TpIjt+a5tHRZgEmaVpIHAy8F/rCqLp9c3894\nvRo4Nskd+3Vn0/VFfYnu3Wpn949X0BVMT51y+qfR9dxcAnyR7t1qT6iqz/fn+zndu85+QdfXdTpw\nDfC7VfWrfp+NdE33D6G79Hk88AlumOH6FbA73bvVzqHryboUOHxkHC+lm026kG6maZtU1QnAk4HH\nAF+hK5peRX/5saoKeCJdf9AG4H3A3wLfn3Kqm4yn74N7Ct1M0ga6Ym+6f+RvMiPWz7Q9CLg13bsB\nv0E3e/kbdG9QmPEl3dy5t8Lb6fqvzgKOBd5WVW8b2f6HwL/TXSqdoLus95i68W1Opnttl9G9G/Ll\ndD9Hk/dkew7dv21foes1/BQ37R+72ddTVa+ky/qFdLOun6b7OZ30XLrv4Svocv1Punfinn9z55YA\n0v1ekCRpdqW7t9k/VtUb5nos0nzjDJgkSdLALMAkSduLl1ikGXgJUpIkaWDOgEmSJA3MG7FqLMcc\nc0ytXLlyrocx701MTGBObcyqjTm1Mad2ZtVmYmKCl770pdPd9mWrWIBpLBs2bOCII46Y62HMe6ed\ndhqrVq2a62EsCGbVxpzamFM7s2pz/PHHz8p5vASpsVx66aVzPYQFYdOmTXM9hAXDrNqYUxtzamdW\nw7IAkyRJGpgFmMbyqEc9aq6HsCA87WlPm+shLBhm1cac2phTO7Nqs99++83KebwNhcaydu3asmdA\nkrRUrF+/njVr1ozdhO8MmMYyMTEx10NYENatWzfXQ1gwzKqNObUxp3ZmNSwLMEmSpIF5CVJj8RKk\nJGkp8RKkJEnSAmUBprHYA9bG3op2ZtXGnNqYUzuzGpYFmCRJ0sDsAdNY7AGTJC0l9oBJkiQtUBZg\nGos9YG3srWhnVm3MqY05tTOrYVmASZIkDcweMI3FHjBJ0lIyWz1gO87GYLS0bbjk2rkegiRpntlj\n2U7stXznuR7GvGUBprFMTExw4uax/xBY9K45b4Lld1s518NYEMyqjTm1Mad2s53V0YeusADbAnvA\nJEmSBmYBprGsXOlfli38C7ydWbUxpzbm1M6shmUBJkmSNDALMI3F+4C1ueY8c2plVm3MqY05tTOr\nYVmASZIkDcwCTGOxB6yNvRXtzKqNObUxp3ZmNSwLMEmSpIFZgGks9oC1sbeinVm1Mac25tTOrIZl\nASZJkjQwCzCNxR6wNvZWtDOrNubUxpzamdWwLMCWsCSfSnJ2ko1J3pEk/fo7JflMkvVJJpL87lyP\nVZKkxcQCbInqi60nVdX+VXU/YA/gSf3mvwQ+WlWrgKcC75jpPPaAtbG3op1ZtTGnNubUzqyG5Ydx\nL2BJ3ghcXFXv6JePAn4FPAy4DXBL4JVVdUqSfYB/B74CrAIOraqL++NuCewEVH/qzcDy/uvbAN8b\n5hVJkrQ0OAO2sH0UePLI8pOB9wOPr6rVwMOBY0a2rwD+rqruN1J8fRq4FLgGOLnf7zXAM5JcDPwb\n8MKZBmAPWBt7K9qZVRtzamNO7cxqWM6ALWBVNZHkdkn2pLuEeAVdMXVskofQzWTtnWSP/pCLqurM\nKed4dJKdgA/RFWxr6S47HldVf5vkAcAJwH2mG8PJJ5/M+Weez8677wnADre6NbvsveL6/5Enp7Rd\ndtlll11eWssTZ3yJa2+7CwcffDAA69atA1hwy5Nfb9q0CYDVq1ezZs0axpWquvm9NG8leTXwI2BP\n4PvAtcCjgcOranOSC4BDgACfqKr7z3CeZwAHVtWLknwdeFRVfa/fdh7w21V1+dTjjjnmmDpx8/7b\n4ZUtLtecN+Ffl43Mqo05tTGndrOd1dGHrmC/vXedtfPNF+vXr2fNmjUZ9zxeglz4TgKeAhwGfAzY\nDbisL74eBuwzsu/1PzBJbt3PnJFkR+AxwDf7zRcB/7Pfti+w83TFlyRJ2jYWYAtcVZ0D7Ap8t6p+\nQHcp8cAkG4Cnc0NRBTc02QPcGjglyQSwHvgB8K5+2/8Fnttv+xDwrJme3x6wNv4F3s6s2phTG3Nq\nZ1bDsgdsERi9rFhVPwIeNMOuo/tdBhw0w/m+CRw8m2OUJEk3cAZMY/E+YG28v047s2pjTm3MqZ1Z\nDcsCTJIkaWAWYBqLPWBt7K1oZ1ZtzKmNObUzq2FZgEmSJA3MAkxjsQesjb0V7cyqjTm1Mad2ZjUs\nCzBJkqSBWYBpLPaAtbG3op1ZtTGnNubUzqyGZQEmSZI0MAswjcUesDb2VrQzqzbm1Mac2pnVsCzA\nJEmSBmYBprHYA9bG3op2ZtXGnNqYUzuzGpYFmCRJ0sD8MG6NZWJigqMPfdJcD2PemzjjS6w86IFz\nPYwFwazamFMbc2o321ntsWynWTvXYmQBprHtt/eucz2Eee/a2+5iTo3Mqo05tTGndmY1rFTVXI9B\nC9jatWtr1apVcz0MSZIGsX79etasWZNxz2MPmCRJ0sAswDQW7wPWZt26dXM9hAXDrNqYUxtzamdW\nw7IAkyRJGpg9YBqLPWCSpKXEHjBJkqQFygJMY7EHrI29Fe3Mqo05tTGndmY1LAswSZKkgdkDprHY\nAyZJWkrsAZMkSVqgLMA0FnvA2thb0c6s2phTG3NqZ1bDsgCTJEkamD1gGos9YJKkpcQeMEmSpAXK\nAkxjsQesjb0V7cyqjTm1Mad2ZjUsCzBJkqSB2QOmsdgDJklaSuwBkyRJWqAswDQWe8Da2FvRzqza\nmFMbc2pnVsOyAJMkSRqYPWAaiz1gkqSlxB4wSZKkBcoCTGOxB6yNvRXtzKqNObUxp3ZmNSwLMEmS\npIHZA6ax2AMmSVpK7AGTJElaoCzANBZ7wNrYW9HOrNqYUxtzamdWw7IAkyRJGpg9YBqLPWCSpKXE\nHjBJkqQFygJMY7EHrI29Fe3Mqo05tTGndmY1LAswSZKkgdkDprGsXbu2dtjz7nM9DEnzxB7LdmKv\n5TvP9TCk7Wa2esB2nI3BaGk78pPfmeshSJonjj50hQWY1MBLkBqLPWBtrjnPnFqZVRtzamNfUzuz\nGpYFmCRJ0sAswDSWlStXzvUQFoTldzOnVmbVxpzaHHzwwXM9hAXDrIZlASZJkjQwCzCNxR6wNvbr\ntDOrNubUxr6mdmY1LAswSZKkgVmAaSz2gLWxX6edWbUxpzb2NbUzq2FZgEmSJA3MAkxjsQesjf06\n7cyqjTm1sa+pnVkNywJMkiRpYBZgS1iS1yXZlOSaKeufleSyJOv7xxEzncMesDb267Qzqzbm1Ma+\npnZmNSw/C3KJShLgFODtwLen2eXEqnrRsKOSJGlpcAZsAUvyxiR/PLJ8VJK/SPKfSc5KsiHJY/tt\n+yT5VpLjk2wE7lhVZ1TVD2Y6fcsY7AFrY79OO7NqY05t7GtqZ1bDsgBb2D4KPHlk+cnA+4HHV9Vq\n4OHAMSPbVwB/V1X3q6qLb+bcT+gLuJOS3HE2By1J0lLnJcgFrKomktwuyZ7AHsAVwKXAsUkeAmwG\n9k6yR3/IRVV1ZsOpTwE+XFW/TPJHwPHAmul2/M53vsP5Z57GzrvvCcAOt7o1u+y94vr+lMm/0l12\neWuWJ82X8czH5eV3WzmvxjO5PHHGD9nv8Y8EbphRmewtmqvlSfNlPPN1eXLdfBnPfFme/HrTpk0A\nrF69mjVrpv0ncaukqsY+ieZOklcDPwL2BL4PXAs8Gji8qjYnuQA4hO6S4ieq6v7TnOOaqlo+w/lv\nAVxRVbeZbvvatWvr5eubrlZKWgKOPnQF++2961wPQ9pu1q9fz5o1a8b+h89LkAvfScBTgMOAjwG7\nAZf1xdfDgH1G9p3pB+ZG6/sZtUmPA86Z6cntAWtjv047s2pjTm3sa2pnVsOyAFvgquocYFfgu31D\n/YeAA5NsAJ4OfHN099Fjk/x1kouBW/W3o3hVv+lFSb6e5GzgBcCzt/frkCRpKfESpMbiJUhJo7wE\nqcXOS5CSJEkLlAWYxmIPWBv7ddqZVRtzamNfUzuzGpYFmCRJ0sAswDQWPwuyjZ/b186s2phTGz/f\nsJ1ZDcsCTJIkaWAWYBqLPWBt7NdpZ1ZtzKmNfU3tzGpYFmCSJEkDswDTWOwBa2O/TjuzamNObexr\namdWw7IAkyRJGpgFmMZiD1gb+3XamVUbc2pjX1M7sxqWBZgkSdLALMA0FnvA2tiv086s2phTG/ua\n2pnVsHac6wFo4Tv60BVzPQRJ88Qey3aa6yFIC4IFmMYyMTHBEUesmuthzHvr1q3zr8tGZtXGnNqY\nUzuzGpaXICVJkgaWqprrMWgBW7t2ba1a5QyYJGlpWL9+PWvWrMm453EGTJIkaWAWYBqL9wFr4/11\n2plVG3NqY07tzGpYFmCSJEkDswdMY7EHTJK0lNgDJkmStEBZgGks9oC1sbeinVm1Mac25tTOrIZl\nASZJkjQwe8A0FnvAJElLiT1gkiRJC5QFmMZiD1gbeyvamVUbc2pjTu3MalgWYJIkSQOzB0xjsQdM\nkrSU2AMmSZK0QFmAaSz2gLWxt6KdWbUxpzbm1M6shmUBJkmSNDB7wDQWe8AkSUuJPWCSJEkLlAWY\nxmIPWBt7K9qZVRtzamNO7cxqWBZgkiRJA7MHTGOxB0yStJTYAyZJkrRAWYBpLPaAtbG3op1ZtTGn\nNubUzqyGZQEmSZI0MHvANBZ7wCRJS4k9YJIkSQuUBZjGYg9YG3sr2plVG3NqY07tzGpYFmCSJEkD\n26oesCR3Au5QVV/efkPSQmIPmCRpKRm0ByzJnZN8AfgW8J/9uicmec+4A5AkSVpqWi9Bvgs4FdgV\n+GW/7j+AR2yPQWnhsAesjb0V7cyqjTm1Mad2ZjWsHRv3Owh4TFVtTlIAVXV1kt2239C0UGy45Nq5\nHsK8d97lP2VXc2qylLPaY9lO7LV857kehqQBNPWAJTkHeHxVnZvkiqr6zST3Bk6sqvtv91Fq3lq7\ndm29fP3Yl8IlAUcfuoL99t51rochaQuGvg/Ym4F/S/IcYMckTwU+Cvz1uAOQJElaapoKsKp6H3Ak\n8CTgYuCZwCur6kPbcWxaAOwBa3PNeebUyqza2K/TxpzamdWwbrYHLMkOwFHA66vq49t/SJIkSYvb\nzc6AVdWvgT/mhnc/StdbuXLlXA9hQVh+N3NqZVZtDj744LkewoJgTu3MalitPWAfAP7P9hyIJEnS\nUtFagB0EHJvkwiSfT/Jfk4/tOTjNf/aAtbGvqZ1ZtbFfp405tTOrYbXeB+wf+4ckSZLGtFWfBSlN\n5X3ApNnjfcCk+W+27gPWNAOW5IiZtvW3qJAkSVKj1h6wZ0x5HAm8s/9aS5g9YG3sa2pnVm3s12lj\nTu3MalitN2J92JTHvnTvijxr+w5vcUlyXJInTLP+kCSfmIPxHJjk7JHH40e2rUrytSTnJnnr0GOT\nJGkxa50Bm877gT+cpXEIBm3G62+wuxE4oKr2B34XeFeSyZ+JfwD+sKruAdwjyaOmO4/3AWvjva3a\nmVUb79nUxpzamdWwmgqwJLeY8lgG/BFw1fYd3vyXZJck/9bPIH0tyZOSvDLJGf3yO2c47tFJvpnk\nLOAJI+t3T/IvSTYk+WKS+81wfJJckGT5yLpzk9wuye8l+XKSryY5Lcnt+u1HJflAknXAB6rq51W1\nuT/8VsDmfr89gV2r6sx+2weAxyNJkmZF6wzYr+juhD/5uBp4Bd0d8pe6RwPfq6r9q+r+wKeBt1fV\nQf3yLkkeM3pAkp2BdwOPqarVwJ4jm18DrK+q/YC/oCt+bqK6t6/+K/AH/TkPAi6sqh8Cn6+qB1TV\nAXQfmv6ykUP3BR5eVYdPHpfk68AG4P/0BdkdgO+OHPPdft1N2APWxr6mdmbVxn6dNubUzqyG1Xof\nsN+asvyTqrp8tgezQG0E3pzkjcCpVbUuyWFJjgR2AXYHvg6cOnLMvYDzq+r8fvkE4Ln91wfTz4hV\n1elJfjPJsqr68TTPfRLwKuB44Cl0xRbAnZKcBOwF3BK4YOSYU6rqusmFqjoDuG+SewIfSPKprXnx\nn/vc5zj/ktPYefeuhtzhVrdml71XXH8ZafIf06W+PGm+jGc+L//0ku/Mq/EMuTxxxpe49ra7XH8p\naPIfRJe3fXnjxo3zajzzeXnjxo3zajzzZXny602bNgGwevVq1qxZw7ia7gOW5G1V9aJp1r+1qv50\n7FEscEluAxxKV0R9BvgTYFVVXZLkKLoJq9cmOQ74BHAe8LaqOqQ//veB51bVY5OsB55QVRf22zYB\n956hACPJucCDgDPo+rmuTHI68OaqOjXJIcBRVfXwfizXVtVbZjjXWrp3uF4CnN6/2YIkTwEOqarn\nTz3G+4BJs8f7gEnz32zdB6z1EuSzZ1i/5G9DkWQv4GdV9WHgzcAquob6K/peuSdOc9i3gH2STM4s\nPnVk2+eBp/fn/h3ghzMVX71/Ad4CnFNVV/brltMVUQDP2sLY79I345NkH+CedJcxLwWu7i9PBngm\n8PEtjEGSJG2FLRZgSY7ob8K64+TXI4/XAV6GhPsBZyQ5m+5y4F/RfWzT14FP0c1MTSqAqvoF8Dzg\nk30T/g9G9nk1cECSDcAb2EIB1TsJOBw4cWTda4CTk5wJ/HALxx4MbOhn3f4JeH5VXdFv+xPgvcC5\nwLer6tPTncAesDb2NbUzqzb267Qxp3ZmNayb6wGbnOHaiRvPdhVd0XBzxcGiV1WnAadNWb2erhib\nuu8RI1//O11D/NR9rqRvrG98/q8CO0xZdwpwyjT7vmbK8gl0/WcznXfad2BKkqTxtPaAva6q/nKA\n8WiBsQdMmj32gEnz36CfBTlafPU9QRnZtnnagzRrkjwbeDE3vlnrF6rqhXMzIkmSNI7WG7Hu3d8c\n9Efc9J5g2s6q6v39fcZWjTzmRfFlD1gb+5ramVUb+3XamFM7sxpW67sg3wVcB6wBfkz3Tr9T6D4P\nUpIkSVuhtQfsR8Cdq+onSa6qqtsk+U3gi1V1r+0+Ss1b9oBJs8ceMGn+G/o+YL+mu/QIcFX/2YI/\nYYaPp5EkSdLMWguwr9Dd6R3g3+k+8uafgbO2x6C0cNgD1sa+pnZm1cZ+nTbm1M6shtX6WZDP4IZi\n7U+BlwK7Am/dHoOSJElazJp6wKSZ2AMmzR57wKT5b9AesCQ7J3l9kvOTXN2ve2SSF4w7AEmSpKWm\ntQfsb4H70n3m4OSU2TeA52+PQWnhsAesjX1N7cyqjf06bcypnVkNq7UH7A+AFf1tKDYDVNX3kvgu\nSEmSpK3UWoBdN3Xf/lYUP5r1EWlBWblyJQfsuWKuh7EAmFG7pZvVHst2at734IMP3o4jWTzMqZ1Z\nDau1APsYcHySlwAk2YvuHZAnbq+BaeGwaViSpK0zYw/YlAb7dwEXABuB2wDfBi4BXrtdR6d5zx6w\nNvZWtDOrNubUxpzamdWwtjQD9nrg7/qvv1pVy4GX9JceLy/vXyFJkrRNZrwPWJKzgc/Qvdvx74E/\nBm5y34uqet/2HKDmt7Vr19aqVavmehiSJA1itu4DtqUZsP8FvAx4KnBL4JnT7FOABZgkSdJWmLEH\nrKrOrar/XVWPAD5XVQ+b5vHwAceqecgesDb2VrQzqzbm1Mac2pnVsJpuxFpVa7b3QCRJkpYKPwtS\nY7EHTJK0lAz6WZCSJEmaPRZgGos9YG3srWhnVm3MqY05tTOrYVmASZIkDcweMI3FHjBJ0lJiD5gk\nSdICZQGmsdgD1sbeinZm1cac2phTO7MalgWYJEnSwOwB01jsAZMkLSX2gEmSJC1QFmAaiz1gbeyt\naGdWbcypjTm1M6thWYBJkiQNzB4wjcUeMEnSUmIPmCRJ0gJlAaax2APWxt6KdmbVxpzamFM7sxqW\nBZgkSdLA7AHTWOwBkyQtJfaASZIkLVAWYBqLPWBt7K1oZ1ZtzKmNObUzq2FZgEmSJA3MHjCNxR4w\nSdJSYg+YJEnSAmUBprHYA9bG3op2ZtXGnNqYUzuzGpYFmCRJ0sDsAdNY7AGTJC0l9oBJkiQtUDvO\n9QC0sE1MTLDDnnef62HMexNnfImVBz1wrocxZ/ZYthN7Ld+5ad9169Zx8MEHb+cRLXzm1Mac2pnV\nsCzANLZZb5FhAAAXFUlEQVQjP/mduR7CvHfNed9j+eVLN6ejD13RXIBJ0lLgJUiNZeXKlXM9hAVh\n+d3MqZV/gbcxpzbm1M6shmUBJkmSNDALMI3F+4C1ueY8c2rlvYjamFMbc2pnVsOyAJMkSRqYBZjG\nYg9YG3vA2tmH0sac2phTO7MalgWYJEnSwCzANBZ7wNrYA9bOPpQ25tTGnNqZ1bAswCRJkgZmAaax\n2APWxh6wdvahtDGnNubUzqyGZQEmSZI0MAswjcUesDb2gLWzD6WNObUxp3ZmNSwLsCUgid9nSZLm\nEf9hXkCSPC/J2UnWJzk/ydokj0jyxSRnJflokl36fS9I8qYkZwFPTLJfki8lmUjyT0l26/e7a5JP\nJTkzyeeS3KNf/6QkG/vn++xMY7IHrI09YO3sQ2ljTm3MqZ1ZDcsCbAGpqndV1f7AQcDFwPuAvwTW\nVNVq4KvAn40ccnlVra6qk4APAEdW1Urg68BR/T7vBl5QVQcCRwL/0K9/JfDI/vkeu51fmiRJS8qO\ncz0AbZO3AZ8BrgLuDXwhSYBbAl8c2e+jAEmWA7tV1eQF/uOBk5LcGngQ8LH+ePpzAHwBOD7JScA/\nzzSQY489lvMv+QU7774nADvc6tbssveK62d8Jnuflvry5Lr5Mp7hX/8K4IYek8m/tKdb3rhxI89/\n/vOb91+qy6P9OvNhPPN12Z+n9uV/+Id/4H73u9+8Gc98WZ78etOmTQCsXr2aNWvWMK5U1dgn0XCS\nPBs4rKp+P8nvAU+tqsOn2e8C4ICquqIvwL5WVXfpt90VOAl4GPCtqrrDDM91IPB7wDOBVVV15dR9\njjnmmDpx8/6z8+IWsWvOm1jSlyGPPnQF++29a9O+69at81JIA3NqY07tzKrN+vXrWbNmTW5+zy3z\nEuQCkuQA4KXA0/tVXwEenORu/fZdktx96nFVdQ1wZZIH96ueAXyuqq4FLkjyxJHnuH//37tW1ZlV\ndRRwGXCn6cZkD1ibpVx8bS3/AWhjTm3MqZ1ZDctLkAvLnwC7A6f3VwzPAp4NfCTJzkDR9YR9u/96\n1LOAdyW5FXA+8Jx+/eHAO5P8Jd3Pw4nA14CjR4q5/6yqr22vFyVJ0lJjAbaAVNURM2w6aJp97zpl\n+WvAA6fZ7yLgd6dZf1jLmLr7gHkJ8uYs9UuQW8PLIG3MqY05tTOrYXkJUpIkaWAWYBqLPWBtnP1q\n51/gbcypjTm1M6thWYBJkiQNzAJMY/GzINv4WZDt/Dy6NubUxpzamdWwLMAkSZIGZgGmsdgD1sYe\nsHb2obQxpzbm1M6shmUBJkmSNDALMI3FHrA29oC1sw+ljTm1Mad2ZjUsCzBJkqSBWYBpLPaAtbEH\nrJ19KG3MqY05tTOrYVmASZIkDcwCTGOxB6yNPWDt7ENpY05tzKmdWQ3LD+PW2I4+dMVcD2Hemzjj\nh6w8aOnmtMeyneZ6CJI0r6Sq5noMWsDWrl1bq1atmuthSJI0iPXr17NmzZqMex4vQUqSJA3MAkxj\nsQesjb0V7cyqjTm1Mad2ZjUsCzBJkqSB2QOmsdgDJklaSuwBkyRJWqAswDQWe8Da2FvRzqzamFMb\nc2pnVsOyAJMkSRqYPWAaiz1gkqSlxB4wSZKkBcoCTGOxB6yNvRXtzKqNObUxp3ZmNSwLMEmSpIHZ\nA6ax2AMmSVpK7AGTJElaoCzANBZ7wNrYW9HOrNqYUxtzamdWw7IAkyRJGpg9YBqLPWCSpKXEHjBJ\nkqQFygJMY7EHrI29Fe3Mqo05tTGndmY1LAswSZKkgdkDprHYAyZJWkrsAZMkSVqgLMA0FnvA2thb\n0c6s2phTG3NqZ1bDsgCTJEkamD1gGos9YJKkpcQeMEmSpAXKAkxjsQesjb0V7cyqjTm1Mad2ZjUs\nCzBJkqSB2QOmsdgDJklaSuwBkyRJWqAswDQWe8Da2FvRzqzamFMbc2pnVsOyAJMkSRqYPWAaiz1g\nkqSlZLZ6wHacjcFoadtwybVzPQTNgT2W7cRey3ee62FI0oJkAaaxTExMcOLmsf8QWPSuOW+C5Xdb\nOdfDmFVHH7piuxRg69at4+CDD5718y425tTGnNqZ1bDsAZMkSRqYBZjGsnLl4prV2V4W2+zX9uRf\n4G3MqY05tTOrYVmASZIkDcwCTGPxPmBtrjnPnFp5L6I25tTGnNqZ1bAswCRJkgZmAaax2APWxh6w\ndvahtDGnNubUzqyGZQEmSZI0MAswjcUesDb2gLWzD6WNObUxp3ZmNSwLMEmSpIFZgGks9oC1sQes\nnX0obcypjTm1M6thzcsCLMlxSZ4wzfpDknxiLsY0MoZ9kmzsvz4gyVvnaAw/TbK+f7xjG89zVJI/\n679+VpI9R7a9J8lE/zgpyS6zNX5Jkpa6eVmA3Yya6wHQj6GqvlpVfzrkEyfZof/yO1W1qn/88Syc\n+tnAHUaW/7SqVlbVSuBi4AXTHWQPWBt7wNrZh9LGnNqYUzuzGtZgBViSXZL8W5Kzk3wtyZOSvDLJ\nGf3yO2c47tFJvpnkLOAJI+t3T/IvSTYk+WKS+23huY9K8v4k/5XkgiR/kOSv++f95GRRk2RVks8m\nOTPJp5Lcvl9/QD8TdDbwJyPnvX5GrnU86VyQZPnIunOT3C7J7yX5cpKvJjktye1Gxv+BJOuAD0we\n1pY8JLl25OvDkhw3ZfthwGrghH5Gbeeq+vHkeIFbMT8KX0mSFoUhZ8AeDXyvqvavqvsDnwbeXlUH\n9cu7JHnM6AFJdgbeDTymqlYDe45sfg2wvqr2A/6CGwqTmdwV+B3gccAJwNr+eX8OPCbJjsDbgcOq\n6kDgOOAN/bHvA/6kqvaf5ryThUnTeKqqgH8F/qB/jQcBF1bVD4HPV9UDquoA4KPAy0YO3Rd4eFUd\n3i/fpS+WTk9ycxfupxZPN1quqn8CzgKe1s+o/aIf2/uA7wP3pMvmJuwBa2MPWDv7UNqYUxtzamdW\nw9pxwOfaCLw5yRuBU6tqXT8bcySwC7A78HXg1JFj7gWcX1Xn98snAM/tvz6Yfkasqk5P8ptJlk3O\n3EzjU1W1ue/fukVVnTYyrrvQFRn3Bf6jn/W5BXBJkt2A3arqC/3+H6QrJqfamvGcBLwKOB54Cl2x\nBXCnJCcBewG3BC4YOeaUqrqu//oS4M5VdWWSVcC/Jrn3Fl57qxvNqlXVEX0Wb+/H+f6pB5x88smc\nf+b57Lx7VxvvcKtbs8veK64vOCYvvbm8OJcnL1lM/uJ22WWXXV5sy5Nfb9q0CYDVq1ezZs0axpVu\nQmYYSW4DHEpXRH2G7nLeqqq6JMlRdBNEr+0vkX0COA94W1Ud0h//+8Bzq+qxSdYDT6iqC/ttm4Bp\ni5D+3NdW1Vv65WuqavnoNuA04F1V9eApx+4GbKiqu/TL9wM+VFX3T3II8NKtHU+//VzgQcAZwAF9\nMXU68OaqOrU/91FV9fCp45/mXKf341g/w/bR13s4sKYvrq4/75bOkeQhwJFV9dip24455pg6cfN0\nE4Madc15E4tuFuzoQ1ew3967zvp5161b51/iDcypjTm1M6s269evZ82aNc1tQDMZsgdsL+BnVfVh\n4M3AKrpLYVckWQY8cZrDvgXsk+S3+uWnjmz7PPD0/ty/A/xwK2aApgvuv4HbJXlAf84d+1mlq4Gr\nkjyo3+/pM5xza8fzL8BbgHOq6sp+3XK62S2AZ804+OS2SW7Rf31XYAVw/kz7A5cmuWd/zB/MsM+1\n/fNPPsfd+v8GeCzd90KSJM2CIS9B3g84Oslm4Drg+cDj6S47fp9uJmjS5LsMf5HkecAnk/yErshZ\n1u/zauB9STYAP2ELBcs0bjLtV1W/TPJE4O39rNcOwFuBc4Aj+ufaTDdTNp2tHc9JdK95dL/XACcn\nuYJuhvAuMxz7UOC1Sa4DNgPPq6qrtvBcf053afcyul6vZdPs837gnUl+CjwYOD7JrnTF6ga679dN\nrFy5khOnnXfTqMU2+7U9+Rd4G3NqY07tzGpYg16C1OKzdu3aevn6sWditQBtr0uQkjSfLbhLkFqc\nvA9YG+8D1s57EbUxpzbm1M6shjXkJcjtLsmzgRdz40uMX6iqFy6F8ST5MrDT5GL/vM+oqm9sj+eT\nJEnbxkuQGouXIJcuL0FKWoq8BClJkrRAWYBpLPaAtbEHrJ19KG3MqY05tTOrYVmASZIkDcwCTGPx\nsyDbeB+wdt6LqI05tTGndmY1LAswSZKkgVmAaSz2gLWxB6ydfShtzKmNObUzq2FZgEmSJA3MAkxj\nsQesjT1g7exDaWNObcypnVkNywJMkiRpYIvqo4g0vImJCY4+9ElzPYx5b+KML7HyoAfO9TBm1R7L\ndrr5nbbBunXr/Eu8gTm1Mad2ZjUsCzCNzY+juXnX3nYXc5IkXc/PgtRY1q5dW6tWrZrrYUiSNAg/\nC1KSJGmBsgDTWLwPWBvvr9POrNqYUxtzamdWw7IAkyRJGpg9YBqLPWCSpKXEHjBJkqQFygJMY7EH\nrI29Fe3Mqo05tTGndmY1LAswSZKkgdkDprHYAyZJWkrsAZMkSVqgLMA0FnvA2thb0c6s2phTG3Nq\nZ1bDsgDTWL7zne/M9RAWhI0bN871EBYMs2pjTm3MqZ1ZtZmtiQcLMI3lJz/5yVwPYUG4+uqr53oI\nC4ZZtTGnNubUzqzabNiwYVbOYwEmSZI0MAswjeXSSy+d6yEsCJs2bZrrISwYZtXGnNqYUzuzGtaO\ncz0ALWyPetSjWL9+/VwPY95bvXq1OTUyqzbm1Mac2plVm/32229WzuN9wCRJkgbmJUhJkqSBWYBJ\nkiQNzAJM00ry6CTfSnJukv83wz5vS/LtJBNJVm7NsYvJtmaV5I5JPpPkG0k2JnnRsCMf1jg/U/22\nWyRZn+SUYUY8N8b8f2+3JB9L8s3+5+q3hxv58MbM6iVJvp7ka0k+lGSn4UY+rJvLKck9k3wxyc+T\n/NnWHLvYbGtW2/T7vKp8+LjRg64w/w6wD3BLYAK415R9fhc4tf/6t4Evtx67mB5jZrUnsLL/ehnw\n34s1q3FyGtn+EuAE4JS5fj3zNSfg/cBz+q93BJbP9Wuaj1kBewPnAzv1yx8FnjnXr2kOc7otcADw\nV8Cfbc2xi+kxZlZb/fvcGTBN5yDg21V1UVX9EjgReNyUfR4HfACgqr4C7Jbk9o3HLibbnFVVXVpV\nE/36HwPfBO4w3NAHNc7PFEnuCBwKvGe4Ic+Jbc4pyXLgIVV1XL/tV1V1zYBjH9pYP1PADsCtk+wI\n7AJcMsywB3ezOVXV5VX1VeBXW3vsIrPNWW3L73MLME3nDsDFI8vf5aY/SDPt03LsYrItWX1v6j5J\n7gKsBL4y6yOcH8bN6W+BI4HF/rbtcXL6LeDyJMf1l2rfneRW23W0c2ubs6qqS4BjgE39uquq6j+3\n41jn0ji/k/19vg2vt/X3uQWYZkvmegALVZJlwMnAi/u/nDQiyWOAH/R/XQZ/1mayI7AK+PuqWgX8\nFHj53A5pfkpyG7qZjX3oLkcuS/K0uR2VFoOt+X1uAabpfA+488jyHft1U/e50zT7tBy7mIyTFf3l\nj5OBD1bVx7fjOOfaODk9GHhskvOBjwAPS/KB7TjWuTROTt8FLq6qs/r1J9MVZIvVOFn9T+D8qrqi\nqn4N/DPwoO041rk0zu9kf59vxevd2t/nFmCazpnAiiT79O8Megow9Z1npwDPBEjyALop/B80HruY\njJMVwPuAc6rq2KEGPEe2OaeqekVV3bmq7tof95mqeuaQgx/QODn9ALg4yT36/dYA5ww07rkwzv97\nm4AHJPmNJKHL6pvDDX1QW/s7eXSG2d/n7VnBVv4+96OIdBNV9eskLwBOoyvS31tV30zyvG5zvbuq\nPpnk0CTfAX4CPGdLx87RS9nutjGrZwMkeTBwOLAxydl0/U2vqKpPz8mL2Y7G+ZlaSmYhpxcBH0py\nS7p3+S3aDMf8PXVGkpOBs4Ff9v9999y8ku2rJaf+jQlnAbsCm5O8GLh3Vf3Y3+dtWQH7sZW/z/0o\nIkmSpIF5CVKSJGlgFmCSJEkDswCTJEkamAWYJEnSwCzAJEmSBmYBJkmSNDALMElLWpKjknxwjOO/\nnuShszymOyW5pr9JqKRFyBuxSlLjh3wnOY7u435edf2BVfed9cFUXQwsn+3zbosk+wAXADtW1ea5\nHo+0WDgDJmnRSrLDXI9hIevzC12B6mycNIsswCQtKkkuSPKyJBuAHye5RZK9kpyc5LIk5yV54RaO\nPynJ95NcmeSzSfbt1z+X7qNGXtZfHvz4yPM9vH+Onya5zci59k/yw8lCMMkRSc5J8qMkn0py5xnG\nsE+SzUlu0S+fnuSvknwhybVJPp7kN5OckOTqJF8ZPVd/7Av713pZkr8Z2ZYkf5nkwiSXJnl/kuVT\nnveIJBcBa4HP0RVfV/Wv+7eT3DXJ2iSX9+c/YfIcI5m8NMmGPseP9J+tN7n9cUnO7sf+7SSP7Ncv\nT/KeJJckubh/zRZ+WpQswCQtRk8Bfhe4Dd3szSfoPu9vL7oPXn5xkkfMcOwngbsBewDrgQ8DVNU/\nAh8C/qaqllfV40YPqqrvA18EDhtZ/VTgY/1nzD0OeDnweOB2wOeBj2zhNUy9LPq/6ArAvYEV/XO9\nF9gd+BZw1JT9Hw+s6h+PS3JEv/45dB9QfQhwV7rPtPu7Kcc+FLgX8Kj+6wKW96/7K3QF2RuAPYF9\ngTsCr55yjicBjwR+i+5z8p4NkOQg4HjgpVW1W3/+C/tjjgeu68e1P/AI4H/PkI+0oFmASVqMjq2q\nS6rqF8CBwG2r6vVV9euquhB4D12RdhNV9f6q+mlV/RJ4LbBfkl0bn/cjwNNGlp9CV7QBPA94Y1Wd\n2/dSvQlYmeROjec+rqourKprgU8B51XV6f25PkZXsIx6U1VdXVXfBd5KVwzSj+8tVXVRVf0U+HPg\nKZOzbXTF1lFV9bM+v0nXz0RV1XlVtbaqflVVPwL+lq6gG3VsVf2gqq6iK4BX9uuPoPuQ48/05/p+\nVZ2bZA+6ovklVfXzqrp8yrilRcUmfEmL0XdHvt4HuEOSK/rl0P3x+V9TD+qLkDcATwRuS1eMVP/1\ntQ3P+0/A25Lcnm4G6ddV9YWRcRyb5JiRcRRwB+DihnP/YOTrn02zvGzK/qMZXEQ3c0b/34umbNsR\nuP0Mx95EXywdCzykf94dgCum7DY6vp/SzT4C3Ak4dZrT7gPcEvh+f9Ux/WPTlsYiLVQWYJIWo9HL\ndxcD51fVPRuOOxz4feDhVbUpyW7Aldww+7PFd0tW1VVJTqOb+doXOHFk8ybgdVW1pcuOs+lOwDf7\nr/cBLum/vqRfZmTbL+kKpsnZuNHXOd1rfgOwGbhPVV3dX159e+O4Lqa7xDvd+p8D/6Oqmt6VKi1k\nXoKUtNidAVzbN+b/RpIdktwnyepp9l0G/AK4MsmtgTdy4wLkB3T9SVvyEboeq8Po+8d67wJekeTe\nAEl2S/LELZxn3ObzI5Pcpr/E+SJuKAY/ArwkyV2SLANeD5w4couJqc/7Q7pia7Ro2hX4MV2udwCO\n3IpxvRd4TpKH9W8I2DvJPavqUuA04G+T7Npvu2tm+R5r0nxhASZpsbnR7ElfWPweXQ/SBcBlwD8y\n/X22PkA3U/U94Ot0je6j3gvcJ8kVSf55uucDTgHuDny/qjaOjONf6fq+TkxyFfA14NGNr2NbZoQ+\nDnyV7o0EnwDe169/H/BBukuw59FdHnzRTM9VVT+jK9K+0L/ug4DXAAcAk/1d/7SFsd94Q9WZdG8E\neCtwNfBZYPIdnM8EdgLOobuk+TG6Rn9p0YkzvZK0uCTZDKyoqvPneiySpucMmCRJ0sAswCRp8fHS\nhjTPeQlSkiRpYM6ASZIkDcwCTJIkaWAWYJIkSQOzAJMkSRqYBZgkSdLALMAkSZIG9v8BqiyIecov\ntOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117c7b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can plot the feature importance score,\n",
    "# note that in this script, the score is sorted in increasing order,\n",
    "# so to plot the top 5 important feauture, you'll have to obtain the last 5 row\n",
    "imp_df1.iloc[-5:].plot( kind = 'barh', x = 'feature', y = 'fscore', legend = False, figsize = ( 8, 6 ) )\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "1. This this is an unbalanced dataset, it's worth trying out under/over sampling techniques.\n",
    "2. Perform grid search/random search to find the \"best\" parameters for xgboost.\n",
    "3. Find a better workflow for cross validation on xgboost.\n",
    "4. Perform standardization, and try out deep learning. Standardizing features by removing the mean and scaling to unit variance is not needed for tree-type algorithms, but required for other types of algorithms ( e.g. deeplearning, svm, regression ).\n",
    "    \n",
    "```python\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardize\n",
    "std = StandardScaler()\n",
    "train_std = std.fit_transform(train)\n",
    "test_std  = std.transform(test)\n",
    "\n",
    "# convert the standardized features from np.array back to DataFrame\n",
    "train = pd.DataFrame( train_std, columns = train.columns )\n",
    "test  = pd.DataFrame( test_std , columns = test.columns )\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
